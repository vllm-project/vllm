## EPS Kickoff Notes

- Read `agent-ref/prd.md` and `agent-ref/impl.md` for EigenPage Summaries scope, requirements, and integration checkpoints.
- Key focus: decode-time gating at page-group granularity with JL sketch as primary method, optional 1PC tightening, must expose flags `--eps-*` and telemetry.
- Integration targets: `vllm/v1` KV cache manager hooks for K writes, decode pre-pass to filter pages, minimal call-site impact, behind feature flag.
- Remember to follow strict TDD, maintain minimal changes, and ensure telemetry + NVTX instrumentation per PRD.
- Recon pass:
  - `vllm/v1/core/kv_cache_manager.py` delegates block allocation to coordinator; `allocate_slots` only returns logical block IDs, so EPS gating needs to act after scheduler emits `req_state.block_ids`.
  - Decode prep lives in `vllm/v1/worker/gpu_model_runner.py`; block tables per KV group (`InputBatch.block_table`) are filled via `append_row` and committed in `_prepare_inputs` before metadata builders run. Prime hook point for injecting per-head/page filters is between block-table assembly and attention metadata creation.
  - `CommonAttentionMetadata` carries `block_table_tensor` + `slot_mapping` consumed by all attention backends; any EPS selector must adjust these tensors (or upstream block IDs) while keeping shapes expected by kernels.
  - KV writes flow through backend `PagedAttention.write_to_paged_cache` wrappers (CPU/GPU). We can attach JL updates alongside the call since slot mapping and new K slices are both available there.
  - Current block tables are per-request, shared across heads. Per-head gating would require either kernel support or deriving a shared visit list (less selective); need guidance on acceptable scope.
- Decision (Sohail): EPS v1 emits a per-request per-layer **union** mask; skip a group only if every head marks it safe. We still track per-head scores and thresholds for telemetry and future per-head table work.
- Env quirk: importing `vllm` on CPU-only setups with torch 2.4.x lacks `torch._inductor.config`; need guard in `env_override` so tests can run against CPU wheels.
- Added unit test skeleton `tests/v1/eps/test_union_mask.py` to pin contract for block table filtering; introduced scaffolding module `vllm/v1/eps/block_filter.py` implementing basic union mask rewrites.
- Local dev env: Python 3.11 venv with torch 2.4.1 CPU wheel plus dependency stack (huggingface_hub, transformers, aiohttp, etc.) required for loading `tests/conftest.py`.
- Added EPS telemetry (groups/blocks/unique/bytes) and NVTX range; decode pre-pass now mutates block tables with config-driven runtime (`EpsRuntimeConfig`).
- Next steps: surface counters via reporter/bytes estimator, add CPU decode smoke toggling `--eps-enabled`, and start JL summary updates on KV writes.
- Telemetry now streams via `EpsReporter` (per-step JSONL/log) with unique-block bytes; added CPU smoke + test coverage for union pre-pass and JL state helpers (`tests/v1/eps/test_union_prepass.py`, `tests/v1/eps/test_jl_state.py`). JL scaffolding in place (`EpsJLState`, `jl_update_*`); ready to hook into KV writes next.
- JL infrastructure added: `EpsJLState` now holds per-request Gram buffers, `jl_update_block/once` support vectorized updates, and unit coverage lives in `tests/v1/eps/test_jl_state.py`. Awaiting cache-write hook details to wire updates into prefill/decode paths.
- Repo audit (codex 2025-01-04 review):
  - CLI only exposes `--eps-enabled`/scope/group blocks/last-n/alpha/dim/metrics path (`vllm/engine/arg_utils.py:736`); PRD flags like `--eps-method`, `--eps-dim`, `--eps-alpha`, `--eps-heads`, etc. still missing.
  - Union pre-pass keeps the newest `last_n` groups without consulting JL sketches (`vllm/v1/eps/selector.py:7`); `EpsJLState` is initialized per request but never updated during KV writes yet (`vllm/v1/worker/gpu_model_runner.py:738`, `vllm/v1/eps/summarizer.py:12`).
  - Telemetry covers group/block/byte counters only and lacks the PRD-specified timing and per-step page metrics (`vllm/v1/eps/telemetry.py:27`).
  - Tests only cover JL state shapes/updates (`tests/v1/eps/test_jl_state.py:11`); union mask and decode smoke tests mentioned in plan are absent.
- KV-write hook landed: FlashAttention now calls `apply_eps_prefill_updates` before caching, and `GPUModelRunner` builds an `EpsForwardContext` (with request/block metadata) each step so JL summaries update per block (`vllm/v1/attention/backends/flash_attn.py:596`, `vllm/v1/worker/gpu_model_runner.py:2668`). Helper modules and unit coverage live in `vllm/v1/eps/writer.py`, `vllm/v1/eps/runtime.py`, and `tests/v1/eps/test_k_write_updates.py`.
- EPS CLI expanded to match PRD knobs (method/head scope/top-pages/strict) via updated `EpsConfig` and runtime plumbing (`vllm/config/eps.py`, `vllm/engine/arg_utils.py:736`, `vllm/v1/eps/config.py`).

- Union pre-pass now computes JL/Frobenius energies per request and applies top-page/last-n/strict heuristics via the forward context (`vllm/v1/eps/union_pass.py`, `vllm/v1/worker/gpu_model_runner.py:1125`).
- EPS unit suite (union pre-pass, smoke, writer, context, JL state, reporter) passes with torch 2.4.1 + Pillow on CPU (`.venv/bin/pytest tests/v1/eps/test_union_prepass.py tests/v1/eps/test_smoke_cpu.py tests/v1/eps/test_k_write_updates.py tests/v1/eps/test_context_builder.py tests/v1/eps/test_jl_state.py tests/v1/eps/test_reporter.py`).
- Open gaps vs. PRD/impl: selector still uses Frobenius (JL quadratic form + strict guardrails missing), lazy backfill for adopted prefixes TBD, non-Flash attention paths lack JL updates, telemetry needs to flow into metrics/logging, head-scoping + strict fallback not enforced, and config sweeps/end-to-end smokes are outstanding.
