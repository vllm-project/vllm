{
  "config": "full_attention",
  "model": "meta-llama/Llama-3.2-1B",
  "benchmark_params": {
    "input_lengths": [
      512,
      1024,
      2048,
      4096
    ],
    "num_prompts_per_length": 50,
    "output_len": 128,
    "num_warmup_iters": 3,
    "num_benchmark_iters": 5,
    "sliding_window": null,
    "use_hybrid": false,
    "seed": 42
  },
  "by_input_length": {
    "512": {
      "config": "full_attention",
      "config_description": "Full attention with complete KV cache",
      "model": "meta-llama/Llama-3.2-1B",
      "num_prompts": 50,
      "initialization": {
        "time_seconds": 10.3580721039325
      },
      "memory": {
        "baseline": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_init": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_benchmark": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "torch_stats": {},
        "kv_cache_memory_gib": null,
        "model_memory_gib": 0
      },
      "throughput": {
        "tokens_per_second": 23080.810981191455,
        "requests_per_second": 36.06376715811165,
        "total_prompt_tokens": 25600,
        "total_output_tokens": 6400
      },
      "latency": {
        "avg_seconds": 1.3864330861717462,
        "min_seconds": 1.29949701577425,
        "max_seconds": 1.723564675077796,
        "std_seconds": 0.16857609332647813,
        "p50_seconds": 1.3019040916115046,
        "p90_seconds": 1.5562749031931162,
        "p99_seconds": 1.706835697889328,
        "all_latencies": [
          1.723564675077796,
          1.29949701577425,
          1.3018594030290842,
          1.3053402453660965,
          1.3019040916115046
        ]
      },
      "benchmark_params": {
        "num_warmup_iters": 3,
        "num_benchmark_iters": 5,
        "gpu_memory_utilization": 0.9,
        "sliding_window": null,
        "use_hybrid": false
      }
    },
    "1024": {
      "config": "full_attention",
      "config_description": "Full attention with complete KV cache",
      "model": "meta-llama/Llama-3.2-1B",
      "num_prompts": 50,
      "initialization": {
        "time_seconds": 6.042668454349041
      },
      "memory": {
        "baseline": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_init": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_benchmark": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "torch_stats": {},
        "kv_cache_memory_gib": null,
        "model_memory_gib": 0
      },
      "throughput": {
        "tokens_per_second": 33902.96468166098,
        "requests_per_second": 29.429656841719606,
        "total_prompt_tokens": 51200,
        "total_output_tokens": 6400
      },
      "latency": {
        "avg_seconds": 1.6989664632827044,
        "min_seconds": 1.5088759455829859,
        "max_seconds": 2.439635656774044,
        "std_seconds": 0.37034741153228046,
        "p50_seconds": 1.514504423364997,
        "p90_seconds": 2.071196406334639,
        "p99_seconds": 2.4027917317301033,
        "all_latencies": [
          2.439635656774044,
          1.5088759455829859,
          1.5132787600159645,
          1.5185375306755304,
          1.514504423364997
        ]
      },
      "benchmark_params": {
        "num_warmup_iters": 3,
        "num_benchmark_iters": 5,
        "gpu_memory_utilization": 0.9,
        "sliding_window": null,
        "use_hybrid": false
      }
    },
    "2048": {
      "config": "full_attention",
      "config_description": "Full attention with complete KV cache",
      "model": "meta-llama/Llama-3.2-1B",
      "num_prompts": 50,
      "initialization": {
        "time_seconds": 5.97366863116622
      },
      "memory": {
        "baseline": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_init": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_benchmark": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "torch_stats": {},
        "kv_cache_memory_gib": null,
        "model_memory_gib": 0
      },
      "throughput": {
        "tokens_per_second": 46923.941576974146,
        "requests_per_second": 21.56431138647709,
        "total_prompt_tokens": 102400,
        "total_output_tokens": 6400
      },
      "latency": {
        "avg_seconds": 2.3186457987874745,
        "min_seconds": 1.9226618763059378,
        "max_seconds": 3.883672568947077,
        "std_seconds": 0.7825300525235727,
        "p50_seconds": 1.9256706815212965,
        "p90_seconds": 3.1050460591912272,
        "p99_seconds": 3.8058099179714917,
        "all_latencies": [
          3.883672568947077,
          1.9256706815212965,
          1.92411757260561,
          1.9371062945574522,
          1.9226618763059378
        ]
      },
      "benchmark_params": {
        "num_warmup_iters": 3,
        "num_benchmark_iters": 5,
        "gpu_memory_utilization": 0.9,
        "sliding_window": null,
        "use_hybrid": false
      }
    },
    "4096": {
      "config": "full_attention",
      "config_description": "Full attention with complete KV cache",
      "model": "meta-llama/Llama-3.2-1B",
      "num_prompts": 50,
      "initialization": {
        "time_seconds": 5.9410791508853436
      },
      "memory": {
        "baseline": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_init": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "post_benchmark": {
          "free_memory_gib": 0,
          "total_memory_gib": 0,
          "used_memory_gib": 0
        },
        "torch_stats": {},
        "kv_cache_memory_gib": null,
        "model_memory_gib": 0
      },
      "throughput": {
        "tokens_per_second": 58209.317609866965,
        "requests_per_second": 13.780614964457142,
        "total_prompt_tokens": 204800,
        "total_output_tokens": 6400
      },
      "latency": {
        "avg_seconds": 3.628285104036331,
        "min_seconds": 2.7482016291469336,
        "max_seconds": 7.093678155913949,
        "std_seconds": 1.7327285660602214,
        "p50_seconds": 2.7652051970362663,
        "p90_seconds": 5.367982525750995,
        "p99_seconds": 6.921108592897653,
        "all_latencies": [
          7.093678155913949,
          2.7652051970362663,
          2.754901457577944,
          2.779439080506563,
          2.7482016291469336
        ]
      },
      "benchmark_params": {
        "num_warmup_iters": 3,
        "num_benchmark_iters": 5,
        "gpu_memory_utilization": 0.9,
        "sliding_window": null,
        "use_hybrid": false
      }
    }
  }
}