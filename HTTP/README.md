# HTTP: Accelerating High Throughput Distributed Inference with Memory Efficient Hybird Tensor and Token Parallelism for Transformers

* Docker continer : nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.3.1

* vllm installed inside container: /opt/dynamo/venv/lib/python3.12/site-packages/vllm/


