{
  "benchmark_type": "video_inference",
  "model": "Qwen/Qwen2.5-VL-3B-Instruct",
  "num_frames": 48,
  "question": "Describe what is happening in this video in detail.",
  "results": [
    {
      "config": "standard_attention",
      "model": "Qwen/Qwen2.5-VL-3B-Instruct",
      "num_frames": 48,
      "num_iterations": 50,
      "total_input_tokens": 360350,
      "total_output_tokens": 6400,
      "avg_latency_seconds": 1.8477352142706513,
      "min_latency_seconds": 1.843474267050624,
      "max_latency_seconds": 1.8555422443896532,
      "p50_latency_seconds": 1.847511114552617,
      "p90_latency_seconds": 1.8506389040499927,
      "p99_latency_seconds": 1.8550118282996118,
      "throughput_tokens_per_second": 3969.724635515654,
      "generation_tokens_per_second": 69.27399500286349,
      "all_latencies": [
        1.8497458193451166,
        1.8472399860620499,
        1.8444317933171988,
        1.8480849992483854,
        1.8452561609447002,
        1.8489904403686523,
        1.849897738546133,
        1.8459400795400143,
        1.8450140915811062,
        1.8468696046620607,
        1.8482523374259472,
        1.8446002174168825,
        1.8484413363039494,
        1.8471893668174744,
        1.846004731953144,
        1.8451532889157534,
        1.8555422443896532,
        1.853418506681919,
        1.8479715269058943,
        1.845727551728487,
        1.8544597625732422,
        1.849705034866929,
        1.843474267050624,
        1.8471011240035295,
        1.8490902800112963,
        1.8463422134518623,
        1.849690429866314,
        1.8504773695021868,
        1.849636573344469,
        1.8477114494889975,
        1.8486601524055004,
        1.8442584425210953,
        1.845195759087801,
        1.8510870207101107,
        1.8440559599548578,
        1.8450864776968956,
        1.8529101312160492,
        1.8492299485951662,
        1.84751545637846,
        1.8475067727267742,
        1.8492386192083359,
        1.8447900395840406,
        1.8474126849323511,
        1.8505891133099794,
        1.8448068629950285,
        1.8446343708783388,
        1.8454270530492067,
        1.8499803338199854,
        1.8478168211877346,
        1.8450983669608831
      ],
      "memory": {
        "post_init": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        },
        "baseline": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        },
        "post_benchmark": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        }
      },
      "error": null
    },
    {
      "config": "hybrid_attention",
      "model": "Qwen/Qwen2.5-VL-3B-Instruct",
      "num_frames": 48,
      "num_iterations": 50,
      "total_input_tokens": 360350,
      "total_output_tokens": 6400,
      "avg_latency_seconds": 1.8441758020222188,
      "min_latency_seconds": 1.8338998388499022,
      "max_latency_seconds": 1.854545496404171,
      "p50_latency_seconds": 1.8443428929895163,
      "p90_latency_seconds": 1.8486274352297187,
      "p99_latency_seconds": 1.8531347292289138,
      "throughput_tokens_per_second": 3977.3865332995124,
      "generation_tokens_per_second": 69.4076995586009,
      "all_latencies": [
        1.8457008823752403,
        1.8423812724649906,
        1.8501752484589815,
        1.8444851357489824,
        1.8429317995905876,
        1.8465633131563663,
        1.8441152218729258,
        1.8422243036329746,
        1.8444306533783674,
        1.8456577509641647,
        1.8479898236691952,
        1.8448285516351461,
        1.8459121882915497,
        1.8453709967434406,
        1.8442933950573206,
        1.8482587281614542,
        1.8435336835682392,
        1.8394859358668327,
        1.8353697918355465,
        1.8343610372394323,
        1.8339294865727425,
        1.8338998388499022,
        1.838582331314683,
        1.843780755996704,
        1.8516663797199726,
        1.843906406313181,
        1.8434387389570475,
        1.8485604468733072,
        1.8416869565844536,
        1.8419966790825129,
        1.842707259580493,
        1.8472141399979591,
        1.8439747840166092,
        1.844392390921712,
        1.8492303304374218,
        1.8423276860266924,
        1.8419368490576744,
        1.8478193003684282,
        1.8447624538093805,
        1.8419796507805586,
        1.842246936634183,
        1.8466807026416063,
        1.8432367574423552,
        1.8418568763881922,
        1.8496218211948872,
        1.8475946988910437,
        1.8461920749396086,
        1.8465280756354332,
        1.854545496404171,
        1.844424081966281
      ],
      "memory": {
        "post_init": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        },
        "baseline": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        },
        "post_benchmark": {
          "available": false,
          "error": "CUDA error: CUDA-capable device(s) is/are busy or unavailable\nSearch for `cudaErrorDevicesUnavailable' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
        }
      },
      "error": null
    }
  ]
}