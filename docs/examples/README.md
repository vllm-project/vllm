# Examples

vLLM's examples are split into three categories:

- If you are using vLLM from within Python code, see [Offline Inference](../../examples/offline_inference)
- If you are using vLLM from an HTTP application or client, see [Online Serving](../../examples/online_serving)
- For examples of using some of vLLM's advanced features (e.g. LMCache or Tensorizer), see [Others](../../examples/others)
