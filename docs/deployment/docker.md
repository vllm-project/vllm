# Using Docker

## Use vLLM's Official Docker Image

=== "NVIDIA CUDA"
    --8<-- "docs/deployment/docker.cuda.inc.md:use-official-docker-image"
=== "AMD ROCm"
    --8<-- "docs/deployment/docker.rocm.inc.md:use-official-docker-image"

## Building vLLM's Docker Image from Source

=== "NVIDIA CUDA"
    --8<-- "docs/deployment/docker.cuda.inc.md:build-docker-image-from-source"
=== "AMD ROCm"
    --8<-- "docs/deployment/docker.rocm.inc.md:build-docker-image-from-source"

## Use the custom-built vLLM Docker image

=== "NVIDIA CUDA"
    --8<-- "docs/deployment/docker.cuda.inc.md:use-custom-docker-image"
=== "AMD ROCm"
    --8<-- "docs/deployment/docker.rocm.inc.md:use-custom-docker-image"
