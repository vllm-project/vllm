# Google TPU

!!! note "vLLM TPU Support via `tpu-inference`"
    vLLM support for Google TPUs is now provided through the [`tpu-inference`](http://github.com/vllm-project/tpu-inference/) library, a dedicated plugin for vLLM. This new backend unifies support for PyTorch and JAX, offering improved performance and a streamlined user experience.

    **The documentation for TPU support has moved to a new, dedicated site.**

    For the most up-to-date guides, please see:

* [**vLLM on TPU Documentation Site**](https://docs.vllm.ai/projects/tpu/en/latest/)
* [**Installation Guide**](https://docs.vllm.ai/projects/tpu/en/latest/getting_started/installation/)
* [**Quickstart Guide**](https://docs.vllm.ai/projects/tpu/en/latest/getting_started/quickstart/)