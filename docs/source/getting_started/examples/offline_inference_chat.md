# Offline Inference Chat

Source <https://github.com/vllm-project/vllm/blob/main/examples/offline_inference_chat.py>.

```{literalinclude} ../../../../examples/offline_inference_chat.py
:language: python
:linenos: true
```
