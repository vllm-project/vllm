fp8, amd/Meta-Llama-3.1-8B-Instruct-FP8-KV, main
None, amd/Llama-3.2-1B-Instruct-FP8-KV, main
gptq, TheBloke/Llama-2-7B-GPTQ, main
