# In this file, you can add more tests to run either by adding a new step or
# adding a new command to an existing step. See different options here for examples.
# This script will be feed into Jinja template in `test-template.j2` to generate
# the final pipeline yaml file.

steps:
- label: Regression Test
  command: pytest -v -s test_regression.py
  working_dir: "/vllm-workspace/tests" # optional

- label: AsyncEngine Test
  command: pytest -v -s async_engine

- label: Basic Correctness Test
  command: pytest -v -s --forked basic_correctness

- label: Core Test
  command: pytest -v -s core

- label: Distributed Comm Ops Test
  command: pytest -v -s --forked test_comm_ops.py
  working_dir: "/vllm-workspace/tests/distributed"
  num_gpus: 2 # only support 1 or 2 for now.

- label: Distributed Correctness Test
  command: pytest -v -s --forked test_basic_distributed_correctness.py
  working_dir: "/vllm-workspace/tests/distributed"
  num_gpus: 2 # only support 1 or 2 for now.

- label: Engine Test
  command: pytest -v -s engine tokenization test_sequence.py

- label: Entrypoints Test
  command: pytest -v -s entrypoints

- label: Kernels Test
  command: pytest -v -s kernels
  soft_fail: true

- label: Models Test
  commands:
    - pytest -v -s models --forked
  soft_fail: true

- label: Prefix Caching Test
  commands:
    - pytest -v -s prefix_caching

- label: Samplers Test
  command: pytest -v -s samplers --forked

- label: Worker Test
  command: pytest -v -s worker

- label: Speculative decoding tests
  command: pytest -v -s spec_decode

- label: LoRA Test
  command: pytest -v -s lora --forked

- label: Metrics Test
  command: pytest -v -s metrics

- label: Benchmarks
  working_dir: "/vllm-workspace/.buildkite"
  commands:
  - pip install aiohttp
  - bash run-benchmarks.sh

- label: Documentation Build
  working_dir: "/vllm-workspace/docs"
  no_gpu: True
  commands:
  - pip install -r requirements-docs.txt
  - SPHINXOPTS=\"-W\" make html
