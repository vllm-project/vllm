# For vllm script, with -t option (tensor parallel size).
# bash .buildkite/lm-eval-harness/run-lm-eval-gsm-vllm-baseline.sh -m Meta-Llama/Llama-4-Maverick-17B-128E-Instruct-FP8 -b 32 -l 1000 -f 5 -t 1
model_name: "Meta-Llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
tasks:
- name: "gsm8k"
  metrics:
  - name: "exact_match,strict-match"
    value: 0.825  # Expected high performance for 17B model
  - name: "exact_match,flexible-extract"
    value: 0.825
limit: 1000
num_fewshot: 5
trust_remote_code: true  # Llama models typically need this 