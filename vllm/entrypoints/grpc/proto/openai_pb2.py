# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: openai.proto
# Protobuf Python Version: 6.31.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import runtime_version as _runtime_version
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
_runtime_version.ValidateProtobufRuntimeVersion(
    _runtime_version.Domain.PUBLIC,
    6,
    31,
    1,
    '',
    'openai.proto'
)
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()




DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0copenai.proto\x12\x0bvllm.openai\"\xda\x04\n\x15\x43hatCompletionRequest\x12\r\n\x05model\x18\x01 \x01(\t\x12*\n\x08messages\x18\x02 \x03(\x0b\x32\x18.vllm.openai.ChatMessage\x12\x18\n\x0btemperature\x18\x03 \x01(\x02H\x00\x88\x01\x01\x12\x12\n\x05top_p\x18\x04 \x01(\x02H\x01\x88\x01\x01\x12\x17\n\nmax_tokens\x18\x05 \x01(\x05H\x02\x88\x01\x01\x12\"\n\x15max_completion_tokens\x18\x06 \x01(\x05H\x03\x88\x01\x01\x12\x13\n\x06stream\x18\x07 \x01(\x08H\x04\x88\x01\x01\x12\x0c\n\x04stop\x18\x08 \x03(\t\x12\x11\n\x04seed\x18\t \x01(\x03H\x05\x88\x01\x01\x12\x1e\n\x11\x66requency_penalty\x18\n \x01(\x02H\x06\x88\x01\x01\x12\x1d\n\x10presence_penalty\x18\x0b \x01(\x02H\x07\x88\x01\x01\x12\x12\n\x05top_k\x18\x0c \x01(\x05H\x08\x88\x01\x01\x12\x12\n\x05min_p\x18\r \x01(\x02H\t\x88\x01\x01\x12\x1f\n\x12repetition_penalty\x18\x0e \x01(\x02H\n\x88\x01\x01\x12\x0e\n\x01n\x18\x0f \x01(\x05H\x0b\x88\x01\x01\x12\x11\n\x04user\x18\x14 \x01(\tH\x0c\x88\x01\x01\x42\x0e\n\x0c_temperatureB\x08\n\x06_top_pB\r\n\x0b_max_tokensB\x18\n\x16_max_completion_tokensB\t\n\x07_streamB\x07\n\x05_seedB\x14\n\x12_frequency_penaltyB\x13\n\x11_presence_penaltyB\x08\n\x06_top_kB\x08\n\x06_min_pB\x15\n\x13_repetition_penaltyB\x04\n\x02_nB\x07\n\x05_user\"=\n\x0b\x43hatMessage\x12\x0c\n\x04role\x18\x01 \x01(\t\x12\x14\n\x07\x63ontent\x18\x02 \x01(\tH\x00\x88\x01\x01\x42\n\n\x08_content\"\x9d\x01\n\x16\x43hatCompletionResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06object\x18\x02 \x01(\t\x12\x0f\n\x07\x63reated\x18\x03 \x01(\x03\x12\r\n\x05model\x18\x04 \x01(\t\x12$\n\x07\x63hoices\x18\x05 \x03(\x0b\x32\x13.vllm.openai.Choice\x12!\n\x05usage\x18\x06 \x01(\x0b\x32\x12.vllm.openai.Usage\"Y\n\x06\x43hoice\x12\r\n\x05index\x18\x01 \x01(\x05\x12)\n\x07message\x18\x02 \x01(\x0b\x32\x18.vllm.openai.ChatMessage\x12\x15\n\rfinish_reason\x18\x03 \x01(\t\"O\n\x05Usage\x12\x15\n\rprompt_tokens\x18\x01 \x01(\x05\x12\x19\n\x11\x63ompletion_tokens\x18\x02 \x01(\x05\x12\x14\n\x0ctotal_tokens\x18\x03 \x01(\x05\"\xb8\x01\n\x1c\x43hatCompletionStreamResponse\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0e\n\x06object\x18\x02 \x01(\t\x12\x0f\n\x07\x63reated\x18\x03 \x01(\x03\x12\r\n\x05model\x18\x04 \x01(\t\x12*\n\x07\x63hoices\x18\x05 \x03(\x0b\x32\x19.vllm.openai.StreamChoice\x12&\n\x05usage\x18\x06 \x01(\x0b\x32\x12.vllm.openai.UsageH\x00\x88\x01\x01\x42\x08\n\x06_usage\"n\n\x0cStreamChoice\x12\r\n\x05index\x18\x01 \x01(\x05\x12!\n\x05\x64\x65lta\x18\x02 \x01(\x0b\x32\x12.vllm.openai.Delta\x12\x1a\n\rfinish_reason\x18\x03 \x01(\tH\x00\x88\x01\x01\x42\x10\n\x0e_finish_reason\"E\n\x05\x44\x65lta\x12\x11\n\x04role\x18\x01 \x01(\tH\x00\x88\x01\x01\x12\x14\n\x07\x63ontent\x18\x02 \x01(\tH\x01\x88\x01\x01\x42\x07\n\x05_roleB\n\n\x08_content\"\x14\n\x12HealthCheckRequest\"7\n\x13HealthCheckResponse\x12\x0f\n\x07healthy\x18\x01 \x01(\x08\x12\x0f\n\x07message\x18\x02 \x01(\t2\xa5\x02\n\rOpenAIService\x12Y\n\x0e\x43hatCompletion\x12\".vllm.openai.ChatCompletionRequest\x1a#.vllm.openai.ChatCompletionResponse\x12g\n\x14\x43hatCompletionStream\x12\".vllm.openai.ChatCompletionRequest\x1a).vllm.openai.ChatCompletionStreamResponse0\x01\x12P\n\x0bHealthCheck\x12\x1f.vllm.openai.HealthCheckRequest\x1a .vllm.openai.HealthCheckResponseb\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'openai_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  DESCRIPTOR._loaded_options = None
  _globals['_CHATCOMPLETIONREQUEST']._serialized_start=30
  _globals['_CHATCOMPLETIONREQUEST']._serialized_end=632
  _globals['_CHATMESSAGE']._serialized_start=634
  _globals['_CHATMESSAGE']._serialized_end=695
  _globals['_CHATCOMPLETIONRESPONSE']._serialized_start=698
  _globals['_CHATCOMPLETIONRESPONSE']._serialized_end=855
  _globals['_CHOICE']._serialized_start=857
  _globals['_CHOICE']._serialized_end=946
  _globals['_USAGE']._serialized_start=948
  _globals['_USAGE']._serialized_end=1027
  _globals['_CHATCOMPLETIONSTREAMRESPONSE']._serialized_start=1030
  _globals['_CHATCOMPLETIONSTREAMRESPONSE']._serialized_end=1214
  _globals['_STREAMCHOICE']._serialized_start=1216
  _globals['_STREAMCHOICE']._serialized_end=1326
  _globals['_DELTA']._serialized_start=1328
  _globals['_DELTA']._serialized_end=1397
  _globals['_HEALTHCHECKREQUEST']._serialized_start=1399
  _globals['_HEALTHCHECKREQUEST']._serialized_end=1419
  _globals['_HEALTHCHECKRESPONSE']._serialized_start=1421
  _globals['_HEALTHCHECKRESPONSE']._serialized_end=1476
  _globals['_OPENAISERVICE']._serialized_start=1479
  _globals['_OPENAISERVICE']._serialized_end=1772
# @@protoc_insertion_point(module_scope)
