#!/usr/bin/env python3
# SPDX-License-Identifier: Apache-2.0
# SPDX-FileCopyrightText: Copyright contributors to the vLLM project
"""Analyze MoE config files to extract patterns for better defaults."""

import json
import os
from collections import defaultdict
from typing import Any

import numpy as np


def parse_all_configs():
    """Parse all config files and extract data."""
    configs_dir = os.path.dirname(os.path.abspath(__file__))

    configs_data = []

    for filename in os.listdir(configs_dir):
        if not filename.endswith('.json') or filename == 'README.json':
            continue

        # Parse filename
        name = filename[:-5]  # remove .json
        parts = name.split(',')

        config_info: dict[str, Any] = {}
        for part in parts:
            if part.startswith('E='):
                config_info['E'] = int(part[2:])
            elif part.startswith('N='):
                config_info['N'] = int(part[2:])
            elif part.startswith('device_name='):
                config_info['device'] = part[12:]
            elif part.startswith('dtype='):
                config_info['dtype'] = part[6:]

        if 'E' not in config_info or 'N' not in config_info:
            continue

        config_info['filename'] = filename

        # Load the config file
        try:
            with open(os.path.join(configs_dir, filename)) as f:
                config_data = json.load(f)

            config_info['batch_configs'] = {}
            for batch_size, batch_config in config_data.items():
                config_info['batch_configs'][int(batch_size)] = batch_config

            configs_data.append(config_info)

        except Exception as e:
            print(f"Error loading {filename}: {e}")
            continue

    return configs_data


def analyze_patterns(configs_data):
    """Analyze patterns in the config data."""

    print("=== MoE Config Analysis (All Vendors) ===\n")

    # Group by dtype
    by_dtype = defaultdict(list)
    for config in configs_data:
        dtype = config.get('dtype', 'unquantized')
        by_dtype[dtype].append(config)

    print("Configs by dtype:")
    for dtype, configs in by_dtype.items():
        print(f"  {dtype}: {len(configs)} configs")
    print()

    # Group by device families
    device_families = defaultdict(list)
    for config in configs_data:
        device = config.get('device', 'Unknown')
        if 'H100' in device:
            family = 'H100'
        elif 'A100' in device:
            family = 'A100'
        elif 'H200' in device:
            family = 'H200'
        elif 'H20' in device:
            family = 'H20'
        elif 'A800' in device:
            family = 'A800'
        elif 'MI300' in device:
            family = 'MI300'
        elif 'MI325' in device:
            family = 'MI325'
        elif 'AMD' in device:
            family = 'AMD_Other'
        else:
            family = 'Other'
        device_families[family].append(config)

    print("Configs by device family:")
    for family, configs in device_families.items():
        print(f"  {family}: {len(configs)} configs")
    print()

    # Analyze patterns for each dtype
    for dtype, configs in by_dtype.items():
        print(f"\n=== Analysis for {dtype} ===")
        analyze_dtype_patterns(configs, dtype)


def analyze_dtype_patterns(configs: list[dict], dtype: str):
    """Analyze patterns for a specific dtype."""

    # Collect all batch configs across all E/N combinations
    all_batch_configs = []
    E_values = set()
    N_values = set()

    for config in configs:
        E_values.add(config['E'])
        N_values.add(config['N'])

        for batch_size, batch_config in config['batch_configs'].items():
            entry = {
                'E': config['E'],
                'N': config['N'],
                'device': config['device'],
                'batch_size': batch_size,
                **batch_config
            }
            all_batch_configs.append(entry)

    print(f"Expert counts (E): {sorted(E_values)}")
    print(f"Hidden dims (N): {sorted(N_values)}")
    print(f"Total batch configs: {len(all_batch_configs)}")

    # Analyze block size patterns
    analyze_block_sizes(all_batch_configs)

    # Analyze warp and stage patterns
    analyze_warp_stage_patterns(all_batch_configs)

    # Analyze trends by E and N
    analyze_E_N_trends(all_batch_configs)


def analyze_block_sizes(configs):
    """Analyze block size patterns."""
    print("\n--- Block Size Analysis ---")
    if not configs:
        print("  No batch configs to analyze for block sizes.")
        return

    block_m_values = [c['BLOCK_SIZE_M'] for c in configs]
    block_n_values = [c['BLOCK_SIZE_N'] for c in configs]
    block_k_values = [c['BLOCK_SIZE_K'] for c in configs]

    print(
        f"BLOCK_SIZE_M: min={min(block_m_values)}, max={max(block_m_values)}, "
        f"most_common={max(set(block_m_values), key=block_m_values.count)}")
    print(
        f"BLOCK_SIZE_N: min={min(block_n_values)}, max={max(block_n_values)}, "
        f"most_common={max(set(block_n_values), key=block_n_values.count)}")
    print(
        f"BLOCK_SIZE_K: min={min(block_k_values)}, max={max(block_k_values)}, "
        f"most_common={max(set(block_k_values), key=block_k_values.count)}")

    # Look at combinations
    combinations: dict[tuple[int, int, int], int] = defaultdict(int)
    for c in configs:
        combo = (c['BLOCK_SIZE_M'], c['BLOCK_SIZE_N'], c['BLOCK_SIZE_K'])
        combinations[combo] += 1

    print("\nMost common (M,N,K) combinations:")
    for combo, count in sorted(combinations.items(),
                               key=lambda x: x[1],
                               reverse=True)[:10]:
        print(f"  {combo}: {count} times")


def analyze_warp_stage_patterns(configs):
    """Analyze warp and stage patterns."""
    print("\n--- Warp/Stage Analysis ---")
    if not configs:
        print("  No batch configs to analyze for warp/stage patterns.")
        return

    warp_values = [c['num_warps'] for c in configs]
    stage_values = [c['num_stages'] for c in configs]
    group_m_values = [c['GROUP_SIZE_M'] for c in configs]

    print(f"num_warps: min={min(warp_values)}, max={max(warp_values)}, "
          f"most_common={max(set(warp_values), key=warp_values.count)}")
    print(f"num_stages: min={min(stage_values)}, max={max(stage_values)}, "
          f"most_common={max(set(stage_values), key=stage_values.count)}")
    print(
        f"GROUP_SIZE_M: min={min(group_m_values)}, max={max(group_m_values)}, "
        f"most_common={max(set(group_m_values), key=group_m_values.count)}")


def analyze_E_N_trends(configs):
    """Analyze trends based on E and N values."""
    print("\n--- E/N Trend Analysis ---")

    # Group by E ranges
    E_ranges = {
        'small_E': [c for c in configs if c['E'] <= 8],
        'medium_E': [c for c in configs if 8 < c['E'] <= 64],
        'large_E': [c for c in configs if c['E'] > 64]
    }

    # Group by N ranges
    N_ranges = {
        'small_N': [c for c in configs if c['N'] <= 1024],
        'medium_N': [c for c in configs if 1024 < c['N'] <= 4096],
        'large_N': [c for c in configs if c['N'] > 4096]
    }

    print("Trends by Expert Count (E):")
    for range_name, range_configs in E_ranges.items():
        if not range_configs:
            continue
        print(f"\n  {range_name} (n={len(range_configs)}):")
        analyze_range_stats(range_configs)

    print("\nTrends by Hidden Dim (N):")
    for range_name, range_configs in N_ranges.items():
        if not range_configs:
            continue
        print(f"\n  {range_name} (n={len(range_configs)}):")
        analyze_range_stats(range_configs)

    # Batch size trends
    print("\nTrends by Batch Size:")
    batch_ranges = {
        'tiny_batch': [c for c in configs if c['batch_size'] <= 8],
        'small_batch': [c for c in configs if 8 < c['batch_size'] <= 64],
        'medium_batch': [c for c in configs if 64 < c['batch_size'] <= 512],
        'large_batch': [c for c in configs if c['batch_size'] > 512]
    }

    for range_name, range_configs in batch_ranges.items():
        if not range_configs:
            continue
        print(f"\n  {range_name} (n={len(range_configs)}):")
        analyze_range_stats(range_configs)


def analyze_range_stats(configs):
    """Analyze stats for a range of configs."""
    if not configs:
        return

    # Collect values for analysis
    block_m_vals = [c['BLOCK_SIZE_M'] for c in configs]
    block_n_vals = [c['BLOCK_SIZE_N'] for c in configs]
    block_k_vals = [c['BLOCK_SIZE_K'] for c in configs]
    warps_vals = [c['num_warps'] for c in configs]
    stages_vals = [c['num_stages'] for c in configs]
    group_m_vals = [c['GROUP_SIZE_M'] for c in configs]

    def analyze_distribution(values, name):
        """Analyze distribution of values."""
        if not values:
            return

        # Basic stats
        avg = np.mean(values)
        std = np.std(values)
        median = np.median(values)

        # Mode (most common)
        from collections import Counter
        counter = Counter(values)
        mode = counter.most_common(1)[0][0]
        mode_count = counter.most_common(1)[0][1]
        mode_pct = (mode_count / len(values)) * 100

        # Top 3 most common values
        top3 = counter.most_common(3)

        print(f"    {name}:")
        print(f"      avg={avg:.1f} Â± {std:.1f}, median={median:.1f}")
        print(f"      mode={mode} ({mode_pct:.1f}% of configs)")
        print(f"      top3: {[f'{val}({cnt})' for val, cnt in top3]}")

    analyze_distribution(block_m_vals, "BLOCK_SIZE_M")
    analyze_distribution(block_n_vals, "BLOCK_SIZE_N")
    analyze_distribution(block_k_vals, "BLOCK_SIZE_K")
    analyze_distribution(warps_vals, "num_warps")
    analyze_distribution(stages_vals, "num_stages")
    analyze_distribution(group_m_vals, "GROUP_SIZE_M")


if __name__ == "__main__":
    configs_data = parse_all_configs()
    print(f"Loaded {len(configs_data)} config files")
    analyze_patterns(configs_data)
