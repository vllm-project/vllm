Just a fork of vllm with minor modifications. 

- generate endpoint modified to output logits, and *not* output the prompt
- Building optimizations, targeting the A100 and changing some flags.
- Torch 2.2 as a requirement

