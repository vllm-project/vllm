{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f810bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-13 10:14:28 [__init__.py:244] Automatically detected platform cuda.\n",
      "INFO 08-13 10:14:32 [config.py:840] This model supports multiple tasks: {'reward', 'generate', 'embed', 'score', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 08-13 10:14:32 [config.py:1454] Using max model len 1024\n",
      "WARNING 08-13 10:14:32 [arg_utils.py:1724] --enable-prompt-embeds is not supported by the V1 Engine. Falling back to V0. \n",
      "WARNING 08-13 10:14:33 [cuda.py:102] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used\n",
      "INFO 08-13 10:14:33 [llm_engine.py:230] Initializing a V0 LLM engine (v0.1.dev7407+gae88822.d20250716) with config: model='/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec', speculative_config=None, tokenizer='Qwen/Qwen2.5-Coder-7B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=False, pooler_config=None, compilation_config={\"level\":0,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":0,\"cudagraph_capture_sizes\":[],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":0,\"local_cache_dir\":null}, use_cached_outputs=False, \n",
      "INFO 08-13 10:14:34 [cuda.py:347] Using Flash Attention backend.\n",
      "INFO 08-13 10:14:35 [parallel_state.py:1076] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "INFO 08-13 10:14:35 [model_runner.py:1172] Starting to load model /project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d93a6733e14f6095a38cfefc3c9844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 08-13 10:14:36 [default_loader.py:272] Loading weights took 0.81 seconds\n",
      "INFO 08-13 10:14:37 [model_runner.py:1204] Model loading took 2.4751 GiB and 0.874681 seconds\n",
      "Layer: DummyDecoderLayer()\n",
      "Error in RMSNorm: too many values to unpack (expected 2). Skipping RMSNorm.\n",
      "INFO 08-13 10:14:38 [worker.py:304] Memory profiling takes 0.36 seconds\n",
      "INFO 08-13 10:14:38 [worker.py:304] the current vLLM instance can use total_gpu_memory (79.32GiB) x gpu_memory_utilization (0.20) = 15.86GiB\n",
      "INFO 08-13 10:14:38 [worker.py:304] model weights take 2.48GiB; non_torch_memory takes 0.09GiB; PyTorch activation peak memory takes 1.40GiB; the rest of the memory reserved for KV Cache is 11.89GiB.\n",
      "INFO 08-13 10:14:38 [executor_base.py:113] # cuda blocks: 13920, # CPU blocks: 4681\n",
      "INFO 08-13 10:14:38 [executor_base.py:118] Maximum concurrency for 1024 tokens per request: 217.50x\n",
      "INFO 08-13 10:14:40 [llm_engine.py:428] init engine (profile, create kv cache, warmup model) took 2.57 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedTokenizer, PretrainedConfig, AutoConfig, AutoModel\n",
    "from transformers.modeling_utils import PreTrainedModel\n",
    "from typing import Callable, List, Optional, Tuple, Union, Dict\n",
    "from torch import nn\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPast, CausalLMOutputWithPast\n",
    "from transformers.cache_utils import Cache\n",
    "from vllm import LLM\n",
    "from vllm import SamplingParams\n",
    "\n",
    "\n",
    "def register():\n",
    "    from vllm import ModelRegistry\n",
    "    from decoder import XCodeDecForCausalLM, XCodeDecConfig  # Import decoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodedec\", XCodeDecConfig)  # Register decoder config\n",
    "    ModelRegistry.register_model(\"XCodeDecModelForCausalLM\", XCodeDecForCausalLM)  # Register decoder model\n",
    "    from middle_model import XCodeForCausalLM, XCodeMiddleConfig  # Changed to absolute import\n",
    "\n",
    "    AutoConfig.register(\"xcodemiddle\", XCodeMiddleConfig)\n",
    "    ModelRegistry.register_model(\"XCodeMiddleModelForCausalLM\", XCodeForCausalLM)\n",
    "\n",
    "    from encoder import XCodeEncForCausalLM, XCodeEncConfig  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeenc\", XCodeEncConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncModelForCausalLM\", XCodeEncForCausalLM)  # Register encoder model\n",
    "\n",
    "    from enc_dec import XCodeEncDecConfig, XCodeEncDecForCausalLM  # Import encoder classes\n",
    "\n",
    "    AutoConfig.register(\"xcodeencdec\", XCodeEncDecConfig)  # Register encoder config\n",
    "    ModelRegistry.register_model(\"XCodeEncDecModelForCausalLM\", XCodeEncDecForCausalLM)  # Register encoder model\n",
    "\n",
    "register()\n",
    "\n",
    "# enc_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"encoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.1,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True,  # Disable CUDA graphs for debugging\n",
    "# )\n",
    "\n",
    "\n",
    "# middle_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_middle_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",\n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"middle\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "enc_dec_model = LLM(\n",
    "    model=\"/project/phan/kt477/OppyAI_backend/qwen7b_enc_dec_clean_no_att_on_client_dec\",\n",
    "    # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "    # skip_tokenizer_init=True,\n",
    "    # task=\"reward\",\n",
    "    enable_prompt_embeds=True,\n",
    "    # model_part=\"encoder\",  # Set to False for encoder\n",
    "    gpu_memory_utilization=0.2,\n",
    "    max_model_len=1024,\n",
    "    tensor_parallel_size=1,\n",
    "    enforce_eager=True\n",
    ")\n",
    "\n",
    "# dec_model = LLM(\n",
    "#     model=\"/project/phan/kt477/OppyAI_backend/qwen7b_dec_clean_no_att_on_client\",\n",
    "#     # model=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "#     tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "#     # skip_tokenizer_init=True,\n",
    "#     # task=\"reward\",    \n",
    "#     enable_prompt_embeds=True,\n",
    "#     model_part=\"decoder\",  # Set to False for encoder\n",
    "#     gpu_memory_utilization=0.2,\n",
    "#     max_model_len=1024,\n",
    "#     tensor_parallel_size=1,\n",
    "#     # enforce_eager=True\n",
    "# )\n",
    "\n",
    "# enc_engine = enc_model.llm_engine\n",
    "# dec_engine = dec_model.llm_engine\n",
    "# middle_engine = middle_model.llm_engine\n",
    "enc_dec_engine = enc_dec_model.llm_engine\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-Coder-7B-Instruct\", trust_remote_code=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "request_id = 0\n",
    "# prompt_embeds  = torch.load(\"test_py_files/prompt_embeds.pt\").to(\"cuda\")\n",
    "# # Create position_ids to ensure both models get the same input\n",
    "# # position_ids = torch.arange(0, prompt_embeds.shape[1], device=\"cuda:1\").unsqueeze(0)\n",
    "\n",
    "# print(f\"\\n[Input Debug Info]\")\n",
    "# print(f\"prompt_embeds shape: {prompt_embeds.shape}\")\n",
    "# print(f\"position_ids shape: {position_ids.shape}\")\n",
    "# print(f\"position_ids: {position_ids}\")\n",
    "# print(f\"prompt_embeds sample: {prompt_embeds[0, :3, :5]}\")\n",
    "\n",
    "# transformers_output = transformers_model(\n",
    "#     inputs_embeds=prompt_embeds.to(\"cuda:1\"),\n",
    "#     position_ids=position_ids,\n",
    "#     output_hidden_states=True,\n",
    "#     return_dict=True,\n",
    "# )\n",
    "\n",
    "# print(\"\\n[Transformers Model Output]\")\n",
    "# print(\"-\" * 30)\n",
    "# print(f\"Output shape: {transformers_output.last_hidden_state.shape}\")\n",
    "# print(f\"First few values: {transformers_output.last_hidden_state[0, :3, :5]}\")\n",
    "# print(transformers_output)\n",
    "# outputs = model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": prompt_embeds.to(\"cuda:0\"),\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# import time\n",
    "# start_time = time.time()\n",
    "# print(\"Adding request to encoder engine...\")\n",
    "# i = 0 \n",
    "\n",
    "prompt = \"write a quick sort algorithm.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(\"cuda:0\")\n",
    "# # input ids to list of integers\n",
    "input_ids = model_inputs.input_ids[0].tolist()\n",
    "tokens = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "def send_intermediate_states(_, __, output, prefix = \"client\"):\n",
    "    hidden_states, residual = output\n",
    "    # Right now, save the hidden states and residual to file\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "\n",
    "    torch.save(hidden_states, f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    torch.save(residual, f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = pickle.dumps(hidden_states.to(\"cpu\"))\n",
    "    # serialized_residual = pickle.dumps(residual.to(\"cpu\"))\n",
    "    # node.isend(serialized_hidden_states, tag=0, latency=None).wait()\n",
    "    # node.isend(serialized_residual, tag=0, latency=None).wait()\n",
    "    # logger.debug(f\"Sent hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent) and residual: {residual.shape} ({len(serialized_residual)} bytes sent)\")\n",
    "\n",
    "\n",
    "def recv_intermediate_states(_, input, prefix = \"client\"):\n",
    "    positions, _, _ = input\n",
    "    device = positions.device\n",
    "\n",
    "    # Load the hidden states and residual from file\n",
    "    if os.path.exists(\"test_py_files\") is False:\n",
    "        os.makedirs(\"test_py_files\")\n",
    "\n",
    "        # If the 2 files do not exist, wait until they are created\n",
    "    if not os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") or not os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\"):\n",
    "        while not (os.path.exists(f\"test_py_files/{prefix}_hidden_states_tensor.pt\") and os.path.exists(f\"test_py_files/{prefix}_residual_tensor.pt\")):\n",
    "            pass\n",
    "                # time.sleep(10)  # Wait for 10 seconds before checking again\n",
    "    i = 0\n",
    "    # Retry loading until successful\n",
    "    while i < 5:\n",
    "        try:\n",
    "            hidden_states = torch.load(f\"test_py_files/{prefix}_hidden_states_tensor.pt\").to(device)\n",
    "            residual = torch.load(f\"test_py_files/{prefix}_residual_tensor.pt\").to(device)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    \n",
    "    # Delete the files after loading\n",
    "    os.remove(f\"test_py_files/{prefix}_hidden_states_tensor.pt\")\n",
    "    os.remove(f\"test_py_files/{prefix}_residual_tensor.pt\")\n",
    "\n",
    "\n",
    "    # serialized_hidden_states = node.irecv(tag=0).wait()\n",
    "    # serialized_residual = node.irecv(tag=0).wait()\n",
    "    # hidden_states = pickle.loads(serialized_hidden_states).to(device)\n",
    "    # residual = pickle.loads(serialized_residual).to(device)\n",
    "    # logger.debug(f\"Got hidden_states: {hidden_states.shape} ({len(serialized_hidden_states)} bytes sent), residual: {residual.shape} ({len(serialized_residual)} bytes sent) and positions {positions.shape}\")\n",
    "\n",
    "    return positions, hidden_states, residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9bf8de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8db1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x155533e69b10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.enc.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"client\"))\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[-1].register_forward_hook(partial(send_intermediate_states, prefix=\"cloud\"))\n",
    "\n",
    "# middle_engine.model_executor.driver_worker.model_runner.model.middle.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"client\"))\n",
    "enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[0].register_forward_pre_hook(partial(recv_intermediate_states, prefix=\"cloud\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a91a9db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XCodeEncDecForCausalLM(\n",
       "  (enc): XCodeEncModel(\n",
       "    (embed_tokens): VocabParallelEmbedding(num_embeddings=152064, embedding_dim=3584, org_vocab_size=152064, num_embeddings_padded=152064, tp_size=1)\n",
       "    (layers): ModuleList(\n",
       "      (0): XCodeDecoderLayer(\n",
       "        (self_attn): XCodeAttention(\n",
       "          (qkv_proj): QKVParallelLinear(in_features=3584, output_features=4608, bias=True, tp_size=1, gather_output=False)\n",
       "          (o_proj): RowParallelLinear(input_features=3584, output_features=3584, bias=False, tp_size=1, reduce_results=True)\n",
       "          (rotary_emb): RotaryEmbedding(head_size=128, rotary_dim=128, max_position_embeddings=32768, base=1000000.0, is_neox_style=True)\n",
       "          (attn): Attention(head_size=128, num_heads=28, num_kv_heads=4, scale=0.08838834764831845, backend=FlashAttentionImpl)\n",
       "        )\n",
       "        (mlp): XCodeMLP(\n",
       "          (gate_up_proj): MergedColumnParallelLinear(in_features=3584, output_features=37888, bias=False, tp_size=1, gather_output=False)\n",
       "          (down_proj): RowParallelLinear(input_features=18944, output_features=3584, bias=False, tp_size=1, reduce_results=True)\n",
       "          (act_fn): SiluAndMul()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "        (post_attention_layernorm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): PPMissingLayer()\n",
       "  )\n",
       "  (dec): XCodeDecModel(\n",
       "    (embed_tokens): PPMissingLayer()\n",
       "    (layers): ModuleList(\n",
       "      (0): DummyDecoderLayer()\n",
       "    )\n",
       "    (norm): RMSNorm(hidden_size=3584, eps=1e-06)\n",
       "  )\n",
       "  (lm_head): ParallelLMHead(num_embeddings=152064, embedding_dim=3584, org_vocab_size=152064, num_embeddings_padded=152064, tp_size=1)\n",
       "  (logits_processor): LogitsProcessor(vocab_size=152064, org_vocab_size=152064, scale=1.0, logits_as_input=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b588fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_engine.add_request(request_id=\"123\", prompt={\n",
    "        \"prompt_token_ids\": input_ids, \n",
    "    }, params=SamplingParams(max_tokens=2048, temperature=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e32d7ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3809, -0.1367, -0.2852,  ...,  0.3066, -0.1533,  0.1250],\n",
      "        [-0.3594, -0.1338, -0.2285,  ..., -0.1572, -0.1719,  0.1963],\n",
      "        [-0.1992, -0.0483, -0.1216,  ..., -0.0113, -0.0449,  0.1367],\n",
      "        ...,\n",
      "        [-0.2207, -0.0586, -0.0820,  ...,  0.0518, -0.1206, -0.0496],\n",
      "        [ 0.0280, -0.0991, -0.1699,  ..., -0.0068, -0.0752, -0.0703],\n",
      "        [-0.0737, -0.0249,  0.0583,  ...,  0.0388, -0.0270,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742, -0.0115,  0.2324,  ...,  0.0344, -0.3594, -0.0618],\n",
      "        [-0.1201, -0.2344, -0.0623,  ..., -0.0669, -0.0030,  0.1045],\n",
      "        [-0.1182,  0.0201, -0.1138,  ..., -0.0072, -0.1406,  0.0630],\n",
      "        ...,\n",
      "        [-0.1846,  0.1387,  0.0173,  ...,  0.0659,  0.0256,  0.0140],\n",
      "        [-0.1406,  0.0542,  0.0212,  ...,  0.0183, -0.0200, -0.0776],\n",
      "        [-0.1357,  0.0134,  0.1758,  ..., -0.0275,  0.0166, -0.0791]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([35, 3584]) and residual: torch.Size([35, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.1000e+01,  1.6094e+00,  1.1406e+00,  ...,  3.8125e+00,\n",
      "          1.4188e+01, -3.4688e+00],\n",
      "        [-1.1875e+01,  2.0469e+00,  1.7500e+00,  ...,  1.9688e+00,\n",
      "          1.4625e+01, -3.8438e+00],\n",
      "        [-1.0500e+01,  2.0000e+00,  1.3125e+00,  ...,  3.7500e+00,\n",
      "          1.4375e+01, -3.2500e+00],\n",
      "        ...,\n",
      "        [-9.2500e+00, -1.8125e+00, -1.1875e+00,  ..., -1.7266e+00,\n",
      "         -4.3125e+00, -7.3438e+00],\n",
      "        [ 7.8125e-01, -1.2656e+00, -7.8125e-03,  ..., -4.5625e+00,\n",
      "         -7.5938e+00, -1.0375e+01],\n",
      "        [ 9.8438e-01, -1.3281e-01,  6.4062e-01,  ..., -3.1562e+00,\n",
      "         -5.5000e+00, -1.0125e+01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9062, -7.0000, -3.9844,  ...,  8.5625, -4.0312, 10.8125],\n",
      "        [-5.2188, -8.6875, -5.5625,  ..., 10.9375, -4.8438, 11.3750],\n",
      "        [-5.4062, -8.0000, -4.7188,  ..., 10.0000, -4.1250, 10.7500],\n",
      "        ...,\n",
      "        [ 0.9414, -1.9375,  4.8125,  ...,  0.4766, -1.8516, -4.4688],\n",
      "        [ 2.2031,  1.0703,  0.4805,  ...,  1.6719,  1.9453,  2.4688],\n",
      "        [ 0.6523,  0.8906,  0.7188,  ...,  2.7031,  3.6719,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure', token_ids=(39814,), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100470.9987304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00029605500458274037, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0027, -0.0082, -0.0461,  ..., -0.0491,  0.1787,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0121,  0.0410, -0.0298,  ...,  0.3633, -0.3359,  0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  1.3672, -0.9336,  ..., -7.7188, -5.8438,  9.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1128,  0.9531,  0.7695,  ...,  1.2891, -1.1250, -0.0064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure!', token_ids=(39814, 0), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0272264, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0006217659974936396, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0192, -0.0374,  0.0498,  ...,  0.0044,  0.1611, -0.0530]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0120, -0.2891, -0.0610,  ...,  0.6523,  0.1826, -0.4238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250, -5.4375, -6.4062,  ..., -1.7031, -0.2949, -7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5898,  1.6641, -1.6484,  ...,  2.1875,  0.9297,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick', token_ids=(39814, 0, 17251), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0519795, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0007214530050987378, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0291,  0.0728,  0.0144,  ..., -0.0044,  0.0299, -0.0332]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2344,  0.2383,  0.0127,  ...,  0.2158,  0.3789,  0.0071]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.2500,  -0.7734,  -5.0312,  ...,   7.0000, -17.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.8906, -0.3125, -1.7188,  ...,  1.7656,  0.4980, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort', token_ids=(39814, 0, 17251, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.075427, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0008100990089587867, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3301, -0.0713,  0.0332,  ..., -0.0085, -0.2246, -0.0015]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0991,  0.0109,  0.1865,  ...,  0.1963, -0.3438, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   5.9062,  -9.1250,  ...,   3.5938,  -8.8125,   2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3906,  1.1953,  1.8438,  ..., -1.9766, -0.7305, -0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is', token_ids=(39814, 0, 17251, 3378, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.0987573, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0008905900031095371, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1357,  0.0566, -0.1523,  ..., -0.1436,  0.0110,  0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0408, -0.1445,  ..., -0.2314,  0.0510, -0.0215]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250,  0.7656, -3.4375,  ...,  8.6875,  7.1562,  1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320,  0.5430,  1.5625,  ..., -1.4062, -2.8438, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a', token_ids=(39814, 0, 17251, 3378, 374, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.122058, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0009659620118327439, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0469,  0.0105,  ..., -0.1279,  0.0559,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0762,  0.3828,  0.0613,  ..., -0.0522,  0.0352, -0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.5312, -2.3438,  5.1250,  ..., -1.6250,  2.8281, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0474,  0.8672, -1.6094,  ..., -2.1406, -1.1719,  0.4199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.145442, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0010470440029166639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569, -0.1079, -0.0417,  ..., -0.1465,  0.0635,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0303,  0.1309, -0.1641,  ..., -0.1768, -0.2598, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -1.1875,  4.4062,  ...,  1.3906, -0.9727, -7.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3066,  1.6953, -0.7852,  ..., -1.0469,  1.6719,  0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.1688235, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0011241190077271312, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0425,  0.0289,  0.0189,  ...,  0.0046,  0.0425, -0.0072]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.2139, -0.1885,  ...,  0.0977,  0.0295, -0.0557]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.1250, -2.7656,  9.2500,  ...,  2.7031,  3.0312, -7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9688,  2.0000, -2.4688,  ..., -2.5156,  1.9688, -2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.1924279, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0012009230122203007, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0131, -0.0173, -0.1572,  ..., -0.2637,  0.0237,  0.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0776, -0.0243,  ..., -0.0884, -0.1836, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.0625,  5.1250, -0.5625,  ..., -1.6250, -1.0391,  0.0596]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141,  0.8672,  1.4062,  ..., -1.2109,  1.7266, -0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2159555, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0012780480028595775, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0045, -0.1035,  ..., -0.2236, -0.1484, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0137, -0.0820,  0.0376,  ..., -0.0503, -0.1807, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4531,  3.7188, -2.8125,  ..., -2.5625, -7.0625, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318,  0.0464, -2.6719,  ..., -0.2471,  2.9531, -1.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2396612, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0013540799991460517, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0889,  0.2100,  0.0236,  ..., -0.4746, -0.0308, -0.0280]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.0361, -0.3242,  ..., -0.2930, -0.0347,  0.0962]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4844, -2.8750,  ...,  0.4727, -2.7656,  5.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0266, -0.6133,  0.0542,  ..., -2.4688, -0.2949, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.2630868, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001432798002497293, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0217,  0.1484, -0.0442,  ..., -0.1562,  0.1201, -0.0481]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513, -0.2578, -0.3359,  ..., -0.1416, -0.1201,  0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5000,  -2.6250,   0.0625,  ...,  -2.0625,  -1.0000,  -5.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984, -1.3516, -0.2773,  ..., -2.2969, -0.5586, -1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.286636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0015120370080694556, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0251,  0.1201, -0.0498,  ...,  0.1187, -0.0889, -0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2324,  0.0469,  0.2100,  ...,  0.1660, -0.7227, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3125,   7.8438, -11.9375,  ...,   1.8906,   4.7812,   2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6094,  0.9219, -0.2070,  ..., -2.1875, -0.5977, -1.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.3101912, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0015883000014582649, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221, -0.0654, -0.0058,  ..., -0.0238, -0.0464,  0.0024]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3223,  0.1816,  0.1738,  ..., -0.2676, -0.3418, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2812, -1.3906, -0.8555,  ..., -5.4375,  0.4297, -9.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1338,  0.4531,  0.3574,  ..., -3.8281,  0.7227, -1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.333247, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0016799720033304766, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0339,  0.1104,  0.0608,  ..., -0.0498, -0.0679, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190,  0.1826,  0.2754,  ..., -0.0071, -0.0869,  0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0781,  2.0469,  1.7422,  ..., -2.0625, -2.2344, -6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4023, -2.9062,  0.4297,  ..., -0.5312, -3.3125,  1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.356373, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0017573070072103292, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1152, -0.0493, -0.0269,  ..., -0.0530, -0.1582, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996,  0.0471,  0.0996,  ..., -0.1338,  0.0251, -0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  6.0625,  8.2500,  ..., -0.6406,  0.6016, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8516, -3.3125, -1.7188,  ...,  0.6367, -6.2500, -0.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-con', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.3794744, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0018336810026085004, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0549,  0.0278,  0.0688,  ...,  0.1030, -0.0991, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001,  0.0025, -0.0046,  ..., -0.0500,  0.0801,  0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.2344, -2.8125, 13.6250,  ...,  2.9844,  0.5117, -4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[  4.7812, -10.5625,  -7.3438,  ...,   8.2500,  -7.2812,   9.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4026031, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001910765000502579, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0281,  0.2109,  0.1777,  ..., -0.2393,  0.1064,  0.0537]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0084, -0.0649, -0.1504,  ...,  0.0684,  0.1465, -0.0255]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.1562,  3.3125,  1.9453,  ..., -2.6875,  0.8320, -0.0254]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4863, -2.6250, -0.3398,  ..., -0.1836, -0.1660, -2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.425549, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.001988279997021891, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0171,  0.0381,  0.0200,  ..., -0.3203, -0.1006, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2793, -0.0178, -0.3613,  ..., -0.2373, -0.0068, -0.2305]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.3906,  3.1094, -3.0781,  ..., -3.6875, -3.8750,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.8516,  0.4258,  ..., -0.1582, -0.1562, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4486415, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00206446299853269, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0605, -0.0508, -0.0071,  ..., -0.1572, -0.0391, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.2188, -0.3281,  ..., -0.0967, -0.0654,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5469, -4.4062, -7.3125,  ..., -1.3750,  0.4453, -2.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750, -2.2188, -0.8594,  ...,  0.7617, -0.5078,  0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4719253, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002141076998668723, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2480,  0.0586,  0.0417,  ..., -0.1514, -0.1611, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1201, -0.2754,  0.1079,  ...,  0.3027, -0.2490, -0.2334]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.3438,  2.1406, -6.0938,  ..., -3.3125,  0.4023,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344,  0.2676, -1.1641,  ..., -0.2275, -1.4844, -0.5898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.4950635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0022199049999471754, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0208,  0.0283, -0.1128,  ..., -0.1221, -0.2100,  0.0260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0019, -0.3340,  0.0630,  ...,  0.0217, -0.0251, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6719,  4.0312,  3.5469,  ...,  0.4219, -7.0938,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3613, -0.6719, -0.9648,  ..., -0.2852, -0.2012,  0.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements.', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5180864, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002296788996318355, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0928,  0.0143,  ..., -0.0520, -0.0308, -0.0251]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1328, -0.0737,  0.1079,  ...,  0.0564, -0.0486,  0.0104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  -4.7188,  -3.1406,  ...,  -1.8594,   3.2188,   1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0742,  1.1719, -1.4844,  ...,  1.6797, -1.1250, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here', token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5413716, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0023726219951640815, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.0742,  0.1875,  ...,  0.1963,  0.0049, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.3594,  0.3066,  ...,  0.6914, -0.0630,  0.0020]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9375, -4.4062, -3.4688,  ...,  0.6055,  0.5078,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1328, -0.0938, -0.3125,  ..., -0.5977, -0.5781, -0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.564856, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0024494859972037375, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.1660,  0.0291,  ...,  0.1445,  0.1807,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0322, -0.5820,  0.3105,  ...,  0.1426, -0.1953,  0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.2500, -1.9688, -0.6602,  ...,  7.7812, 13.3750,  4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6094, -1.1797,  0.6680,  ...,  0.2520, -1.7812,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.5878582, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0025277130043832585, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0071,  0.0198,  ..., -0.0354,  0.0918,  0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2500,  0.1865,  0.1719,  ..., -0.1235, -0.0140, -0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -1.2188,  8.9375,  ...,  3.7812, 11.2500, -7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -0.4648,  1.4531,  ..., -2.2031, -0.1543, -0.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6110518, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.002603544999146834, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0054,  0.1836, -0.0796,  ..., -0.2305, -0.0225, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.0461, -0.1797,  ..., -0.1689, -0.3262, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.1250, -7.0312,  4.4375,  ..., -2.1719, 15.7500, -6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3711,  1.1406,  0.5586,  ..., -2.2812,  1.1797, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6342702, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0026807099930010736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2256,  0.1484, -0.0942,  ..., -0.2090, -0.1494, -0.0981]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0972, -0.1553,  0.3164,  ..., -0.5195,  0.1562,  0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750, -2.0781, -2.6875,  ..., -5.2500,  3.3750,  5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5820,  0.4883,  0.1885,  ..., -0.9883, -0.0605, -0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.657606, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0027617220039246604, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0796,  0.0552,  0.0586,  ..., -0.1504,  0.0371, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3984, -0.1128,  0.0918,  ..., -0.5859,  0.1475, -0.0282]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188, -3.9375,  4.3750,  ..., -2.2812, 13.6250,  0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320, -0.4180, -1.3047,  ..., -0.3184,  0.2207,  0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.6809168, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0028383860044414178, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608,  0.1113, -0.0078,  ..., -0.0613,  0.0073, -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0302, -0.0449,  ..., -0.1309, -0.0767, -0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  5.1875, -12.6875,   2.7500,  ...,  -4.8438,  12.1875,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6875, -0.0791, -0.5703,  ...,  0.3262,  0.0928, -0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.703982, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0029271819948917255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0061,  0.1426, -0.1338,  ..., -0.0840,  0.1426, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2695,  0.4844,  0.2363,  ...,  0.0752,  0.1904,  0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.6875,  -5.4375,  -3.0469,  ...,   2.0312, -12.5000,   3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0527,  0.5273,  ...,  2.8906, -4.0625,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7270362, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003004126003361307, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773, -0.0420,  0.0461,  ..., -0.0898, -0.1167,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0121,  0.1641,  ...,  0.1221, -0.2871, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375, -0.5859, -3.1562,  ...,  1.2500, -4.7812,  1.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0508, -2.3438, -2.9375,  ..., -1.9062,  3.4375, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7500324, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003080588998273015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1768,  0.1299,  0.0986,  ..., -0.4180,  0.0547,  0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.0549, -0.2246,  ..., -0.3633, -0.0918,  0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9844, -6.4375, -2.5625,  ..., -2.0469,  2.0000,  5.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3438,  0.4141,  0.4551,  ..., -0.6602,  0.1260,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.772986, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00315742299426347, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1074, -0.0004, -0.0747,  ..., -0.1709, -0.0476, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2061,  0.0786,  0.0610,  ..., -0.3398, -0.0549,  0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  0.2891,  -9.6875,   2.4062,  ..., -11.1875,   5.6250,   4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0234, -0.5703, -0.4453,  ..., -0.1680,  0.4395,  0.2695]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.7963095, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0032336759904865175, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2256,  0.0708,  0.0442,  ..., -0.1416,  0.0732,  0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.7461, -0.4551,  ..., -0.3789, -0.3008,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -0.2148, -1.3281,  ...,  5.1250,  2.9688,  1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6719,  0.0737,  0.0420,  ...,  0.1914,  0.5703, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8192992, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0033186259970534593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0378,  0.0325,  0.1377,  ...,  0.1318,  0.0771, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0053, -0.3184,  0.1182,  ..., -0.0942,  0.0986, -0.0564]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.8438, -0.6016,  ...,  1.7266,  8.4375,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -2.4219,  0.1504,  ...,  0.2441,  1.5000, -2.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8426375, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003404848001082428, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0527, -0.0537, -0.0332,  ...,  0.1357,  0.1357, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.3320, -0.0684,  ..., -0.3105, -0.2324, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.8906,  1.5859,  ..., -0.4844, 10.5625,  4.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6875, -0.1396,  1.5156,  ..., -0.2988,  2.1406, -2.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8658636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003481532010482624, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0703, -0.0664,  ...,  0.0649, -0.0942, -0.0410]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4785, -0.0016, -0.0547,  ..., -0.3652, -0.3027, -0.3652]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1250,   5.4062,  -2.8594,  ...,   6.4062,   5.8438,   8.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670, -1.7578,  1.2500,  ...,  0.0427, -0.5273, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.8890007, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00355754500196781, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0211,  0.2021,  0.0226,  ...,  0.0674,  0.0474, -0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2754, -0.1377, -0.0615,  ..., -0.3223,  0.1465, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   3.3906,  -1.9141,  ...,   8.6875,  16.1250,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734, -2.6250,  1.4531,  ..., -1.5547,  1.7500, -2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9119768, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0036368140135891736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1211,  0.0825, -0.0918,  ..., -0.0674, -0.0420, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2090, -0.1060,  0.0376,  ..., -0.3789, -0.3027, -0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875,  2.0000, -8.1250,  ...,  6.7812,  5.3750, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8984,  1.1328, -3.5781,  ..., -1.1172, -3.4219, -3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9350235, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003712356017786078, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0364,  0.1348, -0.2246,  ..., -0.0752,  0.0830, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.6328,  0.2422,  ...,  0.1455,  0.1768,  0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   0.0508,  -1.0703,  ...,   6.5625,  -3.6719,   1.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4258,  2.5156,  2.0156,  ...,  3.1719,  3.1250, -3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9583259, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003788118017837405, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0371, -0.0654,  ..., -0.1436, -0.0354,  0.1807]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099,  0.0781, -0.1099,  ...,  0.0518, -0.1982, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,   7.5312,  -2.5938,  ...,   4.7812,  -0.6328,  -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3965,  0.2910,  0.7070,  ..., -2.0469,  2.5156, -3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100471.9816234, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.003869942025630735, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0515,  0.0093,  0.0014,  ...,  0.0106,  0.0194, -0.0957]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4043, -0.1426, -0.0211,  ...,  0.4160,  0.1953, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.5938,   3.4062,  ...,   5.7500,  -9.3125,   6.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375,  2.4062, -2.1406,  ...,  0.2617, -0.6992,  0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0046003, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00394636501732748, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0352, -0.0271,  0.0535,  ...,  0.0295,  0.0220, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0942, -0.0698,  0.0361,  ..., -0.0674,  0.3203, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -1.1797, -1.3047,  ..., -1.3281,  0.5547,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2656, -2.5156,  0.1030,  ...,  2.2344,  1.0469, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n   \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0276833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0040233900072053075, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1089,  0.0002, -0.1611,  ...,  0.1235,  0.1650, -0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.1377,  0.1318,  ...,  0.2158,  0.2412, -0.4043]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.8750,  -0.9766, -11.1875,  ...,   4.2500,   0.0684,  -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5469,  0.7344, -2.0938,  ...,  0.1445, -0.8789, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0511503, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0041028490086318925, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297, -0.0359, -0.1553,  ..., -0.0097,  0.0066, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.3652, -0.1445,  ..., -0.1904,  0.0023, -0.2832]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   0.7422,  -3.4062,  ...,   2.4219,   1.2109,  -1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5156,  0.7266,  0.5820,  ...,  0.5391, -1.1094, -0.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0747826, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004191194006125443, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1260, -0.1030,  0.0164,  ...,  0.0479, -0.0518, -0.0457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0618, -0.0014, -0.0840,  ...,  0.1050,  0.0249,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.0000,  6.2500, -0.5352,  ...,  0.0820, -0.2031,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.2812,  2.4062,  0.1064,  ..., -0.8672,  0.4922, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.0982068, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00426829801290296, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0200,  0.0139,  0.0134,  ...,  0.0640, -0.0173, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4961, -0.0151,  0.0461,  ...,  0.4141,  0.0786,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -9.5625, -16.6250,  ...,   3.1406,  -3.1562,  11.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1226,  1.6484, -3.5312,  ..., -0.0422, -1.0625,  1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.121785, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004347126014181413, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1104,  0.0469,  0.0256,  ..., -0.0569,  0.2324,  0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952,  0.0908, -0.0830,  ..., -0.1973,  0.1484, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -8.8750, -10.1250,  ...,   1.9844,  -5.9062,  -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8555,  0.3262, -0.0024,  ...,  0.4961, -0.5938,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <=\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1449656, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004423138016136363, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605,  0.0312, -0.0762,  ..., -0.1406, -0.0092, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.3398, -0.1055,  ..., -0.3320, -0.0569, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,   4.8750,  -0.9688,  ...,  12.7500,   2.0000,   2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8984,  0.1836, -0.2832,  ..., -1.2031,  0.1089, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1684923, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004499341011978686, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0022,  0.0003,  ..., -0.1562,  0.0737,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0249, -0.0549,  0.1099,  ...,  0.0383,  0.1328, -0.1118]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -0.2578,  -6.4688,  ...,   6.7500,  -1.9141,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5312, -4.3125,  0.3516,  ...,  2.0469, -2.4844, -9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.1921282, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004575845014187507, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0040, -0.0396,  0.0049,  ..., -0.0786,  0.1328, -0.0535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0157, -0.0581,  0.0320,  ..., -0.0391,  0.0771, -0.0239]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.2500,   0.1719,  -2.8438,  ...,   8.8750, -10.1250,   9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3242,  1.0859, -0.1387,  ..., -0.9609,  0.4863, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.215716, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004653601004974917, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0076,  0.0850, -0.0166,  ...,  0.1348,  0.0060, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2188, -0.0035,  0.0337,  ...,  0.0801,  0.0713, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  5.1250, -6.6250,  ..., -2.2500, -2.6250, 14.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625, -0.1221, -2.2812,  ..., -1.1250,  1.0859, -6.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2393136, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004730284999823198, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0262, -0.0703,  ...,  0.0608,  0.1074, -0.0195]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2402, -0.1729,  0.0820,  ...,  0.0520,  0.1196, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.9062, -4.7500,  ...,  5.5312,  4.5312,  0.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0859,  0.1079, -0.7383,  ...,  0.9961, -1.2109, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2628932, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0048162869934458286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811, -0.0742, -0.0728,  ...,  0.0649, -0.0278, -0.1128]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3320, -0.1982,  0.1729,  ...,  0.0217, -0.1367, -0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -1.9844, -2.9531,  ...,  6.9688,  7.0625,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2344, -0.8242,  0.2354,  ...,  4.6250, -2.6719,  1.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.2864337, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0048924699949566275, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610,  0.0095, -0.0073,  ..., -0.1191, -0.1064, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4199,  0.0608,  0.0483,  ...,  0.2793,  0.1523,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.3125,  -6.2812,  ...,  -2.1719,  -7.3750,  10.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0703, -1.3359, -0.6758,  ...,  0.2129, -0.1943, -0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.309671, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.004969403991708532, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0505,  0.0791,  0.0210,  ...,  0.0186,  0.0669,  0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1836, -0.0796, -0.0322,  ..., -0.1196,  0.1338, -0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  3.4531,  0.5977,  ..., -2.2031,  1.4062, 15.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6719,  3.5469, -1.4219,  ...,  5.4062,  2.7656, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n   \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3338382, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0050487929984228685, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0791, -0.0113, -0.1494,  ...,  0.0728,  0.0635,  0.0063]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.0649,  0.0471,  ...,  0.1387,  0.1504, -0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8125,  0.2617, -1.7188,  ..., -0.1914, -7.0938,  0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5352,  0.6797, -0.1406,  ...,  0.9141, -0.4004, -2.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3574297, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0051258169987704605, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128, -0.1221, -0.1494,  ..., -0.0342,  0.1187, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1973, -0.1973, -0.2168,  ..., -0.4258, -0.0933, -0.1270]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2500, -2.0156,  3.0781,  ...,  3.7969, -8.7500, 10.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  1.4141,  0.4004,  ...,  1.6953, -0.1191, -1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.3809016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005201528998441063, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1152,  0.3262, -0.0530,  ...,  0.1611, -0.0366, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2793,  0.0635,  0.1309,  ...,  0.0723, -0.0010, -0.4453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  3.1406, -1.8672,  ..., -0.1328, -4.7812,  9.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4688,  0.0273, -1.6484,  ..., -0.0264,  1.5703, -7.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4044967, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005278092998196371, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0255,  0.0459, -0.0928,  ...,  0.0693,  0.1143, -0.0089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441, -0.0613,  0.0542,  ...,  0.0444,  0.1621, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -0.7227,   2.1562,  ...,   2.3438, -10.6875,   0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8047, -1.6641,  1.2422,  ...,  0.9023, -2.5625, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4278271, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005353714994271286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0264, -0.1318,  0.0425,  ..., -0.1309, -0.0625, -0.0208]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0017,  0.0752,  ..., -0.0400, -0.1299,  0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4688,  1.2266,  7.0625,  ..., -7.3438, -0.1250, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7539, -0.5898,  0.2363,  ...,  0.1406, -0.5000, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.451619, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0054418009967776015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0884,  0.0503,  ...,  0.0796,  0.0630, -0.0508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0645, -0.1299, -0.1611,  ...,  0.0199,  0.2598, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -2.0938, -3.3438,  ...,  3.1562,  3.2812, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7188, -0.1299, -1.4922,  ...,  3.1875, -1.2422,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.4751594, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00551921600708738, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0693,  0.0137,  0.0258,  ..., -0.0591, -0.1709, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4434,  0.0918,  0.1128,  ...,  0.2871,  0.1226,  0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2031,  5.8125, -4.7500,  ..., -6.5312, -6.3125,  4.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -2.2812,  2.7188,  ...,  2.4844,  2.3438, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.49884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005594567002844997, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0117,  0.0542, -0.0635,  ..., -0.1992,  0.0236, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0903, -0.1758, -0.0938,  ...,  0.2012,  0.1436,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.6875,   7.3125,  -0.1016,  ...,   3.0156,  -3.1875,   1.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.3125,  2.5469, -0.0684,  ...,  0.0801,  0.7930, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.522135, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005669958001817577, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0562, -0.0177,  0.0415,  ...,  0.0669, -0.0396, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453,  0.0640,  0.0113,  ...,  0.3750,  0.0339,  0.1543]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -6.8125, -9.9375,  ..., -5.2500,  0.6172, 22.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4531,  3.7500, -7.3750,  ...,  1.2109,  2.5000,  3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5456142, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005748786003096029, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0850,  0.0248,  0.0327,  ..., -0.0469,  0.1768, -0.0121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0571,  0.1309, -0.0518,  ..., -0.2188,  0.0767,  0.0056]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0312, -1.0156, -2.2656,  ..., -8.3125, -3.6875,  6.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5977, -0.3789, -3.9375,  ...,  0.2461,  2.6562, -0.2490]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) //\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5690484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005824327003210783, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0967,  0.0957, -0.0747,  ..., -0.0143, -0.0215, -0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.0679, -0.3125,  ...,  0.2168, -0.0825, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.8125,  0.3984,  2.1875,  ...,  9.3125,  0.4258,  5.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5000,  0.2070, -2.8125,  ...,  1.7031,  0.8867, -0.0172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.5928109, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.005901632001041435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0991,  0.0004,  ..., -0.0277, -0.0236,  0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1250, -0.1172,  0.1328,  ..., -0.0698,  0.1113, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2812, -4.7812, -6.5625,  ...,  6.0938, -0.0693,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8281, -6.8125, -3.3594,  ...,  4.4062, -2.8750, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6163988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00597759400261566, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0742,  0.1021,  ...,  0.0234, -0.0135, -0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0231,  0.0277,  0.0439,  ...,  0.0679,  0.0693, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8750,   1.5938,  -4.5625,  ...,  -5.5312,   0.5156,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781,  0.6641, -1.4922,  ...,  0.6523, -0.1035, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6400266, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0060524040018208325, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[0.0342, 0.0197, 0.0522,  ..., 0.1982, 0.0118, 0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1953, -0.1738,  0.0131,  ..., -0.0781,  0.1279, -0.0933]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   4.2812,  -3.2188,  ..., -10.5000,  -5.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3633,  1.7344, -0.6094,  ..., -0.3887, -0.4805, -4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.6672337, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006129269007942639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371,  0.0522, -0.1157,  ...,  0.0869,  0.0635, -0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680, -0.0801,  0.0569,  ...,  0.0364,  0.0986, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9961, -0.4922,  3.6562,  ...,  0.3867,  1.7578,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  0.7578, -2.2031,  ...,  3.7031, -1.2266, -0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.690865, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006205672994838096, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2109, -0.0269, -0.0122,  ...,  0.0684, -0.1260, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2363,  0.2080, -0.0077,  ..., -0.1670, -0.1992,  0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   2.0469,  11.0000,  ...,  -3.8438,   9.9375,   2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250, -0.2061, -0.2188,  ...,  0.1582,  1.3828, -3.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7146187, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006281584996031597, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1187, -0.0762,  0.0247,  ...,  0.1279,  0.0747, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0967, -0.1377, -0.0854,  ..., -0.0051,  0.3008, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.1250,   4.9375,  15.5625,  ..., -10.8750,   5.1875,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6367,  0.8945, -3.2031,  ...,  0.3574, -1.4062,  0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7381005, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006356024998240173, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.1143,  0.0957,  ..., -0.0649, -0.1074,  0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0615, -0.2754,  0.0928,  ...,  0.0811, -0.0247,  0.0013]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.0000,  11.3750,   4.8750,  ..., -11.1875,   1.8594,   0.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  0.3789,  3.8906,  ..., -1.9922,  3.7031, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.761614, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006436275987653062, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0454, -0.0918,  0.1465,  ...,  0.0698, -0.0879,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.1680, -0.0398,  ..., -0.0562, -0.0806, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   5.8125,  -3.6250,  ...,  -3.5312,  -0.3340,  -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.0698,  0.0221,  ...,  0.6484, -0.3633, -1.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.7855568, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006511416984722018, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054,  0.0669, -0.0284,  ...,  0.0032, -0.0542, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3164, -0.2129,  0.0018,  ..., -0.5547, -0.1904,  0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   1.7969,  -2.6406,  ...,   1.0781,  -1.1016,  -7.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1172,  3.1719,  1.3125,  ...,  2.5625, -0.5938,  2.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8094003, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006591457989998162, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610, -0.0074,  0.1279,  ..., -0.0215, -0.1562, -0.0898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1914, -0.0131, -0.1279,  ..., -0.1167, -0.0118,  0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7188,  3.0469,  1.9844,  ...,  1.3203,  3.0625,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344,  0.2471, -2.0781,  ..., -1.0625, -1.7344, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8330178, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006678981982986443, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635,  0.0034,  0.0066,  ...,  0.0481, -0.0986, -0.1738]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.4512, -0.1416,  ..., -0.4434, -0.1914, -0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.2812, -1.5391,  ...,  1.9922,  2.6406, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.1328, -0.3945,  ...,  5.2500, -1.2266,  0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8565893, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006755374983185902, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0137,  0.0649,  ..., -0.0245, -0.1318, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3457,  0.0972,  0.0349,  ...,  0.3203,  0.1084,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.3281,  2.6562, -4.6562,  ..., -5.0312,  4.6875,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -1.7188, -0.8867,  ..., -0.8984,  0.0084, -0.6758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.8801584, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006830265992903151, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0006, -0.0332, -0.0251,  ..., -0.0059, -0.0253, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1089, -0.3887,  0.0659,  ..., -0.1504, -0.0889,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   1.0391,  -2.5781,  ...,   1.1406,   1.0781,  -0.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  1.9531,  0.9258,  ...,  1.9688, -0.6836,  3.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9037504, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006904634996317327, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640,  0.0046,  0.1113,  ...,  0.0508, -0.0938, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832, -0.0574, -0.1650,  ..., -0.1387,  0.0098,  0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.5625,   5.1250,  -1.2266,  ...,  -6.9688,  -1.4062,   6.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8672, -0.7461, -2.3750,  ...,  1.1250,  0.7344, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x <\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9273725, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.006980909005505964, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0986, -0.0520,  ...,  0.0918, -0.0608, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1465, -0.4141, -0.1426,  ...,  0.0645,  0.1572, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -0.8750,  2.9062,  ..., 10.0625, -7.1562, -3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7422, -0.8203,  2.3750,  ...,  2.4062, -5.0938, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9508476, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007056400994770229, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0154, -0.0815,  0.0635,  ..., -0.0400,  0.0287,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1060, -0.0522,  0.0942,  ..., -0.0089, -0.1562,  0.0308]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   5.5000,   1.6719,  ...,  -3.3594,  -0.8438,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9609, -0.9688, -0.9688,  ...,  1.2969, -0.8984, -3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9744153, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007133706007152796, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1216,  0.0835,  0.0693,  ...,  0.2100, -0.0723,  0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.0806,  0.0212,  ..., -0.0361,  0.1089, -0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.2812,  -1.4375,   1.6875,  ..., -13.1250,   2.3906,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4219,  0.1113, -1.9609,  ...,  0.6758, -0.6914, -7.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100472.9979098, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007210029012640007, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0287,  0.0757, -0.1377,  ...,  0.1196,  0.0469, -0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1699, -0.0525,  0.0430,  ...,  0.0425,  0.1040, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1094, -1.2188, 10.0625,  ..., -3.6875, -4.2500,  6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5938,  0.2109, -2.5156,  ..., -1.4844, -1.1719, -3.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0213614, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007285791012691334, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0104, -0.0840, -0.0052,  ...,  0.2314, -0.0732, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.1719,  0.2383,  ...,  0.0859,  0.2002,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.7500,  8.0625,  7.4375,  ...,  0.4453,  5.1562, -0.5391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1484, -0.0645, -1.9375,  ...,  0.1108,  2.5469, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0448523, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007362545016803779, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605, -0.0444,  0.0190,  ...,  0.1689,  0.0295, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996, -0.0742, -0.0688,  ...,  0.0386,  0.2158, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3125,  5.6562, 12.6250,  ..., -2.5469, 10.3750,  1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9062e-03,  1.6797e-01, -8.1875e+00,  ..., -1.6309e-01,\n",
      "         -2.4688e+00,  1.9609e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0682018, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007438738030032255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0449,  0.1108,  0.1050,  ..., -0.0178, -0.1465,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0977, -0.2295,  0.1069,  ...,  0.0947, -0.0317,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   2.9062,   5.8125,  ...,  -5.5000,   7.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9375,  3.2500,  1.2656,  ...,  0.6406,  4.9688, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.0916603, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007513338030548766, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0015, -0.0996,  0.1504,  ...,  0.1064, -0.1279,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0383, -0.0337,  ..., -0.0131, -0.0532, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.5000,  6.5625, -0.3359,  ..., -8.0000,  3.6875, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1719,  0.8516, -0.5117,  ...,  0.5547, -0.4707, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.11513, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007589461034513079, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014,  0.0713, -0.0106,  ...,  0.0188, -0.0649, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1973,  0.0089,  ..., -0.5234, -0.1973,  0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.3438, -0.6133,  ..., -2.7656, -1.1953, -1.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8711,  3.8125,  1.5625,  ...,  3.4062, -0.2100,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.138643, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007668149031815119, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0417, -0.0137,  0.1270,  ...,  0.0229, -0.1895, -0.0356]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1816,  0.0334, -0.1250,  ..., -0.0684, -0.0154,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4375,  6.5312,  3.9062,  ..., -5.5312,  1.7500,  1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.0596, -1.6406,  ..., -0.4199, -1.3516, -0.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.162049, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0077458850282710046, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0559,  0.0102,  0.0098,  ...,  0.0684, -0.0986, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.4609, -0.1235,  ..., -0.4453, -0.1973, -0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.2812, -0.3398,  ...,  3.7812,  2.5625, -4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8047, -0.5977, -0.5352,  ...,  6.6250, -1.0234,  0.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.1855106, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00782462302595377, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.0178,  0.0547,  ..., -0.0110, -0.1445, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3340,  0.1167,  0.0505,  ...,  0.3242,  0.1050,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1562,  4.3438, -0.4043,  ..., -3.9062,  4.8438, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625,  0.0596, -2.4062,  ..., -1.5234, -0.2871, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2092748, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007910154017736204, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0337, -0.0234,  ...,  0.0135, -0.0183, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1279, -0.3848,  0.0874,  ..., -0.1826, -0.1016,  0.0417]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,   5.9375,  -0.0566,  ...,   0.4688,  -0.8984,  -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4219,  2.7031, -0.0713,  ...,  1.8906, -0.1216,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2330456, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.007991978010977618, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0547,  0.0023,  0.1191,  ...,  0.0845, -0.1230,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2891, -0.0288, -0.1641,  ..., -0.0972,  0.0253,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   9.6875,   1.9844,  ...,  -3.2188,  -7.3750,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6406, -0.8203, -3.0469,  ..., -1.7266,  0.3770, -1.8672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x ==\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2567499, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00806956400629133, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0405,  0.0291,  0.1021,  ..., -0.0522,  0.0569, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1826, -0.1357,  0.1504,  ..., -0.3164,  0.0913, -0.4023]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4297,  3.3281,  ...,  8.5000, -9.5000, -6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  1.4688,  2.9219,  ...,  1.2891, -6.3750, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.2804155, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008144515013555065, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0486, -0.1211,  0.0298,  ..., -0.0840, -0.0442, -0.0157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0757,  0.0003,  0.0659,  ..., -0.0388, -0.1318,  0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0625,  3.1875, -0.4590,  ..., -8.3750,  2.2031,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828, -1.6328, -1.3359,  ...,  2.9219, -1.5938, -4.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.304186, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008220247022109106, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0801,  0.0496,  0.0493,  ...,  0.1650, -0.1113,  0.0100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1846, -0.0723,  0.0601,  ..., -0.0586,  0.0967, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.6250,   2.4375,   1.1250,  ..., -10.1875,  -0.3867,  11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828,  0.5078, -3.3125,  ...,  1.2969,  1.2031, -6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3277755, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008297452019178309, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0723, -0.1396,  ...,  0.1089,  0.0349, -0.0603]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1553, -0.0486,  0.0449,  ...,  0.0337,  0.1118, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   4.0000,  10.3125,  ...,   4.9062,   0.6523,   4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797,  0.2363, -0.6602,  ...,  2.0000, -2.7812, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3515222, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008373053016839549, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0491, -0.0386,  0.0135,  ...,  0.0762, -0.1611, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.4238, -0.1001,  ..., -0.0640, -0.0041,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   3.4531,   6.8125,  ...,   1.6719,   4.8750,   1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3672, -0.3828, -3.4844,  ...,  1.9844,  1.4453, -2.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3751738, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008449496017419733, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0669, -0.0723,  0.0033,  ...,  0.0742,  0.0476, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1157, -0.0815, -0.0273,  ...,  0.0261,  0.2490, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  2.0312,  7.7500,  ...,  0.3906,  5.4688,  1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.5703, -8.3125,  ...,  1.1641, -2.6406,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.3991642, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008528945021680556, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297,  0.1079,  0.1025,  ..., -0.0635, -0.1338,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0581, -0.2373,  0.0840,  ...,  0.0933, -0.0240, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.0273,   0.3008,  ...,  -2.7500,   3.0312,   1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  4.4688,  0.9766,  ...,  0.6094,  3.3281, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.422943, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008606411021901295, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0046, -0.1016,  0.1514,  ...,  0.1089, -0.1118,  0.1177]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.0104, -0.0251,  ..., -0.0151, -0.0498,  0.0123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7188,   5.2812,  -6.9375,  ..., -11.3750,   2.6250,  -3.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1562,  0.9062, -1.1719,  ...,  1.3125, -2.2031, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.4466016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.00868452801660169, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0071,  0.0771, -0.0084,  ...,  0.0137, -0.0396, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1992,  0.0148,  ..., -0.4980, -0.2012,  0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625,  3.3438,  1.0234,  ..., -2.8125, -2.3438, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6367,  3.0781,  0.3926,  ...,  5.1250, -0.7695,  2.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.470255, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008760200013057329, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.0062,  0.1299,  ...,  0.0300, -0.1768, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0322, -0.1123,  ..., -0.0540, -0.0130,  0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.0000,   3.1250,   3.6094,  ...,  -6.7500,   3.0469,   0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7500,  0.8320, -1.4688,  ...,  0.8672, -2.6094, -1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.4941304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008843777002766728, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569,  0.0164,  0.0121,  ...,  0.0664, -0.0815, -0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.4531, -0.1328,  ..., -0.4473, -0.1982, -0.3887]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  1.8750, -1.6250,  ...,  2.3750,  2.9375, -0.6172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3359,  0.0400,  ...,  5.9375, -2.2031,  1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5177, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008921924003516324, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0220,  0.0557,  ..., -0.0094, -0.1318, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.1099,  0.0466,  ...,  0.3105,  0.1074,  0.1099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  1.1484, -5.4062,  ..., -5.3438,  3.0469, -1.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9453, -1.0703, -1.1406,  ..., -0.7617, -1.7812, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5413804, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.008998377015814185, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0239, -0.0262, -0.0258,  ...,  0.0119, -0.0002, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.3594,  0.1016,  ..., -0.1768, -0.1060,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7812,  2.5625, -2.9531,  ...,  2.2188, -3.5625, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  2.4062,  2.0312,  ...,  2.9531, -0.1885,  4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.565191, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009074831017642282, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0576,  0.0080,  0.1133,  ...,  0.0933, -0.1201,  0.0168]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2871, -0.0249, -0.1475,  ..., -0.0820,  0.0232,  0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,   5.3438,   5.0000,  ...,  -0.7500,  -4.1562,   4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8945,  1.8906, -1.2266,  ...,  0.9688, -0.2471, -0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x >\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.5887873, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009161273017525673, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0127,  0.0508,  0.0796,  ..., -0.0156,  0.0106, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0317, -0.0439,  ...,  0.2012, -0.0620, -0.1436]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  3.5781,  5.3438,  ...,  7.3125, -4.8438, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2812,  1.6250,  2.8438,  ...,  4.0625, -5.8438, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6125057, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0092402510199463, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0806, -0.1416,  0.0500,  ..., -0.0742, -0.0334,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0530,  0.0972,  ...,  0.0240, -0.1631,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0000,   5.2188,  -1.3203,  ...,  -3.7344,   4.4062,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0391, -0.4570,  0.6211,  ...,  1.0547, -2.3750, -3.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6362565, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009320362019934691, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0830,  0.0850,  0.0757,  ...,  0.1982, -0.1182,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1729, -0.0574,  0.0542,  ..., -0.0408,  0.1108, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   3.5000,  -0.5547,  ...,  -6.6875,   3.3750,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9492, -0.1680,  0.1826,  ...,  0.7500, -1.3359, -3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n       \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6599343, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009405261007486843, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679,  0.0659, -0.1445,  ...,  0.1138,  0.0520, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504, -0.0320,  0.0488,  ...,  0.0364,  0.1143, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   1.0859,   3.2812,  ...,   3.3125,   7.3125,  -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1592, -0.2178, -0.6602,  ..., -0.7500, -0.8984, -0.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.6836627, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009484309004619718, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0415, -0.0757,  ...,  0.0684, -0.0698, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2236, -0.1094,  0.1147,  ...,  0.0757, -0.0771, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6406, -3.5625,  0.2344,  ...,  3.3125,  3.4375,  5.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2891, -0.0918, -0.1758,  ...,  4.2500, -2.8125, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7074287, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009560712016536854, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0474,  0.0791, -0.0986,  ..., -0.0231,  0.1562, -0.0259]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3242,  0.5195,  0.1768,  ...,  0.1875,  0.1924,  0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.3594,   3.9219,  ...,  -0.7188,  -2.5000,  -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -1.1641,   7.2812,   1.0000,  ...,  10.6875,  -1.9219, -10.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7311647, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009637556009693071, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874, -0.0317, -0.0869,  ..., -0.0952,  0.0004,  0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181,  0.1504, -0.1182,  ...,  0.0361, -0.0947, -0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375,  6.0625,  6.9062,  ..., -4.1875,  0.6406, -1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4668,  6.0000,  3.4688,  ..., -2.6562,  1.9062, -5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7550209, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009713329010992311, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1475,  0.0128, -0.0211,  ...,  0.1816, -0.0938, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4570,  0.1279, -0.0097,  ...,  0.0530, -0.1494,  0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3750, -3.4062, -2.1094,  ..., -0.7812, 10.5000, 18.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7500, -4.4375,  ...,  0.2227,  0.8438,  2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left)\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.7787025, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009788520008441992, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0894, -0.0630,  ..., -0.0133,  0.0840,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0146,  0.0432,  0.0276,  ..., -0.2109,  0.0129, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5312, -3.9531,  3.9219,  ..., -2.5469, 11.0000,  2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.5000, -3.4375,  ...,  0.5586,  1.2266, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) +\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8024678, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009863811006653123, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1318, -0.0908,  0.0923,  ..., -0.0415,  0.0393,  0.0057]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2373, -0.1445, -0.1387,  ..., -0.1094,  0.0718, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7617, -5.1875, 10.3750,  ..., 12.8750,  6.2812, -1.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7930, -1.7656, -1.8438,  ...,  2.1250,  1.4766,  0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8262386, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.009942339005647227, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0781, -0.0084,  0.0166,  ...,  0.2295, -0.0830, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3496,  0.1582,  0.2422,  ...,  0.0183,  0.1855,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0000,  0.6484, -0.3594,  ..., -4.9688, 14.9375,  0.4180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8164, -0.6797, -4.6875,  ...,  1.5312,  1.3438, -1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle +\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.850032, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010017249005613849, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0864, -0.0325,  0.0537,  ...,  0.0104,  0.0544, -0.0106]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.0281, -0.0452,  ..., -0.0215,  0.0271,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8125e+00, -3.7812e+00,  5.5312e+00,  ...,  7.8125e-03,\n",
      "          5.3750e+00,  9.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742,  1.5625,  0.0410,  ...,  6.0312, -4.9375, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8735495, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010093681994476356, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0073,  0.0693, -0.0967,  ...,  0.0151,  0.1182, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.4648,  0.1611,  ...,  0.1260,  0.1992,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,  -0.6211,   0.8281,  ...,  -5.2500,  -2.6250,  -4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  3.6562,  1.2422,  ..., 10.0000, -2.1250, -8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.8973706, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010169673987547867, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1240, -0.0306, -0.0806,  ..., -0.0918, -0.0217,  0.2080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0106,  0.1338, -0.1138,  ...,  0.0157, -0.0728, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000e+00,  6.6250e+00,  1.1312e+01,  ..., -6.6875e+00,\n",
      "         -3.9062e-03,  5.7812e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.3438,  3.5156,  3.1094,  ..., -0.4004,  2.6719, -3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9213688, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010246998979710042, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 1.2207e-04,  7.9346e-03,  1.5625e-02,  ...,  1.4648e-01,\n",
      "         -3.3936e-02,  4.2236e-02]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4375,  0.2988,  0.0035,  ..., -0.0129,  0.2275, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   2.2031,  -3.5938,  ...,  -0.8945,  -2.0312,  12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.6367, 2.0781, 1.8750,  ..., 0.0151, 0.2168, 0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9452314, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010323181981220841, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0344, -0.0693,  0.1543,  ...,  0.1187,  0.0598, -0.0058]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0933, -0.1445,  0.0330,  ...,  0.0398,  0.1982, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.3438,  4.6875,  3.9375,  ...,  1.3906,  9.9375,  5.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -0.9375,  0.7031,  ..., -1.5859, -0.4629, -1.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n#\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.9692028, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010414031974505633, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640, -0.0052, -0.0231,  ...,  0.0233, -0.0557, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0047,  0.0913, -0.3477,  ...,  0.1973, -0.0552, -0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.0938,  3.3438,  4.6875,  ..., 10.9375,  2.8594,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719, -0.5312, -2.7031,  ...,  2.0625,  0.9609, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100473.99308, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010490314976777881, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0293,  0.0258, -0.0688,  ...,  0.0444,  0.0581,  0.0070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0869, -0.1904, -0.1895,  ..., -0.0073,  0.1123,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0938,  9.1875,  6.3750,  ...,  6.1250, -3.1406,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1914, -0.1885, -0.5625,  ..., -0.2969,  0.9062, -1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0165567, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010567699981038459, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1729,  0.0130,  0.0549,  ...,  0.2832, -0.0938, -0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3535, -0.0442, -0.0718,  ...,  0.1050, -0.0669, -0.3965]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -5.5625,  8.5000,  ...,  5.1875, -8.2500,  3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906,  0.8125, -0.9219,  ...,  1.0312, -0.6641, -0.0303]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0402765, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010646958980942145, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0405,  0.0923,  ...,  0.1875, -0.1650,  0.0101]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0004,  0.0918, -0.0659,  ..., -0.0204, -0.2217,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,   6.6250,   5.5625,  ...,   5.6875,  11.9375,   3.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4531, -1.4766, -0.2344,  ..., -1.1719,  0.1914, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0641193, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010728591980296187, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1621, -0.0281,  0.1108,  ..., -0.1050, -0.0022, -0.0161]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555, -0.0938, -0.0344,  ...,  0.2539,  0.1709,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.2500,   9.1875,   2.8594,  ...,   6.4375,   5.8438,   2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  0.2266, -0.9062,  ..., -1.3125,  2.4688, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.0880344, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010804734978592023, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0229,  0.0688,  ...,  0.1562,  0.0508, -0.0309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1123, -0.1484, -0.1206,  ...,  0.0532,  0.1436,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1875,   9.4375,   7.0000,  ...,   2.3438,   6.5938,  -4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5664,  0.9727, -3.7969,  ...,  0.2041, -1.3828, -0.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1119237, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010882149974349886, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.1348,  0.0869,  ..., -0.0649, -0.0972,  0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0640, -0.2432,  0.1094,  ...,  0.0654, -0.0347, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   4.0312,   7.7500,  ...,  -2.5625,   5.1875,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109,  1.3438,  0.5781,  ..., -3.0156, -1.6797, -5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1356385, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.010959264967823401, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0352, -0.0291,  0.0820,  ...,  0.0325, -0.0610, -0.0210]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1445, -0.0588,  0.0559,  ..., -0.1367,  0.0767,  0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6250, -0.1953,  3.2969,  ...,  0.0156, -6.9688,  2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0161,  0.2256,  0.9297,  ..., -1.6328, -1.3203, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1594148, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011035868970793672, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0259, -0.0515,  0.0291,  ...,  0.0474, -0.0669, -0.0190]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703, -0.1289,  0.1328,  ...,  0.1348,  0.0806, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -1.3594,  5.4688,  ...,  1.1562, -7.0625,  2.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4688,  1.1797, -4.2812,  ..., -1.6875,  1.2812, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.1831932, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011111269966932014, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0250,  0.0562,  0.0447,  ..., -0.0415,  0.0181,  0.0087]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0513,  0.1084,  ..., -0.0801,  0.1562, -0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234, -2.0156,  3.9375,  ..., -3.6094, -4.4062,  3.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7305, -5.0938,  ..., -2.2344, -1.8359, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2070353, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011186270974576473, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269,  0.0454,  0.1953,  ..., -0.0347, -0.0845, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.0588, -0.0312,  ...,  0.2422,  0.0698, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9375,  0.2617, -2.0625,  ...,  2.4062, -9.4375,  3.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3535,  0.9531, -2.9531,  ..., -1.7422,  0.9492, -0.9492]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2318947, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011262714979238808, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0488, -0.0033,  0.0620,  ...,  0.0640, -0.0305,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181, -0.0148,  0.0923,  ...,  0.0339,  0.0771, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0938,  1.3750, -9.1875,  ..., 11.6250, -2.0000,  5.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -2.7500,   2.4844,  -4.0625,  ...,  -2.5000,   5.0625, -10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.255904, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011339888980728574, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0332,  0.0410,  0.0435,  ..., -0.0444,  0.0356,  0.0131]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1377, -0.0014,  0.0957,  ..., -0.0732,  0.1455, -0.0586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.6875,  7.7812, -7.0938,  ...,  7.7812,  2.1250, 12.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504,  1.4609, -4.5938,  ..., -7.6250, -1.2656, -7.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.2797635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011415870991186239, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0623,  0.1201,  0.1465,  ..., -0.0125, -0.0226, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0066, -0.0615,  0.0032,  ...,  0.2285,  0.0457,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828,  3.1250,  1.1562,  ...,  3.5469, -0.7852, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.8906, -3.8750,  ..., -0.0742,  0.7109, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.303686, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011491351993754506, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0544,  0.0085,  0.0552,  ...,  0.0250, -0.0654,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0471,  0.0229,  0.1104,  ...,  0.0141,  0.0845, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -1.3750,  -4.5625, -13.2500,  ...,  17.0000,   2.8438,  -8.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6094, -1.3516, -4.9688,  ...,  3.4375,  3.6250, -4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.327352, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011568386005819775, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0386,  0.0430,  0.0417,  ..., -0.0488,  0.0408,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0398,  0.0967,  ..., -0.0640,  0.1357, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312,  -5.0000, -17.0000,  ...,  10.7500,   7.3438,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.4062, -0.3320, -3.2969,  ...,  3.1094, -1.5234, -5.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.3509674, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011656151007628068, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0223, -0.0259,  0.0874,  ..., -0.0486,  0.0586, -0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0439,  0.0493,  0.0659,  ..., -0.0315,  0.0640,  0.0214]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  6.7188,   1.6719,  -9.5625,  ...,   3.0312, -12.0625,  -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -2.9531, -1.1719,  ..., -4.2500,  1.3750, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.3745756, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0117312119982671, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0859,  0.0437,  ...,  0.0640,  0.0679, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1484, -0.1201,  0.2236,  ..., -0.0203,  0.1035, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.7812, -1.3672, -1.7969,  ...,  7.3438, -1.8125, -1.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031,  1.9844, -1.9141,  ..., -1.7344,  0.0469, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.398248, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011806412992882542, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0212,  0.0854,  ...,  0.0052, -0.0053, -0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603,  0.0150,  0.0417,  ..., -0.0186,  0.0898, -0.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  3.1406, -6.6250,  ..., 16.1250, -4.3750,  4.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 4.2188, -3.6094, -4.1562,  ..., -0.2090,  2.2656, -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4220314, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011892053982592188, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0095,  0.0491,  0.0430,  ..., -0.0559,  0.0598,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0376,  0.0762,  ..., -0.0327,  0.1348, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1875,  6.4375, -1.6562,  ..., 13.1875, -5.0625,  8.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.5312, -1.4922, -0.1875,  ..., -5.1562, -2.1094, -5.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4456935, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.011968877995968796, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0042, -0.0366,  0.0801,  ..., -0.0500,  0.0723, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0386,  0.0645,  0.0786,  ..., -0.0339,  0.0791,  0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.3516,   2.2188,  -7.1562,  ...,   4.2500, -10.3125,   3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0625,  0.3262,  0.6250,  ..., -4.6562,  0.8945, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4695883, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012051922996761277, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0420,  0.0154,  0.0698,  ...,  0.0371,  0.0256,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0898,  0.0167,  0.0437,  ...,  0.0228,  0.0598, -0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,   6.7188, -21.0000,  ...,   9.4375, -10.2500,  -0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1562, -1.3516, -3.4219,  ...,  1.3281,  2.2188, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.4935439, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012127996000344865, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0403,  0.0400,  ..., -0.0540,  0.0645,  0.0029]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1904,  0.0422,  0.0869,  ..., -0.0292,  0.1318, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.1875,  14.6250, -26.1250,  ...,   3.3906,  -6.8125,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.1875, -0.0527, -3.4688,  ...,  1.9688, -5.3125, -6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5174317, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012205200997414067, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0052,  0.0211,  0.1367,  ..., -0.0199, -0.0408, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0102,  0.1074,  0.0894,  ...,  0.0618,  0.0874, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5312, -4.5312,  1.3203,  ...,  3.6406, -4.5938,  9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6641,  2.2344, -2.0938,  ..., -0.4453, -0.6953, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5413532, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012280862996703945, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0089,  0.0679,  ..., -0.0019,  0.0001,  0.0166]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0820,  0.0162,  0.0625,  ...,  0.0021,  0.0859, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  10.8125,  -2.5625,  ...,   8.6875,  -0.4414,  11.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8125, -2.5312, -0.8984,  ..., -2.7812,  0.4199, -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5652595, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012358218998997472, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0237,  0.0322,  0.0393,  ..., -0.0645,  0.0562,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.0461,  0.0908,  ..., -0.0236,  0.1309, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3125,  16.5000,  -3.6719,  ...,   3.1250,   0.6211,  20.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -1.2500,  2.4531,  ..., -4.1562, -5.6562, -3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.5892034, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012443077997886576, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0081, -0.0388,  0.0972,  ..., -0.0452,  0.0549, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0315,  0.0608,  0.0630,  ..., -0.0232,  0.0845,  0.0310]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.1250,  -2.1562, -14.9375,  ...,   1.9766, -22.7500,   3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2246,  0.4082,  2.5000,  ..., -1.5078, -1.2734, -2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.613148, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01251978198706638, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0552,  0.0044,  0.0703,  ...,  0.1602, -0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2441, -0.1235,  0.0281,  ..., -0.0737,  0.1377, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.6875,  -7.2188,   2.8281,  ...,   5.4688,   2.8281,   1.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0488,  0.5234,  3.6250,  ...,  0.4199,  4.4688, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.6370966, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012597336986800656, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0422, -0.0938,  ...,  0.1309, -0.1289, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0415,  0.1387, -0.0889,  ...,  0.1445,  0.1494,  0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   2.8750,   9.0000,  ...,  -2.0312,   5.7500,   0.9258]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3203,  1.6406,  3.4219,  ..., -1.2344,  0.0947, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.660747, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012676645987085067, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0454, -0.0184,  ..., -0.1436,  0.0635, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.0913, -0.2109,  ...,  0.2578,  0.3457, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -0.7422,  6.8125,  ...,  1.9844,  3.3438,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734,  0.6953, -1.3047,  ...,  0.6211,  2.4844, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr =\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.6846032, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012756565993186086, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0347,  0.0437,  ...,  0.1123,  0.0540, -0.1040]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318, -0.1367, -0.1621,  ...,  0.0222,  0.1963, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1719, -8.0625,  5.9375,  ...,  3.7656, 10.1875,  2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6094,  3.3594, -0.9492,  ...,  5.1875, -6.0312, -2.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.708422, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012831736996304244, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0166,  0.0752, -0.0776,  ..., -0.0101,  0.1572, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3652,  0.4648,  0.2090,  ...,  0.2051,  0.1289,  0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.1250,  -1.3828,   1.8750,  ...,  -1.3047,  -1.8984,  -3.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  4.6875,  2.4062,  ..., 10.7500, -1.7969, -9.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.732338, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012917276995722204, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1108,  0.0035, -0.0752,  ..., -0.0850,  0.0019,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.1367, -0.0903,  ...,  0.0557, -0.1289, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.6875,  2.2188,  2.3438,  ..., -1.6562,  4.6562,  2.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5312,  3.9375,  0.5703,  ..., -2.0781,  1.6484, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.7563102, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.012993068987270817, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0430, -0.0004,  0.0762,  ...,  0.0527,  0.0044, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4219,  0.0089, -0.0142,  ...,  0.3301,  0.1494,  0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   2.1250,  -7.1562,  ...,  -2.5469,   3.4062,  12.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828,  1.1875, -0.0869,  ..., -0.1582,  0.0640, -0.2852]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.7804692, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013076364994049072, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0128, -0.0190,  0.0889,  ...,  0.0938,  0.1279, -0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0613, -0.1230,  0.0201,  ..., -0.1445,  0.2188, -0.0354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1250,  -1.2500,   0.4980,  ...,  -2.0000,   4.5625,   0.2754]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1797,  0.1895,  2.1406,  ...,  1.7578,  3.2656, -3.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8044834, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01315161699312739, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0374, -0.1396, -0.1387,  ...,  0.0417, -0.0093, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2734, -0.3164, -0.2832,  ..., -0.3320, -0.3789, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -2.5156,  7.4062,  ..., -1.0469,  2.0625,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7734,  0.3086,  1.0625,  ..., -2.4219, -0.3164,  0.2715]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8283687, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013227769988588989, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0049,  0.0299, -0.1099,  ...,  0.3105, -0.0564, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  0.2773,  0.0693,  ...,  0.1045,  0.0222, -0.0253]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.3750,   5.6250,   2.5000,  ..., -10.1250,   4.6250,   3.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2207,  4.0312,  3.9688,  ..., -0.4668, -0.6328,  3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8522902, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013303822983289137, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371, -0.0654,  0.0057,  ..., -0.1328,  0.0613, -0.1157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2236,  0.0181, -0.2461,  ...,  0.2734,  0.2812,  0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -0.3242,  -5.6875,  ...,  -2.6719,  -0.4883,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3477,  1.0078, -2.6875,  ..., -0.1240,  0.1211,  0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8758073, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013386287988396361, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014, -0.0566,  0.0498,  ...,  0.0295,  0.0742,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1055, -0.0830, -0.0139,  ..., -0.1406,  0.1748, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5625,   2.5312,   2.3906,  ...,   0.0664,  -2.2812,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2734, -1.6875,  2.2344,  ..., -0.4727, -0.2852, -2.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n``\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.8997939, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01346493598248344, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0275, -0.0879, -0.0281,  ...,  0.0366, -0.0378, -0.1465]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0859, -0.1162,  0.2412,  ..., -0.4141, -0.1465, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.7500,  -1.0312,  -1.0312,  ...,  -5.6875,  -1.5078,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.0703, -1.2500,  ..., -1.3516, -5.0625, -5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.9236786, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013540567990276031, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-3.1006e-02,  4.5898e-02,  8.6914e-02,  ...,  1.5234e-01,\n",
      "         -2.7710e-02,  1.2207e-04]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4961,  0.0732, -0.0786,  ..., -0.2090,  0.3418, -0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.6250,   1.3750,  -4.6250,  ...,  -0.2266,   0.8750,   1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2344, -1.7109, -1.2344,  ...,  1.8438, -0.5234, -0.8398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n###\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.947527, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013617361983051524, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0442, -0.0248,  0.0141,  ...,  0.1533,  0.1504, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3145,  0.1895,  0.2295,  ..., -0.0566, -0.1982, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -3.4219, -0.4863,  ...,  5.7188,  7.4062, -1.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.6992, -3.0312,  ..., -1.1016,  0.8125,  0.2734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.971491, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013695318979443982, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2295, -0.2207, -0.0649,  ..., -0.0718, -0.0923,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0064, -0.2021, -0.1973,  ..., -0.4062,  0.0801,  0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2500, -0.7188,  2.7500,  ..., -0.0391, -5.0312,  7.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773,  1.3750,  0.8516,  ...,  0.3047,  0.6055, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100474.9951422, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01377111098554451, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201,  0.0327,  0.0294,  ...,  0.2188, -0.1846, -0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1235,  0.0080, -0.0635,  ..., -0.1475, -0.1680,  0.0598]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.4375,   0.1016,   1.7344,  ...,   3.3594,  -1.9766,  -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -1.4297, -0.0513,  ...,  1.0625, -2.2031, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.018772, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013846882982761599, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0145, -0.0177,  0.0205,  ...,  0.0430,  0.1504, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.0029,  0.0178,  ..., -0.0640,  0.0352,  0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -2.5781,  1.4766,  ...,  2.0625,  5.3750, 10.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250,  0.2285, -2.2656,  ..., -2.4219,  2.3906, -2.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.042531, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013924017985118553, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1406, -0.0908,  0.0466,  ...,  0.0312,  0.0267,  0.0444]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2715,  0.1064,  0.0728,  ...,  0.0840, -0.0510,  0.0923]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.2500,  -9.8125,  -4.0938,  ...,   6.5000,   0.0625,   4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828, -0.7617, -4.3438,  ..., -2.0938, -0.7617, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.066297, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.013999709975905716, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0254, -0.0308,  0.0713,  ...,  0.0791, -0.0344, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2559,  0.0840, -0.0801,  ...,  0.0131, -0.3262,  0.2891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,  -6.8750,  -3.0000,  ...,   7.5000,  -0.9414,   8.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.4375, -0.5898, -0.8984,  ..., -0.6484,  1.4375, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.0899184, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014082655980018899, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0121,  0.0052, -0.0405,  ...,  0.1064, -0.1533, -0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.1836,  0.0071,  ..., -0.1787, -0.0183, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,  -0.9141, -10.8750,  ...,   7.6875,   6.4062,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7930, -1.3906, -1.1797,  ...,  6.0000,  2.3594, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1138258, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014173255985951982, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2090,  0.0422, -0.0266,  ...,  0.1953,  0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1055, -0.0079,  0.0879,  ...,  0.5273,  0.1064, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.7500,   3.9375,  -6.9062,  ...,   8.4375,   2.1250,   3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750,  2.4062, -3.7031,  ...,  1.5000,  0.1758, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1377585, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01424960898293648, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0378, -0.2236, -0.0425,  ...,  0.2852,  0.0820, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1016,  0.1079, -0.1123,  ..., -0.0420,  0.0840,  0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.8438, -10.2500,  -6.4375,  ...,   7.3125,   2.4219,  -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.7891, -1.5938,  ...,  0.2539, -1.3125, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1617856, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014326572985737585, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0884, -0.0625,  0.0178,  ...,  0.0522, -0.0459, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1602, -0.1650, -0.1553,  ...,  0.0664,  0.1523,  0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -4.6875,  0.7109,  ...,  5.7188,  9.3750, -6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109, -0.4648, -1.4766,  ..., -2.1875, -3.1875,  0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.1857188, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01440294599160552, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0718,  0.0967, -0.0025,  ...,  0.0957,  0.0457, -0.0371]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0133,  0.0188,  0.0359,  ..., -0.1621, -0.0522,  0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500,  1.8594,  6.8750,  ..., -2.5625,  6.0625,  0.6602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9531, -1.5703, -3.1406,  ..., -0.8594, -0.3652, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2097385, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01448042098490987, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0498, -0.0120, -0.0415,  ..., -0.0267,  0.0344, -0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147,  0.0156,  0.0996,  ...,  0.0032,  0.0033,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188, -5.4688,  0.9922,  ..., -1.6328, -9.1250, -2.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344, -0.6055,  0.2812,  ..., -2.5312, -0.2988,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2335987, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014556933980202302, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787,  0.2139,  0.0083,  ..., -0.0581, -0.0072, -0.1582]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0708, -0.1475,  ..., -0.1523,  0.0121, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062, -7.9375, -4.5938,  ..., -0.1250, -7.0938, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453, -1.2031, -1.3359,  ..., -2.6250, -1.4062, -0.7461]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2574766, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014633587983553298, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0557, -0.0625,  0.0015,  ..., -0.1133,  0.0200,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0679, -0.0146,  ...,  0.1157,  0.1138, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0000, -6.4688, -5.0625,  ...,  6.7500, -6.6250,  8.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2969, -3.1406, -3.8281,  ...,  2.7031, -3.3438, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.2813213, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01471033199049998, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0952,  0.0859,  ..., -0.0371, -0.0078, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118, -0.0977, -0.0192,  ...,  0.1309,  0.0728, -0.0084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.4688,  -4.5000, -13.4375,  ...,   3.9844,   4.2812,  -1.0078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734,  2.1719, -1.7812,  ..., -1.6406, -3.7969, -0.5039]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3048458, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014786053987336345, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0003, -0.0223,  0.0947,  ...,  0.0269, -0.0747, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.1030, -0.0625,  ..., -0.1992,  0.2031, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0586, -6.8750, -6.1250,  ...,  5.6250,  0.3320,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8047,  0.8359, -5.6562,  ...,  0.3066, -0.9727, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3287392, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014863589982269332, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347,  0.0820,  0.1069,  ..., -0.0928,  0.0327, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  0.0022,  0.0209,  ...,  0.0398,  0.0645, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -1.9922, -1.1094,  ...,  6.5312,  1.7344,  9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0781, -3.3438, -4.0312,  ...,  4.5000, -3.0156, -7.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3523507, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.014939011991373263, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0101, -0.0310,  0.0374,  ..., -0.0248,  0.0588, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0243,  0.0483,  0.0471,  ..., -0.0439,  0.0703,  0.0225]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.0625,   6.8438, -10.1875,  ...,  -0.8438,   3.7188,  -2.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406,  0.7656, -3.4219,  ..., -1.2422, -1.2422, -1.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.3761096, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015015144992503338, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0261,  0.0211, -0.1226,  ..., -0.0240, -0.0713,  0.0182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0050, -0.2812,  0.1089,  ..., -0.0972,  0.0781, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2500,  0.4727, -2.5312,  ..., -1.2188, -0.5625,  6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.4043, -0.8906,  ..., -0.1191, -0.8672, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.399911, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01509085699217394, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0278, -0.0342,  0.0014,  ..., -0.0276,  0.0496, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1079, -0.1396, -0.1138,  ..., -0.0674,  0.1187,  0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.9375,  -0.2773, -11.5000,  ...,   2.4688,   1.2812,   2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -1.2109, -1.4766,  ..., -1.2891, -1.7969, -0.3984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4238496, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01516660898050759, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0513, -0.0189,  0.0771,  ..., -0.1338,  0.0918, -0.0203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0216, -0.0508,  0.0908,  ..., -0.0728,  0.0117, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  4.5000, -5.0312,  ...,  6.4375, -9.1875,  5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  2.1562, -1.0000,  ..., -0.2090, -1.4219, -0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.447839, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015242871988448314, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1572,  0.1162, -0.0645,  ..., -0.1660, -0.0317, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641,  0.1406, -0.1719,  ..., -0.0454, -0.1738,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000, -3.0469, -4.2188,  ...,  2.9375, -0.7891,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8984, -0.5781, -2.2812,  ...,  0.1367, -1.4531,  0.8008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4717636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01531955599784851, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1914, -0.1011, -0.1113,  ...,  0.0991,  0.0027, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.1060, -0.5508,  ...,  0.0635,  0.0010,  0.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3438, -2.7188, -1.6328,  ...,  7.4375,  3.2500, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2344, -2.0469,  2.9688,  ...,  0.8750, -2.1562,  1.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.4957435, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015406098988023587, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269, -0.1162, -0.1279,  ...,  0.0317, -0.1875, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0293, -0.1211, -0.0554,  ...,  0.1406,  0.2188, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578, -2.2812,  0.6836,  ...,  7.8750,  2.4688, 10.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0112,  1.1562, -0.7539,  ..., -0.9805, -0.2441, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5194519, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015483944982406683, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0141,  0.0535,  0.0339,  ..., -0.0366, -0.0325,  0.0173]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172, -0.0762, -0.0684,  ..., -0.0806,  0.0957,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1211, -1.9531, -8.0000,  ...,  1.2344,  2.8750,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9023, -1.3594, -0.9531,  ..., -0.7734, -0.1602,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5434983, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015561910986434668, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0322, -0.1309, -0.0139,  ..., -0.0581,  0.0099, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641, -0.2734,  0.0684,  ...,  0.0596,  0.1787, -0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4062, -1.1562, -9.0625,  ...,  3.8750,  3.9062,  3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0156, -0.4707, -1.2812,  ..., -0.8672, -1.1406,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.567293, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015638443976058625, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0188,  0.1138,  0.0850,  ..., -0.1377,  0.0322, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520,  0.1572, -0.0991,  ..., -0.1289,  0.0278,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.4375, -6.1250, -9.9375,  ...,  1.0312,  2.4375,  3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1016, -0.0588,  0.0527,  ..., -1.7500, -1.3359, -0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.5911462, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015721659976406954, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0077,  0.0459, -0.0118,  ..., -0.0659, -0.0806, -0.2021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1426, -0.0532,  0.0776,  ...,  0.1230, -0.0698,  0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3281,  3.4219, -5.5938,  ...,  5.5625,  5.3438,  4.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6172, -0.6641, -0.2021,  ..., -2.3906, -2.0469,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6150331, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01579852397844661, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1191,  0.0542,  0.1016,  ..., -0.1846,  0.0723, -0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.1455,  0.2461,  ...,  0.0588, -0.1235, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.3281, -0.8633, -4.4688,  ...,  1.4453,  3.3906,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8125,  1.3984,  0.3125,  ..., -0.9062,  0.1221,  0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6389887, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01587480698071886, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0173,  0.0708,  0.1211,  ..., -0.1484,  0.1162, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0771, -0.1157,  0.1953,  ..., -0.1377,  0.0723,  0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -4.4375, -2.1562,  ...,  6.6562, -0.9141,  6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9219, -0.9570, -1.7344,  ..., -1.8203, -2.6250, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6629136, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.015951149980537593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0850, -0.0009, -0.0737,  ..., -0.1514, -0.0610, -0.0405]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0879,  0.2793,  0.0630,  ..., -0.1895, -0.2021,  0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188,  0.3945, -3.0938,  ...,  2.2344, -3.7969,  5.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5625,  1.5625,  1.1328,  ..., -0.0088, -1.0703, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.6866353, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01602773298509419, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.0090,  0.0737,  ...,  0.0391,  0.0654, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0574, -0.1436, -0.0649,  ..., -0.0208,  0.1611,  0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,  -2.4688,  -3.0938,  ...,   0.9219,   1.3750,   5.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5859, -4.1562, -1.2500,  ...,  4.5000, -0.2578, -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.710387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01610456699563656, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0045,  0.0518,  ..., -0.0148,  0.0019, -0.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0894,  0.1138,  0.0718,  ...,  0.1289,  0.0859, -0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,   0.9531,  -4.1250,  ...,   0.9219,  -3.6875,   6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9844,  0.0894, -7.2500,  ..., -0.4375,  4.9062, -4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.7339618, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016180809994693846, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006,  0.0017,  0.1025,  ..., -0.0459, -0.0135, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1152,  0.2754, -0.0388,  ...,  0.0559, -0.0698,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,  -2.8906,  -6.7812,  ...,  -3.7812,  -1.4062,  -0.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406, -3.1094, -4.5938,  ..., -0.9844,  1.0312, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.757817, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016257894996670075, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0034,  0.0786,  0.1689,  ...,  0.0786,  0.0271, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2578,  0.1660, -0.1406,  ...,  0.0938, -0.2793,  0.3398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6250,   0.9727,  -1.7734,  ...,   2.2969,  -0.9453,  -3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.0625, -1.7578, -0.1875,  ...,  6.3125,  4.4688, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **P\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.7817078, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01633502999902703, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1592, -0.1045,  0.1914,  ...,  0.1543,  0.0072, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0442, -0.2314,  0.0262,  ..., -0.1484,  0.0781, -0.0427]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,  -2.7188,  -0.3203,  ...,   7.5000,  -6.2500,  -6.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -4.5312,   1.7891,  -1.7266,  ..., -10.5000,  -3.0938, -15.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8055007, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01640984100231435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1104,  0.0806,  0.0972,  ..., -0.2891,  0.0352, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1650,  0.1279,  ..., -0.1621, -0.1299, -0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,  -0.2422,  -6.0938,  ...,   4.4062,   3.4531,  -5.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.1094, -2.4375, -1.1406,  ...,  5.7500,  1.4062, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8295515, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016484481006045826, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0116,  0.0306,  0.1143,  ..., -0.0610,  0.0164, -0.2617]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416,  0.0972,  0.0184,  ...,  0.1934,  0.2773, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,   1.0469,   1.1875,  ...,   2.9844,   3.7188,   1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9141,  1.2031, -2.3438,  ...,  2.6406, -0.5547, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.853532, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01655992300948128, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0503, -0.1465, -0.0308,  ...,  0.2178,  0.0996, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1357,  0.0579, -0.1670,  ...,  0.0228,  0.1465,  0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.8125,  -6.3438, -10.8750,  ...,   3.7500,   3.7500,   2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -4.3750, -0.3203,  ...,  1.2969,  0.5586,  0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.8773386, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01664615501067601, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0649, -0.0378,  0.0535,  ..., -0.0884, -0.0205, -0.0630]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.3379,  0.2461,  ..., -0.0028, -0.0038,  0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7812,  -2.4688, -14.8125,  ...,   2.7656,   0.5195,  -1.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -3.0156, -0.0547,  ...,  2.9531, -2.8125,  0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.90117, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016723279011785053, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1084,  0.0352, -0.0210,  ...,  0.1123,  0.0635, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603, -0.3633,  0.1553,  ...,  0.4434,  0.0547, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7188,  2.9062, -6.3438,  ...,  8.7500,  4.8438,  5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5938, -1.0625, -0.1299,  ..., -2.4844, -4.2500, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.924937, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016799632998299785, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0398,  0.0200,  ..., -0.1328,  0.0103, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0413, -0.1011,  0.2266,  ..., -0.1475, -0.0757, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500, -7.1250,  6.2500,  ...,  3.6250,  1.5625, -0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4023, -0.8906, -1.0938,  ..., -1.4141, -3.2344, -1.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9485116, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016875174987944774, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0276, -0.1035,  0.0542,  ..., -0.1592, -0.0403, -0.0422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0532, -0.0732,  0.1030,  ..., -0.0496, -0.0403,  0.0306]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6875,  3.3438,  4.6875,  ..., -5.4688, -5.0312,  1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2734, -1.3203,  0.6953,  ..., -1.2891, -0.5430, -0.0298]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9724045, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.016957398984231986, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0055,  0.1250, -0.0396,  ..., -0.0474,  0.0518, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0449, -0.3613,  0.1152,  ...,  0.0118,  0.0014, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625, -1.9688,  0.4434,  ..., -1.9141, -5.7500, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8398, -0.8984, -0.0801,  ..., -0.2930, -0.8047, -0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100475.9962132, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01703430397901684, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0369,  0.0596,  0.0466,  ..., -0.0334,  0.0879, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1025, -0.0767,  0.0381,  ...,  0.0045,  0.0075, -0.0134]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.5312, -9.0000, -9.7500,  ...,  4.1562, -0.4980,  5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906, -2.0781, -1.8203,  ...,  2.1406, -1.6016, -0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.020097, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017112690984504297, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201, -0.0488,  0.0227,  ...,  0.0605, -0.1045, -0.1787]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009,  0.1328, -0.0374,  ..., -0.1084, -0.1436,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -1.6250, -6.7188,  ...,  1.1172,  4.1250,  5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3203, -1.3516,  0.4414,  ..., -1.8438, -0.3555,  0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0441368, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017188803991302848, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1206,  0.0879,  0.1777,  ...,  0.2520,  0.0791, -0.0127]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0209, -0.1680, -0.3281,  ...,  0.3242,  0.1709, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2812,  3.2812, -3.3125,  ...,  7.8125,  2.1562, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9883, -1.0469, -1.6328,  ..., -2.1406,  1.2188, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0680163, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017264886992052197, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1553,  0.1738,  0.0493,  ...,  0.0033,  0.0309, -0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.1807,  0.4961,  ..., -0.4355,  0.0439,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.7812,   1.0938, -10.5000,  ...,   1.2422,   5.0938,   8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375, -0.0198, -0.1777,  ...,  0.1201, -0.3965, -1.3047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.0921693, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01733998798590619, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0110,  0.0265,  0.0586,  ..., -0.0178, -0.0039, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.1318, -0.0515,  ..., -0.0718, -0.0056,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5000,  -2.0625, -14.3750,  ...,   1.6875,   7.1875,   6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -0.7930,  0.4805,  ..., -0.2480, -1.6953,  0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.1169484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017415298978448845, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0325,  0.0486,  0.0074,  ..., -0.0444,  0.0198, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2383,  0.1143, -0.0037,  ..., -0.0432,  0.0498,  0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -5.7188, -12.8750,  ...,   5.8125,   1.0938,   0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2539, -1.8984, -0.6133,  ...,  1.8594, -2.9375, -0.0146]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.140981, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017491681981482543, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-7.9102e-02,  1.9775e-02, -8.5449e-02,  ...,  3.3691e-02,\n",
      "          1.8311e-04, -2.2656e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0393, -0.0869,  0.2598,  ...,  0.2832, -0.0684, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4629, -3.6250, -3.5625,  ...,  5.6250,  7.8125,  0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -0.4473, -0.5391,  ..., -3.6875, -3.6250, -0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.16469, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01756683297571726, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0004,  0.0503,  0.0476,  ..., -0.1084, -0.0118, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0938, -0.0091,  0.2656,  ..., -0.1836, -0.0121, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2969, -6.7812,  8.3125,  ...,  3.5469,  3.0156, -1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7031, -0.4258, -1.5625,  ..., -2.8281, -2.2188, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.1886737, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01764621197071392, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0067,  0.0164, -0.0167,  ...,  0.1787, -0.1172, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832,  0.1182,  0.2695,  ...,  0.0049,  0.1641,  0.0488]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125,  7.7188, -0.5859,  ...,  2.6250,  4.3125, -0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0859,  0.4492, -1.6094,  ..., -1.1328,  0.5703, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2127016, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01772269597859122, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0977, -0.0532, -0.0732,  ...,  0.0471, -0.0479, -0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0481, -0.3965,  0.1592,  ...,  0.0150,  0.0457, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  7.0625, -2.7031,  ..., -1.6250,  2.4688,  2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363,  0.6016, -0.1279,  ..., -0.8594, -0.7422, -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2365334, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017797695982153527, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1367, -0.1367, -0.0420,  ...,  0.0317, -0.0620, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943, -0.4434,  0.1079,  ..., -0.0645, -0.3047,  0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500,  1.2812,  5.0938,  ...,  3.2500,  3.6562,  2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2578,  0.1650, -1.1484,  ..., -2.7656, -3.5625, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2605164, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01788672296970617, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0444,  0.0315,  ..., -0.0344,  0.0238, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1338,  0.0315, -0.0210,  ..., -0.1494, -0.0040, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.5625,  4.3438, 13.4375,  ...,  4.6875,  6.9375,  2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9180, -3.2812, -1.6875,  ..., -1.1094,  0.7500, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.2845273, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.017961563979042694, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0615, -0.0332,  0.0010,  ..., -0.0598, -0.0483, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0491,  0.0645,  0.0664,  ...,  0.0209, -0.0654,  0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062,  2.6875, -2.2812,  ...,  3.2344, -1.3438,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4258,  0.9688,  0.1523,  ..., -0.1001, -1.3672, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3085294, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01803781697526574, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0361,  0.0874,  ...,  0.0618,  0.0825, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1133, -0.1406, -0.0708,  ..., -0.0840,  0.1543,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.5000, -1.2812, -1.9219,  ..., -8.1250,  1.9844, 11.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3281, -1.1406, -0.6992,  ...,  1.5859, -1.7344, -0.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3324354, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018113538972102106, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0137, -0.0452,  0.0129,  ..., -0.0325, -0.0408, -0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0239,  0.0718,  ...,  0.0339,  0.0354,  0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2812, -1.7422,  0.3008,  ...,  2.4688, 10.5000,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.7344,  1.4375, -7.6250,  ..., -2.0625,  5.4062, -1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3562615, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01818868998088874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0713,  0.0087,  0.0430,  ..., -0.0513,  0.0073, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0825,  0.3750,  0.0073,  ...,  0.0231, -0.0840,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125, -2.3125, -5.9375,  ..., -9.3125,  9.5625, -0.9453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906,  0.5859, -5.6875,  ..., -0.9180,  2.0156, -0.4336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.3800995, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01827319797303062, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0996,  0.1855,  ...,  0.0708,  0.0593, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598,  0.1699, -0.1650,  ...,  0.1270, -0.2793,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7969,  0.0234, -2.9219,  ...,  3.3125, 16.0000, -0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8906,  1.1719, -5.0312,  ...,  4.3125,  1.9844,  2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partition\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4042516, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018351414968492463, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0062,  0.0330,  ..., -0.1865,  0.0479, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1167, -0.0483,  0.1338,  ..., -0.0947, -0.0889,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000, -2.9531, -3.1562,  ...,  9.2500, -2.9062, -3.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0781, -1.2969, -2.5000,  ...,  0.6875,  0.8281, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4281778, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018432115961331874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1777,  0.1084,  0.0554,  ..., -0.2412,  0.0254, -0.2910]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0229, -0.0291,  0.0012,  ..., -0.2773,  0.0286,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  2.6875, -0.3828,  ...,  8.3750, -2.1562,  2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.2637, -5.5312,  ...,  0.6641,  0.2773, -0.9180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.4523246, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01850752795871813, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0586, -0.1738, -0.0016,  ...,  0.2344,  0.0986, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.1006, -0.1426,  ...,  0.0270,  0.1299,  0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4941, -4.0938, -5.7500,  ..., -7.7188, 11.5000,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.7578, -0.7656,  ...,  0.4375, -0.5234, -0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.476308, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018583891956950538, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0525,  0.0801,  ..., -0.0664, -0.0182, -0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  0.3809,  0.2256,  ...,  0.0265,  0.0229,  0.4004]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -1.3047, -3.3594,  ..., -5.6875,  8.7500, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.2207, -1.7266,  ...,  2.3125, -1.2734, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5002928, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01866809994680807, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0000,  0.0908, -0.0277,  ..., -0.0100, -0.1338, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4570, -0.1963, -0.0123,  ..., -0.5742, -0.2402, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250, -0.8906, 14.8750,  ..., -4.2500,  1.9297, 11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0469,  0.0723,  1.0234,  ..., -0.2012, -4.4062, -0.5742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5241387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018750473944237456, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0452,  0.0732,  0.1357,  ..., -0.0630,  0.0679, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0552, -0.1055, -0.0835,  ...,  0.0432,  0.0554, -0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7812, -2.7812, 14.1875,  ...,  1.0312, -3.7812,  4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9297,  2.4531, -0.0752,  ...,  0.5547, -2.3750,  0.8086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5482304, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018827267951564863, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0203,  0.0864,  0.1592,  ..., -0.0791, -0.0449, -0.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0967,  0.0938,  0.1826,  ...,  0.1206,  0.1040, -0.0142]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.7500, -4.6562,  4.1562,  ...,  8.3750,  2.0625, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3457,  0.9961,  8.0000,  ..., -5.5625, -4.2812,  3.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5721982, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.018904953947640024, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0044, -0.0996, -0.0099,  ..., -0.0967,  0.0081, -0.0159]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0359, -0.1084,  0.0522,  ...,  0.1660,  0.2256, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.0938, -3.8125,  1.9375,  ...,  2.6562,  1.3750,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5156, -3.5156, -2.2500,  ..., -4.5625, -0.5234, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.5962863, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01898188894847408, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0845, -0.0160, -0.0090,  ..., -0.1011, -0.0762,  0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1895, -0.0023, -0.0085,  ..., -0.0269, -0.0820, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9062, -1.1953,  4.1250,  ...,  2.4844, -1.4844,  9.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9219,  0.8789,  0.4473,  ..., -1.8516, -1.1875, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6203156, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019067449946305715, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0020,  0.0603,  0.0977,  ...,  0.1147, -0.0261, -0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.1138, -0.1348,  ..., -0.0933,  0.0277,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0469, 10.5000,  3.9531,  ..., -7.4375,  4.5000, 13.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3594, -4.9688, -1.2891,  ...,  0.2070,  0.0299, -2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6440723, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019154643945512362, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.0688, -0.0112,  ...,  0.1826,  0.0262, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147, -0.2236,  0.3105,  ..., -0.0029, -0.0605,  0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.4219,  0.3203,  ..., -5.7500,  4.7500, 13.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000, -2.3438, -4.2188,  ..., -0.9297, -0.0762, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.667959, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019230214951676317, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1030,  0.0015,  0.0364,  ...,  0.1953,  0.1299, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.1533,  0.0669,  ...,  0.0383, -0.0513,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.6406, -3.8906,  1.3906,  ..., -1.0547,  8.4375,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -1.8125, -3.5938,  ..., -1.7188, -2.4531,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.6918857, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019307849943288602, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0630,  0.0227,  ...,  0.1074, -0.0233,  0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0093, -0.1865,  0.0781,  ..., -0.1445, -0.3105, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0000,  0.5547,  7.2500,  ...,  0.4766, 10.7500,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188,  1.3281, -0.2812,  ..., -3.4531, -3.2656, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.7158477, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019383822931558825, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1040,  0.1006,  0.0201,  ..., -0.1079, -0.0879, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2656,  0.2051, -0.0781,  ..., -0.0830, -0.2617,  0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1875,  -1.3125,  -1.0312,  ...,   6.5312,  -1.0156,  10.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7148,  0.9297, -2.4375,  ...,  0.2070,  2.5469, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.739749, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019459294926491566, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0283, -0.1279,  0.0229,  ...,  0.1670,  0.2539, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2373,  0.2275, -0.2598,  ...,  0.0791,  0.4648, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1641,  0.5078, -5.5312,  ...,  2.0312,  5.9688, -1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520, -4.7812, -0.1475,  ..., -0.0248, -2.3594,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.7637627, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019534826918970793, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0320, -0.0063,  0.0215,  ..., -0.1904,  0.0610, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0287,  0.0013,  ..., -0.0591, -0.1494,  0.3262]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9062,  9.0625, -4.4062,  ...,  1.0781,  2.1875,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2539, -0.9375,  1.0781,  ...,  0.5234, -1.4297, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.787863, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019610598916187882, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366,  0.0386, -0.1582,  ..., -0.0640, -0.0874,  0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.4863,  0.0315,  ..., -0.0464,  0.0864,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.1562,  1.0859, -1.6016,  ..., -4.0625, -6.5938,  4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.6211,  1.4062,  ...,  1.5469, -1.6953, -1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.811661, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01968670092173852, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0256, -0.0107, -0.0942,  ..., -0.0193, -0.0305, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.1963, -0.0009,  ..., -0.0879, -0.1514,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1250, -1.9453, -1.9297,  ..., -1.7891, -5.7500,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8438, -0.7031, -1.7500,  ..., -0.0352, -5.8750, -0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.8356454, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019765949924476445, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0108,  0.1035, -0.1143,  ...,  0.0776,  0.0947, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4277, -0.3965, -0.4316,  ..., -0.5039,  0.2832,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -2.1094, -5.4375,  ...,  2.7188,  0.1758,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3750, -0.9219, -1.7969,  ..., -1.5000, -4.1562, -1.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.8596034, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019841952933347784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0269,  0.1021,  0.0598,  ..., -0.0559, -0.0359, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0459,  0.2715,  0.0620,  ..., -0.2275, -0.0010, -0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  2.5938,  0.6172,  ...,  3.0469, -9.4375,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0623, -1.4688, -0.4082,  ..., -0.4336, -3.8125, -5.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.883619, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.019918856938602403, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0179, -0.0967,  0.0334,  ..., -0.1104, -0.0106, -0.0216]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0801, -0.0825,  0.1094,  ..., -0.0613, -0.0388,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7188,  2.0312,  1.1406,  ..., -0.3984, -3.1406,  1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5156,  0.7344, -0.9688,  ..., -0.5859, -1.1094, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9076712, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.01999412894656416, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0493,  0.0996,  0.0884,  ...,  0.0610,  0.1187, -0.0549]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396, -0.1089, -0.0498,  ..., -0.1221,  0.1475,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1602,  0.8047,  4.1875,  ..., -5.5625,  5.9062,  6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2734, -1.8594, -2.2500,  ...,  4.3438, -0.5273, -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9315984, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02007041194883641, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0820,  0.0581, -0.0192,  ...,  0.1689, -0.0243, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0435, -0.1035,  0.2832,  ..., -0.0133, -0.0172,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -1.5469,  3.3125,  ..., -2.9375,  8.4375,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.9688, -4.5625,  ...,  3.0469,  0.4922,  0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9555387, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020146003953414038, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0184,  0.0576,  0.0488,  ...,  0.1357,  0.1445, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1816,  0.0708,  0.0292,  ..., -0.0081, -0.0747,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2656, -2.2812,  4.0312,  ..., -0.4219,  3.1719,  6.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734, -0.6523, -5.7188,  ..., -1.2578, -3.4844, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100476.9797988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02022133495484013, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0088,  0.1011,  0.0635,  ...,  0.0703, -0.0100,  0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0046, -0.0630,  0.0552,  ..., -0.1025, -0.2969, -0.0017]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1367,  2.6094, 15.4375,  ...,  0.9375,  4.5625,  0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.1562, -0.6055,  0.3633,  ..., -2.8438,  2.8125, -3.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0037255, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020297066948842257, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1089, -0.0037,  0.0791,  ...,  0.1123,  0.0044, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4355,  0.2129,  0.2158,  ...,  0.1338,  0.0781,  0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,   0.8125,  -0.7891,  ...,   4.3125,  -3.3750,   7.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5625, -1.4297, -3.7969,  ...,  3.9531,  1.4922, -3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0271833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02038414095295593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1108, -0.1348,  0.0815,  ...,  0.2070,  0.2148, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2109,  0.2109, -0.2422,  ...,  0.1631,  0.3809, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.5625, -3.9531, -6.4375,  ..., -7.4375,  8.3750, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5938, -2.8125, -5.0000,  ..., -2.9531, -1.1875,  0.3926]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0510242, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020463810957153328, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0092, -0.0317,  0.0583,  ..., -0.1348, -0.0233, -0.1348]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3535e-01,  1.6309e-01,  1.4404e-02,  ...,  2.8229e-04,\n",
      "         -7.5195e-02,  3.5156e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562,  6.8438, -4.5625,  ..., -3.2500,  0.8398, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -1.4219, -0.6758,  ..., -0.5703, -2.2344, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.074739, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020538760960334912, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0757,  0.0076, -0.1113,  ..., -0.0791, -0.1260,  0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1099, -0.4238,  0.0476,  ..., -0.0148,  0.1025,  0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5625,  2.6875, -1.9922,  ..., -2.9688, -9.7500,  2.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.8906, -1.0156, -1.2500,  ..., -1.6953, -0.6523, -1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.0985084, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020614121967810206, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874,  0.1826, -0.0272,  ..., -0.0825,  0.0635, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1416, -0.3398, -0.0928,  ..., -0.2490,  0.2695,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7500,  0.8516, -1.3516,  ..., -3.6562,  3.3438, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8594,  1.8672,  0.5273,  ..., -1.7891, -4.6562,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.1223266, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.020691206969786435, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.1367,  0.0801,  ...,  0.0052, -0.0342, -0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3691, -0.2617, -0.0028,  ..., -0.6445,  0.4414, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2969,  0.5078, -6.2812,  ..., -1.6094, -2.2500,  6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031, -0.4473, -1.3984,  ..., -0.8203, -5.2500, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.1462052, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02076785996905528, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0728,  0.0835, -0.0132,  ..., -0.0593,  0.0461, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0378,  0.0830,  0.1182,  ..., -0.1172, -0.0510, -0.1318]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.4062,  0.8828,  ...,  2.6719, -9.5625, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6250,  0.2910, -0.1416,  ..., -0.6094, -4.1250, -9.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.170079, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02084794096299447, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0996,  0.0063,  ..., -0.1074, -0.0055, -0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0889, -0.1094,  0.1235,  ..., -0.0281, -0.0374,  0.0220]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0234,  1.8281, -3.8438,  ...,  0.4961,  2.6094,  3.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0938,  1.5234,  0.2988,  ...,  0.8906, -2.2188, -1.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.194051, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02092432497011032, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0591,  0.0962,  0.0542,  ...,  0.0654,  0.1279, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309, -0.1147, -0.0481,  ..., -0.1299,  0.1475,  0.0476]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2832,  3.6250,  3.0156,  ..., -5.3750,  0.8555,  7.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -1.8359, -2.5625,  ...,  2.9844, -0.7188, -3.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n  \", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2182217, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021000016975449398, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811,  0.0557, -0.0396,  ...,  0.1719, -0.0134, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0476, -0.0801,  0.2949,  ..., -0.0127, -0.0183,  0.0654]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9062, -0.4648,  1.7734,  ..., -7.5625,  4.2500,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906, -1.5234, -3.2656,  ...,  1.3125, -1.9766, -0.9883]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   -\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2419372, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021076640972751193, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0240,  0.0591,  0.0352,  ...,  0.1338,  0.1621, -0.0757]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943,  0.0967,  0.0371,  ..., -0.0011, -0.0679,  0.3086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -1.6406,  3.1562,  ..., -4.3438, -0.5664,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9922, -0.3398, -4.8750,  ..., -0.3789, -2.7031, -2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2661002, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021155678972718306, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.1074,  0.0544,  ...,  0.0684, -0.0049,  0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099, -0.0530,  0.0518,  ..., -0.0972, -0.3008,  0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6562,  3.1094, 10.3125,  ..., -3.0625,  3.4219,  4.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5625,  2.0469,  2.4219,  ..., -0.5039,  0.5352, -0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.2900207, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021232252969639376, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177,  0.1099, -0.0228,  ..., -0.0127,  0.0449, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2617,  0.3340, -0.0825,  ..., -0.0762,  0.1069,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.6875,   0.8594,   0.2656,  ...,   3.7188,  -2.8906,   9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.2500, -0.5898, -3.4688,  ...,  6.4375,  0.2637, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.3138812, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021309557967470028, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0583, -0.1504,  0.0698,  ...,  0.1807,  0.2637, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2285,  0.3379, -0.1128,  ...,  0.1641,  0.4746, -0.1865]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.1875,  -6.6250,  -3.8125,  ..., -10.6250,   4.3438,   2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.8750,  1.2500, -3.9062,  ..., -3.2812, -3.2969, -0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.337891, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021386050968430936, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0503, -0.0125,  0.0413,  ..., -0.1738,  0.0317, -0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1924,  0.1670,  0.0142,  ..., -0.0182, -0.1040,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.8281,  8.8750, -6.1562,  ..., -3.9531, -0.5859, -3.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7305, -1.0938, -0.0923,  ...,  0.3867, -3.8750, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.3617632, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021461141965119168, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767,  0.0488, -0.1123,  ..., -0.0542, -0.1104,  0.0601]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1216, -0.4004,  0.0466,  ..., -0.0398,  0.0669,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000,  0.1562, -0.9375,  ..., -1.1250, -3.3438, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6445, -0.6289, -0.6719,  ...,  2.7500, -3.9062, -1.5078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.385884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021536512969760224, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0476, -0.0083, -0.0206,  ...,  0.0337,  0.0330, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1113, -0.2695,  0.2520,  ..., -0.1514, -0.1641, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9375, -1.5078, -4.0938,  ..., -4.0625, -0.9766,  1.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8984,  1.3359, -0.3555,  ...,  0.5273, -5.8438, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4098966, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021621641964884475, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0439,  0.1162, -0.1611,  ...,  0.1553, -0.0198, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0479, -0.3574, -0.2393,  ..., -0.4551,  0.2305,  0.1709]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0547,  2.3750, -6.9688,  ..., -0.2451, -1.1641,  4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0146, -1.1016,  ..., -0.5078, -4.4688, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4337566, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02169841597788036, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0096,  0.0928,  0.0532,  ..., -0.0352, -0.0603, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747,  0.2539,  0.0547,  ..., -0.2246, -0.0118, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2344,  0.9102,  1.1641,  ...,  4.9688, -7.7188,  0.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7109,  0.4922,  0.6758,  ...,  0.8125, -4.3750, -8.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4574835, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021775971981696784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0310, -0.1074,  0.0457,  ..., -0.1035, -0.0216, -0.0327]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1094, -0.1147,  0.1221,  ..., -0.0488, -0.0317,  0.0396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4375,  1.6562, -1.2969,  ...,  2.7500,  7.8750,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8047,  1.9766,  1.8984,  ...,  0.1162, -1.0703, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.4813144, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02185449897660874, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0879,  0.0674,  ...,  0.0613,  0.1318, -0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416, -0.1089, -0.0486,  ..., -0.1436,  0.1602,  0.0242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9688, -1.1641,  1.2031,  ..., -3.5312, -1.1172,  9.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5859,  0.6172,  1.9609,  ...,  0.7109, -1.3047, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.505211, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.021931943978415802, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0806, -0.0190,  ..., -0.0532, -0.0679, -0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0923,  0.1465,  0.0035,  ..., -0.0111,  0.0613,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.9375, -0.8984, -6.1875,  ..., -0.8555,  4.3438, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938, -0.1982, -6.1562,  ..., -1.6562,  5.1875, -3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5290442, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02200933897984214, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0317,  0.0090,  0.0820,  ..., -0.0247, -0.0322, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0981,  0.3613, -0.0027,  ..., -0.0017, -0.0884,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -6.6875, -4.5938,  ..., -6.1875,  2.6406, -3.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3125, -1.0156, -2.7812,  ..., -0.8555,  0.5039, -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5530927, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02208511198114138, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0219,  0.1196,  0.1914,  ...,  0.0708,  0.0515, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676,  0.2188, -0.1709,  ...,  0.1270, -0.2500,  0.3555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.3750, -6.7812, -4.3750,  ...,  6.4688,  7.1562, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.1250,  3.4375, -2.4062,  ...,  3.8906,  2.7344,  1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.5768108, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02216170498286374, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0273, -0.0435, -0.0129,  ..., -0.1904, -0.0874,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.1562, -0.0962,  ..., -0.2451, -0.2393,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578,  0.7188, -3.1562,  ..., 14.0000,  0.2988,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.7656,  0.2451, -1.4531,  ...,  3.3438,  1.6406,  1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6005602, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02223796797625255, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1016,  0.0618,  0.0422,  ..., -0.3457, -0.0297, -0.1973]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0466, -0.1904,  0.0972,  ..., -0.2559,  0.0410, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -2.6562,  0.5938,  ...,  7.1562, -0.2852,  1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9023,  1.7812, -4.4375,  ...,  2.0156,  0.8711, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6245835, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02231399097945541, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684, -0.1318, -0.0249,  ...,  0.2188,  0.1133, -0.1963]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1147,  0.1069, -0.1426,  ..., -0.0271,  0.1572,  0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.4453, -10.0000,  -0.7852,  ...,  -2.7031,   2.7500,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1201, -1.8281, -1.4688,  ..., -0.2656,  1.4062, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6483202, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022389732985175215, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366, -0.0557,  0.0796,  ..., -0.0884, -0.0156, -0.0352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3418,  0.3984,  0.2227,  ...,  0.0212,  0.0349,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.6875,  -6.5312,   4.3438,  ...,  -3.2969,  -4.3438, -14.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2188, -1.6797, -2.8125,  ...,  0.2754, -1.0312,  0.7148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.671773, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0224688909802353, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0618, -0.1904,  0.0126,  ..., -0.1924, -0.1787,  0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1235, -0.2217, -0.2754,  ..., -0.2910, -0.1924,  0.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2734, -2.5469, -3.1094,  ...,  0.8281,  4.1562, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3125, -3.1406,  ...,  0.6719, -1.9531, -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.6957066, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02254788897698745, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0737,  0.1338,  0.1182,  ...,  0.0132, -0.1328, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1299,  0.1406, -0.0437,  ...,  0.0251, -0.0630, -0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.5312, -7.5625,  ..., -0.4102,  2.2500, 11.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8633,  0.5078, -2.1875,  ..., -1.9922, -1.9297, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7216597, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022623710974585265, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0151,  0.1245, -0.0167,  ..., -0.1641, -0.0703, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0071, -0.0583,  0.3105,  ..., -0.1885, -0.0145,  0.0164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.6875,  0.7734, -1.6406,  ...,  0.0518, -2.4219,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  1.8906, -2.0312,  ..., -0.7656, -1.4609, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7474616, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022700404966599308, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0112,  0.0879,  0.0106,  ...,  0.0201, -0.0186, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009, -0.1143, -0.0466,  ..., -0.2598, -0.4375, -0.0032]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2578, -0.5586,  0.5625,  ..., -0.3496,  6.4688,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062,  2.8594, -1.3828,  ...,  0.0820,  2.7500, -2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7714107, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02278236897836905, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1631,  0.1108, -0.0266,  ...,  0.0109,  0.1299, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.2988,  0.0099,  ..., -0.0869,  0.2178,  0.0167]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -4.8750,  -2.1719,  ...,  -0.2520,  -7.7188,   3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670,  3.8438, -1.2500,  ...,  8.3750, -1.1094, -7.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.7952862, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.022872167974128388, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0510, -0.0762,  ..., -0.1108,  0.0150,  0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0540,  0.1138, -0.0166,  ...,  0.0659, -0.0018, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.1250,  -6.8125, -10.3125,  ...,   4.0625,  -0.1602,   4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2969,  2.1094, -1.8906,  ..., -3.6250,  1.3828, -3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8189988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02295518397295382, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2168,  0.0233,  0.0273,  ...,  0.0330,  0.1582, -0.0840]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0154, -0.3125, -0.1270,  ..., -0.3301,  0.0287, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -6.6875, -1.4062,  ...,  4.6250,  1.1406, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4863, -0.5234, -0.2969,  ..., -2.0000,  1.8438,  0.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.843355, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023033269972074777, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0198,  0.1406,  0.0649,  ..., -0.0564, -0.0479, -0.1191]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500, -0.1738,  0.0129,  ..., -0.2217, -0.0649, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.4688, -5.5938, -2.7500,  ...,  2.8750,  5.8125, -1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9688, -0.1621, -0.5000,  ..., -1.3047, -1.1484,  0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8675199, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023109141970053315, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0532,  0.0967, -0.0732,  ..., -0.0952,  0.0469, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188, -0.0272, -0.2734,  ..., -0.0684,  0.1162, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5938, -5.0000, -3.5781,  ...,  1.0469,  1.5859,  4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3984, -1.1328, -1.9375,  ..., -0.4355, -5.7188, -0.5664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.8923392, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023184363963082433, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1006,  0.0160,  ..., -0.1011,  0.0315, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118,  0.0581,  0.1240,  ..., -0.1387, -0.0684, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4336,  0.5938,  1.0938,  ...,  0.5352, -1.8516,  6.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1182, -1.1250, -2.1875,  ..., -1.5703, -2.4375, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.916582, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02326192996406462, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0195,  0.0835, -0.0437,  ...,  0.0781,  0.0073, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0061, -0.1631,  0.0096,  ..., -0.3008, -0.4219,  0.0188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8438,  0.3516,  5.6875,  ..., -0.7266,  3.2969,  2.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8750,  3.7031, -1.3047,  ..., -4.0938, -3.6094, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9403841, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023338743951171637, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1113,  0.1279,  0.0405,  ..., -0.1992, -0.1016, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2148,  0.3203, -0.0410,  ..., -0.0361, -0.2148,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5625,  -6.4062,  -1.2969,  ...,   2.0000,   5.1250,   3.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3281,  3.0781, -2.2812,  ..., -1.5000, -2.8125, -2.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9641774, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023414856957970187, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2080,  0.0128, -0.0256,  ...,  0.0654,  0.1270, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.2734, -0.0923,  ..., -0.3672,  0.0820, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9688, -9.0625,  7.6562,  ...,  6.9062, 10.3125, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2266,  1.6641, -2.4688,  ..., -1.7656, -4.0938,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100477.9881833, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023489626953960396, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0500,  0.0623,  0.0282,  ...,  0.0586, -0.0444, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.0479,  0.1582,  ..., -0.1953,  0.1475, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250,  3.7188,  1.8828,  ...,  1.1016, -2.7031,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3047, -1.5234, -5.5625,  ..., -1.3906, -2.4219, -0.9805]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.0121274, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02356696195784025, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.1118, -0.0072,  ...,  0.1250, -0.0732, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0679, -0.0918,  0.1777,  ..., -0.1797, -0.5391, -0.0105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0625,  0.6953,  9.7500,  ..., -2.2656,  1.0312,  1.4766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9375,  2.5938,  1.8594,  ...,  1.4531,  0.3867,  0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.036021, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02364348496485036, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0109,  0.1050, -0.0408,  ...,  0.0012, -0.0074, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2471,  0.3691, -0.0383,  ..., -0.0649,  0.0801,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.2500,  -9.3125,  -5.0625,  ...,   5.6875,  -6.5000,   7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5469,  2.3281, -0.9062,  ..., -1.3438, -1.7422, -3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.0601742, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02372009896498639, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2139, -0.0271,  0.0024,  ...,  0.1064,  0.1318, -0.0608]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0115, -0.2559, -0.0386,  ..., -0.3359,  0.1270, -0.2061]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -5.6562,   7.0312,  ...,   6.2812,  -5.5625,  -0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594,  1.6094,  2.7812,  ...,  0.7305, -3.7500,  0.6680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.084094, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023795119966962375, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1279,  0.0610,  0.1250,  ...,  0.0605, -0.0815, -0.3320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0305,  0.1807,  0.1807,  ...,  0.0732,  0.0415, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  0.9141,  1.3359,  ..., 11.5625, -3.4219,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9766, -1.3125, 10.6875,  ..., -3.4531, -0.9375,  1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1081402, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.023874979975516908, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347, -0.0566, -0.0342,  ..., -0.0513,  0.0564, -0.0610]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0288, -0.0859,  0.0654,  ...,  0.1221,  0.1973,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.1562,  7.3125, -1.4688,  ..., -0.3555, -9.6875,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7266, -4.2500, -2.7344,  ...,  0.1006,  3.1719,  2.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1320362, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0239505819772603, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006, -0.0095, -0.0255,  ..., -0.0576, -0.0486,  0.0120]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0564,  0.0041,  ..., -0.0168, -0.0879, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  0.5469, -4.4688,  ...,  3.5625,  1.9688,  0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  1.4453,  0.1514,  ..., -0.2871, -1.5469, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1559138, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024024960977840237, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0796,  0.0369,  ...,  0.0688,  0.1069, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001, -0.0991, -0.0293,  ..., -0.1211,  0.1660,  0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9375, -1.1562, -1.0312,  ..., -6.0312,  2.4844, 13.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3633, -0.9688,  2.0469,  ...,  3.5781, -1.2969,  1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.1798306, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024110831989673898, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0728,  0.0099,  ...,  0.0098, -0.0146, -0.2793]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1289,  0.0012, -0.0649,  ...,  0.0815,  0.1240,  0.0012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.7812,  -0.7578, -10.8125,  ...,   6.2812,  -1.2266,   2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5312, -0.2139, -5.4062,  ..., -1.8438,  4.5625, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.2037988, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024187716990127228, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0645,  0.0752,  0.0420,  ..., -0.0378, -0.0062, -0.0771]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1211,  0.3203,  0.0135,  ..., -0.0082, -0.1045,  0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1875, -5.5938, -9.1250,  ...,  4.6250, -1.0859,  0.5117]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8203, -1.7656, -2.2031,  ...,  0.6602,  2.3750, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.227593, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0242642199882539, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0226,  0.1387,  0.1787,  ...,  0.0791,  0.0752, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.1973, -0.1475,  ...,  0.1367, -0.2158,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.6562, -6.0625, -9.2500,  ..., 15.1875, 10.2500,  0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9688,  1.4062, -3.9062,  ...,  3.5938,  2.3750,  4.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Comb\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.251398, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024341674987226725, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0012,  0.1348,  0.0447,  ...,  0.1445, -0.0183, -0.0005]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2002, -0.1030,  0.1514,  ...,  0.1582,  0.0026, -0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -7.3438,  -8.0625,  ...,  12.4375,  -3.7969,  -4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5547,  5.2188,  2.7969,  ...,  0.6797, -0.0674, -8.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.275257, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024418167988187633, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0947, -0.0052,  0.0195,  ...,  0.0913, -0.3398, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0432, -0.0513,  0.0962,  ..., -0.0189,  0.0396,  0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4688, -3.6250, -0.8984,  ...,  6.1250, -3.2656, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9141,  0.8945, -1.3125,  ...,  3.4219, -3.4219, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**:\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.2988372, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02450268599204719, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0762, -0.1689, -0.0317,  ...,  0.2656,  0.0908, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703,  0.0942, -0.1436,  ...,  0.0193,  0.1523,  0.0952]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7031, -7.8125, -5.8438,  ...,  4.5938,  4.0625,  1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781, -1.3906, -0.6914,  ...,  0.4375,  0.4785, -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.322617, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02458167399163358, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0356,  0.0762,  ..., -0.0459, -0.0674, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.3789,  0.1895,  ..., -0.0210,  0.0732,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.5391, -7.7500, -4.0000,  ..., 10.8125, -2.0000, -0.6953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -2.4375, -3.0625,  ...,  0.6211, -1.2578,  1.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3464081, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02465998099069111, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0359, -0.0537,  ...,  0.0771, -0.1289, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.1865,  0.0121,  ...,  0.0698,  0.0118, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6719, -0.8047, -4.9062,  ...,  6.8125,  2.7812,  2.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2500, -0.4570, -1.2969,  ..., -2.6875, -3.4531,  0.6133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3702164, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02473735598323401, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0200,  0.1289,  0.0327,  ..., -0.0608, -0.0337, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0332, -0.0344,  0.1934,  ..., -0.1465, -0.0430, -0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[10.6875, -3.6719, -3.6875,  ...,  8.3750,  1.2188,  6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.7188, -0.7031,  0.1465,  ..., -2.9688, -0.9023,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.3939815, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02481363898550626, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054, -0.0664, -0.1309,  ...,  0.0214, -0.1543, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0559,  0.1904, -0.0004,  ...,  0.2275,  0.0544,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3594, -5.6875,  3.9844,  ...,  6.1562, -1.3828,  7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1406, -0.9258, -1.3125,  ..., -1.9062, -3.0938, -0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4177897, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.024890723987482488, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1162,  0.1377,  0.0588,  ...,  0.0713, -0.0361, -0.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0342, -0.0493,  0.0762,  ..., -0.1855, -0.5352, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0625, -2.2188,  5.5938,  ..., -0.8398,  1.5469,  2.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  4.0312, -0.9180,  ..., -2.0312, -2.7500, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4417331, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02496563499153126, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0933,  0.1128,  0.0693,  ..., -0.1865, -0.1045, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2334,  0.3105, -0.0630,  ..., -0.0250, -0.1924,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.5625,  -9.6250,  -0.8203,  ...,   3.4844,  -2.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1992,  1.3672, -3.0156,  ..., -0.1895, -0.2227, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4654484, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02504001499619335, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2354, -0.0171, -0.0503,  ...,  0.0532,  0.1201, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0444, -0.2363, -0.0928,  ..., -0.3438,  0.0776, -0.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125, -12.1875,   7.2500,  ...,   2.2656,   2.1406,   3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4180,  0.4590, -0.6484,  ..., -0.5703, -0.8203,  0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.4894354, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025115936994552612, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0425,  0.1504,  ...,  0.0625, -0.0781, -0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0381,  0.1719,  0.1729,  ...,  0.0771,  0.0410, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7031, -2.5938,  1.8906,  ...,  7.6250,  2.5938,  2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4473,  1.0078,  4.7500,  ..., -1.0312, -2.2500,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.5129302, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025192039989633486, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0010, -0.1572, -0.0649,  ...,  0.0625,  0.2139,  0.0232]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0625,  0.0036, -0.0859,  ...,  0.2480,  0.5195, -0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0781, -1.7422, -1.0234,  ...,  4.4062, -0.0391,  2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.7695, -0.7578,  ..., -0.6133, -1.3906, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.5368536, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025270967991673388, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0332,  0.0046,  ..., -0.0212,  0.0623, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0640, -0.0693, -0.0415,  ..., -0.1504,  0.0903, -0.0571]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9219, -3.2031,  0.5391,  ...,  4.2500,  0.0820, 10.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844, -0.6797, -1.4531,  ..., -1.8125, -2.2812,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.560751, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02535699898726307, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0186,  0.0253,  0.0117,  ..., -0.0874,  0.0732, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0615,  0.0513, -0.0618,  ...,  0.0188,  0.0708,  0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5547, -1.0469,  6.8125,  ...,  2.9531,  2.4062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0459, -1.0234, -3.2188,  ..., -1.6328, -2.2500, -0.0081]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.58463, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025433412985876203, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0527, -0.0386,  ...,  0.0664,  0.0022, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0240, -0.1709, -0.0282,  ..., -0.3086, -0.3984,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5000, -0.7656, 12.1875,  ...,  6.1875,  4.1875, -0.4570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.6250,  0.8750,  1.3438,  ..., -0.9258,  0.9219, -1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6083503, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02550977598002646, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1030, -0.0023,  0.0203,  ...,  0.0850,  0.0026, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.2637,  0.1865,  ...,  0.1060,  0.1064,  0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4688, -6.6250, -3.4531,  ...,  0.6602, -1.6172,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0854,  0.9961, -1.7812,  ..., -0.4199, -1.5156, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6321537, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025584806979168206, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2471, -0.0618, -0.0034,  ...,  0.1357,  0.1436, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0233, -0.3008, -0.1611,  ..., -0.2832,  0.0168, -0.1748]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4062, -6.6562,  7.9375,  ...,  2.7500,  5.3750,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0417, -0.4922,  0.5352,  ..., -0.2617, -2.3281,  0.5430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6559057, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025661189982201904, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0752,  0.0269,  0.1523,  ...,  0.0583, -0.1494, -0.3008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0168,  0.1836,  0.0923,  ...,  0.0825,  0.0583, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9297, -0.1719, -0.7578,  ...,  6.3125,  1.7500,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8789, -1.1250,  3.6719,  ...,  1.7734, -0.9141,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.6797068, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025742572979652323, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0182, -0.1689, -0.0547,  ...,  0.0217,  0.1631, -0.0033]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0286,  0.0023, -0.0654,  ...,  0.2734,  0.5156, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[5.6875, 0.1289, 2.8594,  ..., 1.2500, 1.4062, 0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0659,  0.7109,  0.1562,  ..., -1.1172, -0.9180, -0.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7034268, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02581966698926408, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0549,  0.0332,  0.0099,  ..., -0.0184,  0.0518, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0376, -0.0659, -0.0549,  ..., -0.1289,  0.0723, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1875, -3.2812, -0.4141,  ...,  1.1328,  1.9219,  0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.4336, -2.9062,  ..., -0.8516, -2.3594, -0.9336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.727219, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025895949991536327, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.0184,  0.0352,  ...,  0.0082,  0.0265, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0918, -0.0588,  0.1465,  ..., -0.0466,  0.0124, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3125, -3.1250, -1.3125,  ...,  5.4062,  0.4961,  5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1484, -0.9688, -1.1094,  ..., -1.9688, -5.0312, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7512074, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.025982582999859005, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0193,  0.0452, -0.0125,  ..., -0.0120,  0.0055, -0.1445]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0393,  0.1719, -0.0400,  ..., -0.0732, -0.0047, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -10.0625,   0.3867,  ...,   5.6250,  -7.6875,   4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6406, -1.0234,  2.0312,  ...,  0.5117, -3.4062,  4.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7749681, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026058976000058465, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0718, -0.1514,  ...,  0.0386, -0.0801, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0664,  0.2441,  0.0903,  ...,  0.2598,  0.0879,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7969,  4.0625,  3.8594,  ..., -1.9688, -4.1562,  7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2031, -0.1260, -4.3125,  ..., -1.0078, -1.7500, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.7988884, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02613503900647629, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1094,  0.0815, -0.0178,  ...,  0.0918,  0.0176, -0.0698]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0586, -0.0369,  0.1084,  ..., -0.1875, -0.5000, -0.0019]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.1875,  0.7656, 11.2500,  ..., -5.6250,  1.1875,  3.7031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  4.5938,  2.2344,  ...,  0.4590, -0.0068, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8229473, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026210971002001315, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0562,  0.0022,  ..., -0.0474,  0.0284, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324,  0.3555, -0.0986,  ..., -0.0830,  0.1240,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3750,  -9.6250,  -3.3594,  ...,   2.3438,  -7.2812,  10.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984,  2.0156, -3.7969,  ...,  0.6758, -2.5000, -2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right`\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.846756, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026287083004717715, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2393, -0.0815, -0.0216,  ...,  0.0889,  0.1406, -0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190, -0.2344, -0.0752,  ..., -0.2988,  0.1523, -0.2363]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5625, -13.8125,   4.3438,  ...,  -0.2676,  -1.4844,   4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.1562,  1.7891,  ...,  2.5000, -2.3906,  3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8707376, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02636293500836473, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221,  0.0261,  0.1299,  ...,  0.0630, -0.0918, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513,  0.1865,  0.1562,  ...,  0.0654,  0.0383, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2969,  0.1484, -3.4219,  ...,  8.2500,  4.0312,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9805, -2.7188,  3.7188,  ...,  0.7969, -0.0273,  3.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.8946636, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026439178007422015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0099, -0.1631, -0.0752,  ...,  0.0723,  0.1934, -0.0046]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0009,  0.0422, -0.0898,  ...,  0.2598,  0.4883,  0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.0156, -1.1172, -6.3438,  ...,  5.8750,  0.0371,  7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3008,  0.2812,  0.8047,  ..., -0.1650, -1.1797, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9180613, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026514359007705934, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1099,  0.0027,  0.0383,  ..., -0.0232,  0.0923, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0320, -0.0339, -0.0654,  ..., -0.0601,  0.1875, -0.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.2969, -12.3125, -12.0000,  ...,   7.2188,   3.1406,  -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0938,  0.3789, -2.9531,  ...,  1.6797, -0.6289,  0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.941552, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026602524012560025, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.1074,  0.0518,  ...,  0.1270, -0.0227, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.3750,  0.0454,  ..., -0.0811,  0.1416, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -7.3750, -6.9688,  ...,  9.1250,  7.3750,  4.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9688, -2.0781, -2.2656,  ..., -4.2500, -4.5625, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9654737, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026682735013309866, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0579,  0.0874, -0.0493,  ..., -0.1338,  0.0413, -0.1113]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.0718,  0.2422,  ..., -0.1631, -0.0781, -0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.3750, -9.4375, -3.2188,  ...,  9.7500,  9.4375,  0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.9531,  0.2734, -1.8750,  ..., -1.8984,  0.0215,  0.4941]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100478.9893572, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026758648018585518, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0508, -0.0854, -0.0040,  ..., -0.0007,  0.0693, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598, -0.2168,  0.0530,  ..., -0.1465, -0.1455,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9062, -9.4375, -2.0938,  ..., 18.6250,  5.7188,  1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -0.0542,  2.8750,  ..., -1.8750,  0.3125,  3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0133228, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02683546202024445, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0830,  0.1348, -0.0884,  ...,  0.0559, -0.0918, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1270,  0.2422,  0.1235,  ...,  0.3594,  0.1133,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125, -5.4375,  9.1875,  ...,  7.7812,  2.5781,  1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7344, -1.5000, -1.7656,  ..., -0.1504,  1.2734, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0372024, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02691162501287181, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0210,  0.0356,  ..., -0.0613,  0.1416, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0437,  0.0105, -0.0072,  ...,  0.1157,  0.1147,  0.0055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0938, -1.9453, -2.7031,  ...,  4.6250,  2.7031,  5.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8125,  0.5273,  0.2119,  ...,  0.7578, -0.1709, -0.9102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\n\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.061067, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.026987628007191233, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0284,  0.1709,  ...,  0.1689,  0.0952, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0986, -0.1484, -0.0060,  ..., -0.0986,  0.1914, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   1.6172,  -0.0391,  ...,  -5.9688,  -2.2500,  -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2500, -0.4863,  0.0781,  ...,  1.3203,  3.2188, -0.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.0848842, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027064663008786738, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0212, -0.0703,  0.1025,  ...,  0.1021, -0.0850, -0.1396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0171, -0.0498, -0.2207,  ...,  0.0391, -0.0527, -0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6250, -5.1250,  7.6875,  ...,  3.2656,  4.0938, -1.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5391, -0.7344, -1.0625,  ..., -2.1875,  1.5078, -1.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1087656, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027141297003254294, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2559,  0.1875, -0.0498,  ..., -0.0312,  0.0388, -0.0098]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0640,  0.4062,  ..., -0.5078,  0.1904,  0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250, -8.5625,  7.8125,  ...,  0.5000,  3.3906, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7578, -0.7656,  2.5625,  ..., -1.5703,  0.0635, -0.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1326554, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027218000002903864, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.1895, -0.1348,  ..., -0.0796, -0.0898, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1050, -0.2217, -0.1094,  ..., -0.2578,  0.0703, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6562, -7.5625, 21.6250,  ...,  5.4062,  1.1719,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7500, -3.2500,  1.2031,  ..., -2.8594, -0.7188, -1.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1562338, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027293591992929578, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.1206, -0.1206,  ..., -0.1953, -0.0688, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1494, -0.2441, -0.2275,  ..., -0.1738, -0.0938, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1719, -9.0000,  2.7188,  ...,  0.7305,  3.1875, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  0.0698, -0.8516,  ..., -0.8828,  0.1074,  0.4902]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.1801734, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027377840000553988, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0012, -0.0439,  ..., -0.0369, -0.0140, -0.0579]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1030, -0.0217, -0.1523,  ..., -0.0077,  0.1562, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312, -16.2500,  27.8750,  ...,   1.1719,  11.5000,  -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062, -1.9688,  2.3281,  ..., -0.5781, -0.9961, -0.9609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2040823, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027453270988189615, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0413,  0.0129, -0.0437,  ..., -0.0786, -0.1162, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.1797, -0.3887,  ..., -0.2637, -0.2344,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0000, -8.7500, -2.9844,  ...,  4.1562,  1.4688, -0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4766,  1.6172, -0.0854,  ..., -1.3359, -1.1250,  1.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2281132, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027529653991223313, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0303, -0.0435, -0.1475,  ..., -0.0703, -0.0211, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6094, -0.1226, -0.0938,  ..., -0.1807, -0.1206,  0.6289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.5312, -5.8438,  5.9688,  ..., 12.3125, -4.9375,  3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.7812,  1.1641,  ...,  1.0781, -2.1406, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2518485, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027605595998466015, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0586, -0.1641,  0.1133,  ...,  0.0767, -0.0427,  0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0630,  0.0786,  0.1553,  ...,  0.1128, -0.2041, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -2.7812,  1.8047,  ..., -1.8281, -6.3125,  1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844,  0.7773, -1.2500,  ...,  0.1641,  0.1748,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.2756414, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02768181898863986, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608, -0.0129,  0.0122,  ...,  0.0076,  0.1226,  0.0276]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0708, -0.1338, -0.0889,  ..., -0.0206,  0.0352,  0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -7.1875,  2.5156,  ..., -8.6875, -3.8906, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594, -0.1201, -2.0000,  ..., -0.4492,  1.2578,  1.7422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.299623, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027757460993598215, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0439, -0.0591,  ..., -0.0391,  0.0884, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4590, -0.4512,  0.0554,  ...,  0.0747, -0.1299,  0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9062, -6.6250, 10.1250,  ..., -2.1719,  0.3555,  0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430, -1.3672, -0.8438,  ..., -0.4688,  0.6094, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.3237708, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027841918999911286, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0596,  0.0623,  ..., -0.0381,  0.0376,  0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.0786,  0.2207,  ..., -0.2012,  0.0067, -0.0085]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.8125, -15.8125,  12.0000,  ...,  -5.9375,  -1.5000,   2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.5820,  0.6289,  ..., -1.2969,  0.2344, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.347414, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027918523002881557, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773,  0.2227,  0.0238,  ...,  0.0247,  0.0349, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2490,  0.3574,  0.0471,  ..., -0.1709, -0.4297, -0.1108]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-16.5000, -12.6250,   1.4297,  ...,  -7.5000,   4.1562,   4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  0.6641, -1.0547,  ..., -1.3125, -1.4297, -3.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.371197, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.027994495001621544, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2451,  0.1758, -0.0195,  ..., -0.0205,  0.0457,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.1328, -0.2578,  ...,  0.5273, -0.3828, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.0938, -12.7500,  -6.4375,  ...,   2.8906,   4.5000,   1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398, -1.0625, -1.6719,  ...,  1.4688, -0.9492, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.3950334, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02807315200334415, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1221,  0.0918,  ..., -0.1729, -0.0498, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0728,  0.0177, -0.1318,  ...,  0.1807,  0.2461, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.9062, -13.1250,  -0.8086,  ...,   1.7656,   7.6875,  -6.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773, -0.8750, -0.4375,  ..., -3.1406, -0.1709, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4187887, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02814880399091635, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0962,  0.0115,  0.0175,  ..., -0.0393,  0.0106, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0674,  0.2178,  0.0227,  ..., -0.1045, -0.1963, -0.0464]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -17.8750,  -0.9297,  ...,  -3.5938,  -7.9062, -11.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7695,  0.1035, -1.4766,  ..., -3.2031,  0.6719, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4426644, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028224705994944088, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1562, -0.0378,  0.0182,  ...,  0.1494,  0.0625, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.2305, -0.3789,  ...,  0.4258,  0.2188, -0.1924]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125,  -6.0312,   6.8750,  ...,   1.9375,   2.1250, -12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.9062, -1.8594, -1.3125,  ..., -1.2969,  2.6406, -3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4665194, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02829955698689446, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0598,  0.0107, -0.0742,  ..., -0.2295,  0.1069,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5078, -0.2363, -0.0669,  ..., -0.2314, -0.0986, -0.0238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.5000, -0.0898,  4.7188,  ..., -2.6562,  0.9609,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676, -2.4531, -2.4844,  ..., -2.2031, -1.2578,  0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.4902892, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028375970985507593, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0349,  0.0054, -0.1611,  ..., -0.0718,  0.0250,  0.0086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0013,  0.0413, -0.1226,  ..., -0.3438, -0.0850, -0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,  -1.7188,   5.6875,  ...,  -5.1875,   9.8125,   3.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5469, -1.9766,  0.1289,  ..., -1.4531, -0.2061, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.5146, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028459096982260235, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1807, -0.1709,  0.0364,  ...,  0.0598,  0.0195,  0.0640]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2520,  0.2080, -0.1641,  ...,  0.1455,  0.1533, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000,  2.5938,  1.1719,  ..., -6.3750,  6.4375,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938,  0.0427, -1.8594,  ..., -3.8594, -1.5469, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.538669, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028562069972394966, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.3223,  0.0064, -0.0708,  ...,  0.0276, -0.0275, -0.0544]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0064, -0.1230, -0.5664,  ..., -0.6328, -0.3828, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8438, -1.8672,  7.5000,  ..., -0.9336,  4.5000,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0781, -2.8281, -1.2969,  ..., -2.0781, -1.7109, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.562401, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02863785198132973, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957, -0.0430,  0.0432,  ..., -0.0498,  0.0767, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1074, -0.0771, -0.1147,  ..., -0.0253,  0.2275,  0.0713]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   6.5625,   2.3750,  ..., -13.1250,   2.8438,   4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7656, -2.5156,  1.3281,  ..., -1.0078, -0.3672, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.5859363, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028712861982057802, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1445, -0.1128, -0.1245,  ...,  0.1221,  0.0303,  0.0027]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4629, -0.0864,  0.0703,  ...,  0.5273, -0.0967,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -0.3594,   6.1562,  ...,   0.1953,   1.3594,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4766, -1.0859, -1.1172,  ..., -2.2188,  0.0085, -1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6097744, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02879184998164419, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.1123,  0.0186,  ..., -0.1992, -0.0320, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1514,  0.1572, -0.1187,  ...,  0.1924,  0.1816,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.3750,   3.2812,  -1.8750,  ..., -12.3750,   8.5000,   7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000,  1.2422, -0.9453,  ..., -2.9844,  0.1021, -0.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6335618, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028868001987575553, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0630,  0.1514,  0.1553,  ..., -0.1582,  0.0019, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2471, -0.1099,  0.0723,  ...,  0.3711, -0.4961,  0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.7500,   1.0312,   0.1992,  ...,   4.0938,   4.3750,   9.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.1094, -5.4062,  ..., -1.8984, -0.5820,  1.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6573033, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.028947330996743403, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0574,  0.0723, -0.0420,  ..., -0.0859,  0.0359, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0352,  0.1021,  0.1250,  ..., -0.0732, -0.1011, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.1250,  8.1875, -0.6719,  ...,  2.4219,  5.7500, 12.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0078,  1.5781, -1.8438,  ...,  0.5859, -0.0566,  0.5547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.6811917, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029022853006608784, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0386,  0.0879, -0.0522,  ...,  0.0427, -0.0110, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1133, -0.0112,  0.0364,  ...,  0.1602, -0.3848,  0.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.2500,   0.9219, -12.6250,  ...,   4.2188,   7.0000,   3.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2891,  2.0156, -2.8281,  ..., -3.8281, -0.8047, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7050457, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029114655015291646, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0260, -0.1514, -0.1475,  ..., -0.0159, -0.0226, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0510, -0.3652, -0.0342,  ...,  0.0187, -0.2676, -0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.5469,  1.3438,  5.7188,  ...,  5.8125,  2.0469,  8.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6523,  2.4375, -3.6094,  ..., -1.0938,  1.4531,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7289076, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02919089801434893, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1738,  0.0767, -0.0840,  ..., -0.2275, -0.0659, -0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0212, -0.0106,  0.4824,  ...,  0.2852, -0.0461, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.2188,  2.3750,  3.4844,  ...,  9.9375, -0.4727,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1250,  0.5898, -1.1719,  ..., -0.6016, -0.0420,  0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7527108, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029266059005749412, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1582, -0.1445,  0.0620,  ..., -0.0869, -0.0208, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  0.0023,  0.0089,  ..., -0.0242,  0.0898, -0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.2500, -0.5547,  ..., 11.5000,  3.2188, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2275,  0.6250, -1.0469,  ..., -0.0859, -1.0625, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.7765646, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029342402995098382, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0801,  0.0544,  ..., -0.0211,  0.0549, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1040,  0.0491,  ...,  0.0072,  0.0238,  0.0171]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.9375, -0.7656,  0.8594,  ..., -0.7305, -9.1250, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5977, -0.3730, -0.0225,  ...,  1.2656,  0.9297, -2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8005419, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029417894998914562, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0281,  0.0610,  ..., -0.0327, -0.0043, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1436, -0.1426, -0.0371,  ..., -0.0386, -0.0344,  0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3750, -1.5547, 11.2500,  ..., -3.2656,  2.8906, -4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8477, -0.2539,  1.5938,  ..., -3.1250, -0.1426, -3.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8242943, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029495189985027537, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.0415,  0.0581,  ...,  0.0417,  0.0078, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309,  0.0332, -0.1396,  ..., -0.4316, -0.1396,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828, -4.5312,  4.1250,  ..., -1.6562,  4.2188, -7.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3125,  0.7148, -1.3828,  ..., -7.6250,  4.3750, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8482041, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02957966798567213, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0415, -0.0096,  0.1021,  ...,  0.0776,  0.0815, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0050, -0.1221,  ..., -0.3262, -0.1348,  0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4688, -4.8750,  7.4688,  ...,  1.4062,  5.8438, -8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0703, -2.7031, -1.0391,  ..., -2.7812,  4.6562, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.8720703, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029654597979970276, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762, -0.1172, -0.0063,  ..., -0.0023, -0.1035,  0.0486]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141, -0.4551,  0.1147,  ...,  0.1235,  0.0574, -0.3574]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5000,  4.0312,  6.4375,  ..., -1.4062, -0.3789, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1406,  1.1094,  1.7188,  ..., -0.5039,  0.7148, -1.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.895753, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029729778980254196, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0337,  0.1206,  0.1475,  ..., -0.2578,  0.0342, -0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0282,  0.0811,  ..., -0.0454,  0.0123, -0.0094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2734,  5.0625, -2.7344,  ...,  0.8086, -3.0312,  7.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1328,  0.7188,  0.2021,  ..., -0.3730, -1.0000, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9195607, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02980459897662513, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684,  0.0291, -0.0141,  ..., -0.2676,  0.2520, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1631, -0.1387, -0.2373,  ..., -0.2490, -0.1162, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[2.7656, 0.9336, 2.6562,  ..., 0.2188, 5.0000, 0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2148,  0.8984, -1.0781,  ...,  0.7930, -0.0137, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9433067, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.02987988997483626, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0090,  0.1108, -0.0554,  ..., -0.0361,  0.1943, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441,  0.6289,  0.2275,  ...,  0.2041,  0.2197,  0.2432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.1250,  -0.7500,   0.2363,  ...,   3.2969, -11.5625,   0.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3047,  0.3848,  0.3164,  ...,  5.1562, -5.5312,  0.8555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.967086, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.029955231977510266, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2461, -0.0544,  0.0674,  ..., -0.0610, -0.0144,  0.0054]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.0081,  0.0859,  ...,  0.1299, -0.2852, -0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9375,  4.5000, -0.5391,  ...,  1.3750, -4.6875,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297,  0.2812,  0.2314,  ..., -0.7969, -1.5156, -0.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort,\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100479.9911635, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03003165496920701, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0178,  0.0728,  ..., -0.0322,  0.0532, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.1416, -0.1738,  ..., -0.0430,  0.0239,  0.0415]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234,  4.8750,  1.5469,  ..., -0.4570, -6.0938,  8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719,  0.2988,  0.0669,  ..., -0.1436, -0.8555,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0149488, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030107697966741398, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0996, -0.0209,  0.1465,  ..., -0.0757,  0.0540,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324, -0.0859,  0.1348,  ..., -0.3613, -0.0996, -0.0398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125,  7.4062,  5.3125,  ...,  6.2188, -3.4375, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344, -1.3672, -1.2422,  ...,  0.4141, -0.6641, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0387342, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030190593970473856, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0215,  0.1338,  0.0410,  ..., -0.0957, -0.1006, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.0009, -0.3359,  ..., -0.1670, -0.4277,  0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7891,  2.6875,  6.7188,  ...,  7.1250, -9.3750,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0066,  0.7031, -2.0156,  ...,  0.9688, -0.4707, -1.8516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0623264, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030265694978879765, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177, -0.0170,  0.2275,  ..., -0.1553,  0.0057, -0.0432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1631, -0.0938, -0.1016,  ..., -0.1602, -0.0435, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875, -0.5234, -1.7656,  ...,  8.5000, -1.2422,  8.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8906, -0.5039, -0.8945,  ..., -1.9609, -1.4844, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.0861878, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030352066969498992, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0002,  0.0420, -0.0060,  ..., -0.1206,  0.0767, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0201,  0.0253,  0.2930,  ..., -0.0767, -0.0199,  0.0149]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  2.5625,  1.8672,  ...,  6.5000, -5.3750,  6.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2656, -1.2109, -1.2422,  ..., -2.2969, -0.1973,  0.2354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1100254, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03042795897636097, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957,  0.0454,  0.0359,  ..., -0.3926,  0.1367, -0.0366]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0630, -0.0469,  ..., -0.3848, -0.1592,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.8281,   3.9688,  -2.0000,  ...,   2.5312, -14.2500,   7.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3320,  0.0850, -0.5547,  ..., -0.4473, -0.9648,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1337886, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030505303977406584, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1123, -0.0038,  0.0229,  ..., -0.2793,  0.0962, -0.0080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.0410, -0.0894,  ..., -0.0298,  0.1982, -0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.8438, -5.9375, -3.8125,  ..., -0.3125, -4.8438,  2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8750, -0.6250, -1.7891,  ...,  1.2578, -1.4453, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.157694, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030580945982364938, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2617,  0.0400,  0.0618,  ..., -0.1680, -0.0003, -0.1602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1104, -0.2949,  0.1084,  ...,  0.1895, -0.1719, -0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.4375, -0.2031,  3.8750,  ...,  2.3750, -1.0312,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0493, -1.1484,  0.4688,  ..., -1.4219, -1.3672,  1.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.1815693, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.0306617079913849, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0476,  0.0127,  ..., -0.1367,  0.0796, -0.1289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1670, -0.0444,  0.2988,  ...,  0.0427, -0.1104,  0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7188, -1.5312,  9.4375,  ..., -4.6562, -5.9062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172,  0.1016, -1.0859,  ..., -1.5156,  0.0703, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2054832, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03073869198851753, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0327, -0.0640, -0.0123,  ..., -0.1001,  0.0176, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0008,  0.0757,  0.1025,  ...,  0.0762, -0.0491,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4375,  6.1562,  6.3750,  ..., -1.3750, -3.0312,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.0134, -0.7930,  ..., -1.3906,  1.1406,  1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2293215, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030815685997367837, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0447, -0.0603,  ..., -0.0703, -0.0245, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0522, -0.0640,  ..., -0.2793, -0.0306,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2500,  5.0625,  9.1250,  ..., -5.1250,  1.0234,  1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4062, -2.8906, -0.6445,  ...,  1.0234,  1.0547, -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2532783, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.030896166994352825, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787, -0.1191,  0.2100,  ...,  0.1465, -0.0291, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1270, -0.2246,  0.1992,  ...,  0.1045, -0.0183, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531,  3.1562, -0.0391,  ...,  1.2969, -3.6250,  6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2500, -0.2168, -0.1426,  ..., -0.3027, -0.8477, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.2771206, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03097930298827123, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0114,  0.0356,  0.0056,  ..., -0.1289,  0.0879, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0173,  0.1099,  0.3516,  ..., -0.0435, -0.3496,  0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7500,  1.6953, -7.7812,  ...,  4.0938, -1.1094,  3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0718,  0.2598, -1.6484,  ..., -0.8633, -2.0312,  2.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.300802, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031054122984642163, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.0154,  0.1089,  ..., -0.1455, -0.1245, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1572, -0.0182,  0.3906,  ..., -0.0058, -0.1689,  0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[1.6641, 3.2812, 0.8984,  ..., 5.5312, 3.2188, 4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1895,  2.2188, -3.3281,  ..., -1.4766,  1.6953,  1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.3248794, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031129493974731304, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0854,  0.0197,  ..., -0.1748, -0.0942, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0698, -0.1543,  0.5625,  ...,  0.2148,  0.0034, -0.2988]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3438e-02,  2.9844e+00, -6.4453e-01,  ...,  1.2812e+01,\n",
      "         -1.1719e-02,  1.6953e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.2969, -1.0781,  ...,  0.7852, -2.5781,  1.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.3483107, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031205886974930763, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206,  0.0203,  0.1504,  ..., -0.0659, -0.0781, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1953, -0.3574, -0.0820,  ...,  0.1738,  0.3066, -0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.8555,  9.0000, -4.0625,  ...,  7.0625,  2.2344,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7812,  0.2383,  0.2852,  ...,  0.9141, -1.1172, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.372078, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031282189971534535, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0771,  0.0625,  0.0144,  ..., -0.1943,  0.0601, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363, -0.1445, -0.0403,  ..., -0.3516, -0.0908,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.6641,  8.7500,  2.0312,  ...,  7.0625, -4.2500, -0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6953,  0.3438, -0.9766,  ..., -1.0938, -2.1094,  0.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.395808, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031358382970211096, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128,  0.0117,  0.1963,  ..., -0.0376, -0.0874, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.0013, 0.2061, 0.1387,  ..., 0.1162, 0.0574, 0.0244]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.9375, -2.9375,  0.3203,  ..., 17.1250, -4.9062, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.6992,  7.5312,  ..., -6.7188, -2.8906,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.4196804, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03143473598174751, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0374, -0.0938,  0.0074,  ..., -0.0928,  0.0437, -0.0014]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0215, -0.0178,  0.0752,  ...,  0.1631,  0.1758, -0.0107]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531e-03,  1.3359e+00, -1.2578e+00,  ...,  4.9375e+00,\n",
      "         -2.6406e+00, -3.5938e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -3.6719, -1.4141,  ..., -4.2500,  3.4531, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.4432218, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.03151054798217956, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0327,  0.0162,  ..., -0.0835, -0.0378,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1514,  0.0977,  0.0483,  ...,  0.0200, -0.0908, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  1.5312, -1.5625,  ...,  6.8438, -0.9727, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7656,  0.5703, -0.8086,  ..., -0.2061, -1.4453, -1.1797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13), cumulative_logprob=None, logprobs=None, finish_reason=None, stop_reason=None)], finished=False, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.467087, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=None, scheduler_time=0.031605204989318736, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0674,  0.0364,  ..., -0.0530,  0.0537, -0.0184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1465, -0.0742,  0.0479,  ..., -0.0052,  0.0254,  0.0199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7500,   1.5156,   2.7812,  ...,   2.5156, -13.9375,  -9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.7188,  0.4277, -0.1523,  ...,  1.1328, -0.5234, -0.8867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13, 151645), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1755100470.3663733, last_token_time=1755100480.491065, first_scheduled_time=1755100470.8469248, first_token_time=1755100470.9987304, time_in_queue=0.48055148124694824, finished_time=1755100480.4911935, scheduler_time=0.031681798995123245, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]\n"
     ]
    }
   ],
   "source": [
    "while enc_dec_engine.has_unfinished_requests():\n",
    "    enc_dec_output = enc_dec_engine.step()\n",
    "    print(enc_dec_output)\n",
    "\n",
    "# Create file terminate.json\n",
    "with open(\"test_py_files/terminate.json\", \"w\") as f:\n",
    "    f.write(\"{}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95cd0d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_engine.abort_request(\"123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "323213fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4d35eb7d54507bb59192bf55fb831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6559de474a6648a0b5179f7cb065d117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34],\n",
      "       device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3809, -0.1367, -0.2852,  ...,  0.3066, -0.1533,  0.1250],\n",
      "        [-0.3594, -0.1338, -0.2285,  ..., -0.1572, -0.1719,  0.1963],\n",
      "        [-0.1992, -0.0483, -0.1216,  ..., -0.0113, -0.0449,  0.1367],\n",
      "        ...,\n",
      "        [-0.2207, -0.0586, -0.0820,  ...,  0.0518, -0.1206, -0.0496],\n",
      "        [ 0.0280, -0.0991, -0.1699,  ..., -0.0068, -0.0752, -0.0703],\n",
      "        [-0.0737, -0.0249,  0.0583,  ...,  0.0388, -0.0270,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742, -0.0115,  0.2324,  ...,  0.0344, -0.3594, -0.0618],\n",
      "        [-0.1201, -0.2344, -0.0623,  ..., -0.0669, -0.0030,  0.1045],\n",
      "        [-0.1182,  0.0201, -0.1138,  ..., -0.0072, -0.1406,  0.0630],\n",
      "        ...,\n",
      "        [-0.1846,  0.1387,  0.0173,  ...,  0.0659,  0.0256,  0.0140],\n",
      "        [-0.1406,  0.0542,  0.0212,  ...,  0.0183, -0.0200, -0.0776],\n",
      "        [-0.1357,  0.0134,  0.1758,  ..., -0.0275,  0.0166, -0.0791]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([35, 3584]) and residual: torch.Size([35, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.1000e+01,  1.6094e+00,  1.1406e+00,  ...,  3.8125e+00,\n",
      "          1.4188e+01, -3.4688e+00],\n",
      "        [-1.1875e+01,  2.0469e+00,  1.7500e+00,  ...,  1.9688e+00,\n",
      "          1.4625e+01, -3.8438e+00],\n",
      "        [-1.0500e+01,  2.0000e+00,  1.3125e+00,  ...,  3.7500e+00,\n",
      "          1.4375e+01, -3.2500e+00],\n",
      "        ...,\n",
      "        [-9.2500e+00, -1.8125e+00, -1.1875e+00,  ..., -1.7266e+00,\n",
      "         -4.3125e+00, -7.3438e+00],\n",
      "        [ 7.8125e-01, -1.2656e+00, -7.8125e-03,  ..., -4.5625e+00,\n",
      "         -7.5938e+00, -1.0375e+01],\n",
      "        [ 9.8438e-01, -1.3281e-01,  6.4062e-01,  ..., -3.1562e+00,\n",
      "         -5.5000e+00, -1.0125e+01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9062, -7.0000, -3.9844,  ...,  8.5625, -4.0312, 10.8125],\n",
      "        [-5.2188, -8.6875, -5.5625,  ..., 10.9375, -4.8438, 11.3750],\n",
      "        [-5.4062, -8.0000, -4.7188,  ..., 10.0000, -4.1250, 10.7500],\n",
      "        ...,\n",
      "        [ 0.9414, -1.9375,  4.8125,  ...,  0.4766, -1.8516, -4.4688],\n",
      "        [ 2.2031,  1.0703,  0.4805,  ...,  1.6719,  1.9453,  2.4688],\n",
      "        [ 0.6523,  0.8906,  0.7188,  ...,  2.7031,  3.6719,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([35], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0027, -0.0082, -0.0461,  ..., -0.0491,  0.1787,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0121,  0.0410, -0.0298,  ...,  0.3633, -0.3359,  0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  1.3672, -0.9336,  ..., -7.7188, -5.8438,  9.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1128,  0.9531,  0.7695,  ...,  1.2891, -1.1250, -0.0064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([36], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0192, -0.0374,  0.0498,  ...,  0.0044,  0.1611, -0.0530]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0120, -0.2891, -0.0610,  ...,  0.6523,  0.1826, -0.4238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250, -5.4375, -6.4062,  ..., -1.7031, -0.2949, -7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5898,  1.6641, -1.6484,  ...,  2.1875,  0.9297,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([37], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0291,  0.0728,  0.0144,  ..., -0.0044,  0.0299, -0.0332]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2344,  0.2383,  0.0127,  ...,  0.2158,  0.3789,  0.0071]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.2500,  -0.7734,  -5.0312,  ...,   7.0000, -17.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.8906, -0.3125, -1.7188,  ...,  1.7656,  0.4980, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([38], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.3301, -0.0713,  0.0332,  ..., -0.0085, -0.2246, -0.0015]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0991,  0.0109,  0.1865,  ...,  0.1963, -0.3438, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   5.9062,  -9.1250,  ...,   3.5938,  -8.8125,   2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3906,  1.1953,  1.8438,  ..., -1.9766, -0.7305, -0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([39], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1357,  0.0566, -0.1523,  ..., -0.1436,  0.0110,  0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0408, -0.1445,  ..., -0.2314,  0.0510, -0.0215]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250,  0.7656, -3.4375,  ...,  8.6875,  7.1562,  1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320,  0.5430,  1.5625,  ..., -1.4062, -2.8438, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([40], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0469,  0.0105,  ..., -0.1279,  0.0559,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0762,  0.3828,  0.0613,  ..., -0.0522,  0.0352, -0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.5312, -2.3438,  5.1250,  ..., -1.6250,  2.8281, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0474,  0.8672, -1.6094,  ..., -2.1406, -1.1719,  0.4199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([41], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569, -0.1079, -0.0417,  ..., -0.1465,  0.0635,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0303,  0.1309, -0.1641,  ..., -0.1768, -0.2598, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -1.1875,  4.4062,  ...,  1.3906, -0.9727, -7.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3066,  1.6953, -0.7852,  ..., -1.0469,  1.6719,  0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([42], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0425,  0.0289,  0.0189,  ...,  0.0046,  0.0425, -0.0072]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.2139, -0.1885,  ...,  0.0977,  0.0295, -0.0557]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.1250, -2.7656,  9.2500,  ...,  2.7031,  3.0312, -7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9688,  2.0000, -2.4688,  ..., -2.5156,  1.9688, -2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([43], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0131, -0.0173, -0.1572,  ..., -0.2637,  0.0237,  0.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0776, -0.0243,  ..., -0.0884, -0.1836, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.0625,  5.1250, -0.5625,  ..., -1.6250, -1.0391,  0.0596]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141,  0.8672,  1.4062,  ..., -1.2109,  1.7266, -0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([44], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0045, -0.1035,  ..., -0.2236, -0.1484, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0137, -0.0820,  0.0376,  ..., -0.0503, -0.1807, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4531,  3.7188, -2.8125,  ..., -2.5625, -7.0625, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318,  0.0464, -2.6719,  ..., -0.2471,  2.9531, -1.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([45], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0889,  0.2100,  0.0236,  ..., -0.4746, -0.0308, -0.0280]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.0361, -0.3242,  ..., -0.2930, -0.0347,  0.0962]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4844, -2.8750,  ...,  0.4727, -2.7656,  5.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0266, -0.6133,  0.0542,  ..., -2.4688, -0.2949, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([46], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0217,  0.1484, -0.0442,  ..., -0.1562,  0.1201, -0.0481]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513, -0.2578, -0.3359,  ..., -0.1416, -0.1201,  0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5000,  -2.6250,   0.0625,  ...,  -2.0625,  -1.0000,  -5.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984, -1.3516, -0.2773,  ..., -2.2969, -0.5586, -1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([47], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0251,  0.1201, -0.0498,  ...,  0.1187, -0.0889, -0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2324,  0.0469,  0.2100,  ...,  0.1660, -0.7227, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3125,   7.8438, -11.9375,  ...,   1.8906,   4.7812,   2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6094,  0.9219, -0.2070,  ..., -2.1875, -0.5977, -1.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([48], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221, -0.0654, -0.0058,  ..., -0.0238, -0.0464,  0.0024]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3223,  0.1816,  0.1738,  ..., -0.2676, -0.3418, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2812, -1.3906, -0.8555,  ..., -5.4375,  0.4297, -9.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1338,  0.4531,  0.3574,  ..., -3.8281,  0.7227, -1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([49], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0339,  0.1104,  0.0608,  ..., -0.0498, -0.0679, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190,  0.1826,  0.2754,  ..., -0.0071, -0.0869,  0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0781,  2.0469,  1.7422,  ..., -2.0625, -2.2344, -6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4023, -2.9062,  0.4297,  ..., -0.5312, -3.3125,  1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([50], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1152, -0.0493, -0.0269,  ..., -0.0530, -0.1582, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996,  0.0471,  0.0996,  ..., -0.1338,  0.0251, -0.0496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  6.0625,  8.2500,  ..., -0.6406,  0.6016, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8516, -3.3125, -1.7188,  ...,  0.6367, -6.2500, -0.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([51], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0549,  0.0278,  0.0688,  ...,  0.1030, -0.0991, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001,  0.0025, -0.0046,  ..., -0.0500,  0.0801,  0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.2344, -2.8125, 13.6250,  ...,  2.9844,  0.5117, -4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[  4.7812, -10.5625,  -7.3438,  ...,   8.2500,  -7.2812,   9.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([52], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0281,  0.2109,  0.1777,  ..., -0.2393,  0.1064,  0.0537]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0084, -0.0649, -0.1504,  ...,  0.0684,  0.1465, -0.0255]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.1562,  3.3125,  1.9453,  ..., -2.6875,  0.8320, -0.0254]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4863, -2.6250, -0.3398,  ..., -0.1836, -0.1660, -2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([53], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0171,  0.0381,  0.0200,  ..., -0.3203, -0.1006, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2793, -0.0178, -0.3613,  ..., -0.2373, -0.0068, -0.2305]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.3906,  3.1094, -3.0781,  ..., -3.6875, -3.8750,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.8516,  0.4258,  ..., -0.1582, -0.1562, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([54], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0605, -0.0508, -0.0071,  ..., -0.1572, -0.0391, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.2188, -0.3281,  ..., -0.0967, -0.0654,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5469, -4.4062, -7.3125,  ..., -1.3750,  0.4453, -2.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750, -2.2188, -0.8594,  ...,  0.7617, -0.5078,  0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([55], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2480,  0.0586,  0.0417,  ..., -0.1514, -0.1611, -0.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1201, -0.2754,  0.1079,  ...,  0.3027, -0.2490, -0.2334]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.3438,  2.1406, -6.0938,  ..., -3.3125,  0.4023,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344,  0.2676, -1.1641,  ..., -0.2275, -1.4844, -0.5898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([56], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0208,  0.0283, -0.1128,  ..., -0.1221, -0.2100,  0.0260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0019, -0.3340,  0.0630,  ...,  0.0217, -0.0251, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6719,  4.0312,  3.5469,  ...,  0.4219, -7.0938,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3613, -0.6719, -0.9648,  ..., -0.2852, -0.2012,  0.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([57], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0928,  0.0143,  ..., -0.0520, -0.0308, -0.0251]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1328, -0.0737,  0.1079,  ...,  0.0564, -0.0486,  0.0104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  -4.7188,  -3.1406,  ...,  -1.8594,   3.2188,   1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0742,  1.1719, -1.4844,  ...,  1.6797, -1.1250, -0.7891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([58], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.0742,  0.1875,  ...,  0.1963,  0.0049, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.3594,  0.3066,  ...,  0.6914, -0.0630,  0.0020]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9375, -4.4062, -3.4688,  ...,  0.6055,  0.5078,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1328, -0.0938, -0.3125,  ..., -0.5977, -0.5781, -0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([59], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1504, -0.1660,  0.0291,  ...,  0.1445,  0.1807,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0322, -0.5820,  0.3105,  ...,  0.1426, -0.1953,  0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.2500, -1.9688, -0.6602,  ...,  7.7812, 13.3750,  4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6094, -1.1797,  0.6680,  ...,  0.2520, -1.7812,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([60], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0071,  0.0198,  ..., -0.0354,  0.0918,  0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2500,  0.1865,  0.1719,  ..., -0.1235, -0.0140, -0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -1.2188,  8.9375,  ...,  3.7812, 11.2500, -7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -0.4648,  1.4531,  ..., -2.2031, -0.1543, -0.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([61], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0054,  0.1836, -0.0796,  ..., -0.2305, -0.0225, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.0461, -0.1797,  ..., -0.1689, -0.3262, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.1250, -7.0312,  4.4375,  ..., -2.1719, 15.7500, -6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3711,  1.1406,  0.5586,  ..., -2.2812,  1.1797, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([62], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2256,  0.1484, -0.0942,  ..., -0.2090, -0.1494, -0.0981]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0972, -0.1553,  0.3164,  ..., -0.5195,  0.1562,  0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750, -2.0781, -2.6875,  ..., -5.2500,  3.3750,  5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5820,  0.4883,  0.1885,  ..., -0.9883, -0.0605, -0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([63], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0796,  0.0552,  0.0586,  ..., -0.1504,  0.0371, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3984, -0.1128,  0.0918,  ..., -0.5859,  0.1475, -0.0282]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188, -3.9375,  4.3750,  ..., -2.2812, 13.6250,  0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8320, -0.4180, -1.3047,  ..., -0.3184,  0.2207,  0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([64], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608,  0.1113, -0.0078,  ..., -0.0613,  0.0073, -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0302, -0.0449,  ..., -0.1309, -0.0767, -0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  5.1875, -12.6875,   2.7500,  ...,  -4.8438,  12.1875,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6875, -0.0791, -0.5703,  ...,  0.3262,  0.0928, -0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([65], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0061,  0.1426, -0.1338,  ..., -0.0840,  0.1426, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2695,  0.4844,  0.2363,  ...,  0.0752,  0.1904,  0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.6875,  -5.4375,  -3.0469,  ...,   2.0312, -12.5000,   3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0908, -0.0527,  0.5273,  ...,  2.8906, -4.0625,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([66], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773, -0.0420,  0.0461,  ..., -0.0898, -0.1167,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0121,  0.1641,  ...,  0.1221, -0.2871, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375, -0.5859, -3.1562,  ...,  1.2500, -4.7812,  1.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0508, -2.3438, -2.9375,  ..., -1.9062,  3.4375, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([67], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1768,  0.1299,  0.0986,  ..., -0.4180,  0.0547,  0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.0549, -0.2246,  ..., -0.3633, -0.0918,  0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9844, -6.4375, -2.5625,  ..., -2.0469,  2.0000,  5.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3438,  0.4141,  0.4551,  ..., -0.6602,  0.1260,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([68], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1074, -0.0004, -0.0747,  ..., -0.1709, -0.0476, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2061,  0.0786,  0.0610,  ..., -0.3398, -0.0549,  0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  0.2891,  -9.6875,   2.4062,  ..., -11.1875,   5.6250,   4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0234, -0.5703, -0.4453,  ..., -0.1680,  0.4395,  0.2695]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([69], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2256,  0.0708,  0.0442,  ..., -0.1416,  0.0732,  0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.7461, -0.4551,  ..., -0.3789, -0.3008,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -0.2148, -1.3281,  ...,  5.1250,  2.9688,  1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.6719,  0.0737,  0.0420,  ...,  0.1914,  0.5703, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([70], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0378,  0.0325,  0.1377,  ...,  0.1318,  0.0771, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0053, -0.3184,  0.1182,  ..., -0.0942,  0.0986, -0.0564]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.8438, -0.6016,  ...,  1.7266,  8.4375,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -2.4219,  0.1504,  ...,  0.2441,  1.5000, -2.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([71], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0527, -0.0537, -0.0332,  ...,  0.1357,  0.1357, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.3320, -0.0684,  ..., -0.3105, -0.2324, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.8906,  1.5859,  ..., -0.4844, 10.5625,  4.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6875, -0.1396,  1.5156,  ..., -0.2988,  2.1406, -2.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([72], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0703, -0.0664,  ...,  0.0649, -0.0942, -0.0410]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4785, -0.0016, -0.0547,  ..., -0.3652, -0.3027, -0.3652]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1250,   5.4062,  -2.8594,  ...,   6.4062,   5.8438,   8.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670, -1.7578,  1.2500,  ...,  0.0427, -0.5273, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([73], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0211,  0.2021,  0.0226,  ...,  0.0674,  0.0474, -0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2754, -0.1377, -0.0615,  ..., -0.3223,  0.1465, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   3.3906,  -1.9141,  ...,   8.6875,  16.1250,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734, -2.6250,  1.4531,  ..., -1.5547,  1.7500, -2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([74], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1211,  0.0825, -0.0918,  ..., -0.0674, -0.0420, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2090, -0.1060,  0.0376,  ..., -0.3789, -0.3027, -0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875,  2.0000, -8.1250,  ...,  6.7812,  5.3750, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8984,  1.1328, -3.5781,  ..., -1.1172, -3.4219, -3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([75], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0364,  0.1348, -0.2246,  ..., -0.0752,  0.0830, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.6328,  0.2422,  ...,  0.1455,  0.1768,  0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   0.0508,  -1.0703,  ...,   6.5625,  -3.6719,   1.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4258,  2.5156,  2.0156,  ...,  3.1719,  3.1250, -3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([76], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0371, -0.0654,  ..., -0.1436, -0.0354,  0.1807]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099,  0.0781, -0.1099,  ...,  0.0518, -0.1982, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,   7.5312,  -2.5938,  ...,   4.7812,  -0.6328,  -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3965,  0.2910,  0.7070,  ..., -2.0469,  2.5156, -3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([77], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0515,  0.0093,  0.0014,  ...,  0.0106,  0.0194, -0.0957]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4043, -0.1426, -0.0211,  ...,  0.4160,  0.1953, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.5938,   3.4062,  ...,   5.7500,  -9.3125,   6.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375,  2.4062, -2.1406,  ...,  0.2617, -0.6992,  0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([78], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0352, -0.0271,  0.0535,  ...,  0.0295,  0.0220, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0942, -0.0698,  0.0361,  ..., -0.0674,  0.3203, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -1.1797, -1.3047,  ..., -1.3281,  0.5547,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2656, -2.5156,  0.1030,  ...,  2.2344,  1.0469, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([79], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1089,  0.0002, -0.1611,  ...,  0.1235,  0.1650, -0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.1377,  0.1318,  ...,  0.2158,  0.2412, -0.4043]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.8750,  -0.9766, -11.1875,  ...,   4.2500,   0.0684,  -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5469,  0.7344, -2.0938,  ...,  0.1445, -0.8789, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([80], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297, -0.0359, -0.1553,  ..., -0.0097,  0.0066, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.3652, -0.1445,  ..., -0.1904,  0.0023, -0.2832]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   0.7422,  -3.4062,  ...,   2.4219,   1.2109,  -1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5156,  0.7266,  0.5820,  ...,  0.5391, -1.1094, -0.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([81], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1260, -0.1030,  0.0164,  ...,  0.0479, -0.0518, -0.0457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0618, -0.0014, -0.0840,  ...,  0.1050,  0.0249,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.0000,  6.2500, -0.5352,  ...,  0.0820, -0.2031,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.2812,  2.4062,  0.1064,  ..., -0.8672,  0.4922, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([82], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0200,  0.0139,  0.0134,  ...,  0.0640, -0.0173, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4961, -0.0151,  0.0461,  ...,  0.4141,  0.0786,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -9.5625, -16.6250,  ...,   3.1406,  -3.1562,  11.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1226,  1.6484, -3.5312,  ..., -0.0422, -1.0625,  1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([83], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1104,  0.0469,  0.0256,  ..., -0.0569,  0.2324,  0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952,  0.0908, -0.0830,  ..., -0.1973,  0.1484, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -8.8750, -10.1250,  ...,   1.9844,  -5.9062,  -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8555,  0.3262, -0.0024,  ...,  0.4961, -0.5938,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([84], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605,  0.0312, -0.0762,  ..., -0.1406, -0.0092, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.3398, -0.1055,  ..., -0.3320, -0.0569, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,   4.8750,  -0.9688,  ...,  12.7500,   2.0000,   2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8984,  0.1836, -0.2832,  ..., -1.2031,  0.1089, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([85], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0022,  0.0003,  ..., -0.1562,  0.0737,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0249, -0.0549,  0.1099,  ...,  0.0383,  0.1328, -0.1118]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -0.2578,  -6.4688,  ...,   6.7500,  -1.9141,   5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5312, -4.3125,  0.3516,  ...,  2.0469, -2.4844, -9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([86], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0040, -0.0396,  0.0049,  ..., -0.0786,  0.1328, -0.0535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0157, -0.0581,  0.0320,  ..., -0.0391,  0.0771, -0.0239]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.2500,   0.1719,  -2.8438,  ...,   8.8750, -10.1250,   9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3242,  1.0859, -0.1387,  ..., -0.9609,  0.4863, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([87], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0076,  0.0850, -0.0166,  ...,  0.1348,  0.0060, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2188, -0.0035,  0.0337,  ...,  0.0801,  0.0713, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  5.1250, -6.6250,  ..., -2.2500, -2.6250, 14.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625, -0.1221, -2.2812,  ..., -1.1250,  1.0859, -6.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([88], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0262, -0.0703,  ...,  0.0608,  0.1074, -0.0195]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2402, -0.1729,  0.0820,  ...,  0.0520,  0.1196, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.9062, -4.7500,  ...,  5.5312,  4.5312,  0.6797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0859,  0.1079, -0.7383,  ...,  0.9961, -1.2109, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([89], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811, -0.0742, -0.0728,  ...,  0.0649, -0.0278, -0.1128]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3320, -0.1982,  0.1729,  ...,  0.0217, -0.1367, -0.2471]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -1.9844, -2.9531,  ...,  6.9688,  7.0625,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2344, -0.8242,  0.2354,  ...,  4.6250, -2.6719,  1.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([90], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610,  0.0095, -0.0073,  ..., -0.1191, -0.1064, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4199,  0.0608,  0.0483,  ...,  0.2793,  0.1523,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5000,   4.3125,  -6.2812,  ...,  -2.1719,  -7.3750,  10.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0703, -1.3359, -0.6758,  ...,  0.2129, -0.1943, -0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([91], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0505,  0.0791,  0.0210,  ...,  0.0186,  0.0669,  0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1836, -0.0796, -0.0322,  ..., -0.1196,  0.1338, -0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  3.4531,  0.5977,  ..., -2.2031,  1.4062, 15.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6719,  3.5469, -1.4219,  ...,  5.4062,  2.7656, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([92], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0791, -0.0113, -0.1494,  ...,  0.0728,  0.0635,  0.0063]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.0649,  0.0471,  ...,  0.1387,  0.1504, -0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8125,  0.2617, -1.7188,  ..., -0.1914, -7.0938,  0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5352,  0.6797, -0.1406,  ...,  0.9141, -0.4004, -2.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([93], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128, -0.1221, -0.1494,  ..., -0.0342,  0.1187, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1973, -0.1973, -0.2168,  ..., -0.4258, -0.0933, -0.1270]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.2500, -2.0156,  3.0781,  ...,  3.7969, -8.7500, 10.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  1.4141,  0.4004,  ...,  1.6953, -0.1191, -1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([94], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1152,  0.3262, -0.0530,  ...,  0.1611, -0.0366, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2793,  0.0635,  0.1309,  ...,  0.0723, -0.0010, -0.4453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  3.1406, -1.8672,  ..., -0.1328, -4.7812,  9.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4688,  0.0273, -1.6484,  ..., -0.0264,  1.5703, -7.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([95], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0255,  0.0459, -0.0928,  ...,  0.0693,  0.1143, -0.0089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441, -0.0613,  0.0542,  ...,  0.0444,  0.1621, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -0.7227,   2.1562,  ...,   2.3438, -10.6875,   0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8047, -1.6641,  1.2422,  ...,  0.9023, -2.5625, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([96], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0264, -0.1318,  0.0425,  ..., -0.1309, -0.0625, -0.0208]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0017,  0.0752,  ..., -0.0400, -0.1299,  0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4688,  1.2266,  7.0625,  ..., -7.3438, -0.1250, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7539, -0.5898,  0.2363,  ...,  0.1406, -0.5000, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([97], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0884,  0.0503,  ...,  0.0796,  0.0630, -0.0508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0645, -0.1299, -0.1611,  ...,  0.0199,  0.2598, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -2.0938, -3.3438,  ...,  3.1562,  3.2812, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7188, -0.1299, -1.4922,  ...,  3.1875, -1.2422,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([98], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0693,  0.0137,  0.0258,  ..., -0.0591, -0.1709, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4434,  0.0918,  0.1128,  ...,  0.2871,  0.1226,  0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2031,  5.8125, -4.7500,  ..., -6.5312, -6.3125,  4.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -2.2812,  2.7188,  ...,  2.4844,  2.3438, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([99], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0117,  0.0542, -0.0635,  ..., -0.1992,  0.0236, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0903, -0.1758, -0.0938,  ...,  0.2012,  0.1436,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.6875,   7.3125,  -0.1016,  ...,   3.0156,  -3.1875,   1.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.3125,  2.5469, -0.0684,  ...,  0.0801,  0.7930, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([100], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0562, -0.0177,  0.0415,  ...,  0.0669, -0.0396, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453,  0.0640,  0.0113,  ...,  0.3750,  0.0339,  0.1543]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -6.8125, -9.9375,  ..., -5.2500,  0.6172, 22.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4531,  3.7500, -7.3750,  ...,  1.2109,  2.5000,  3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([101], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0850,  0.0248,  0.0327,  ..., -0.0469,  0.1768, -0.0121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0571,  0.1309, -0.0518,  ..., -0.2188,  0.0767,  0.0056]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0312, -1.0156, -2.2656,  ..., -8.3125, -3.6875,  6.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5977, -0.3789, -3.9375,  ...,  0.2461,  2.6562, -0.2490]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([102], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0967,  0.0957, -0.0747,  ..., -0.0143, -0.0215, -0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.0679, -0.3125,  ...,  0.2168, -0.0825, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.8125,  0.3984,  2.1875,  ...,  9.3125,  0.4258,  5.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5000,  0.2070, -2.8125,  ...,  1.7031,  0.8867, -0.0172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([103], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0991,  0.0004,  ..., -0.0277, -0.0236,  0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1250, -0.1172,  0.1328,  ..., -0.0698,  0.1113, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2812, -4.7812, -6.5625,  ...,  6.0938, -0.0693,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8281, -6.8125, -3.3594,  ...,  4.4062, -2.8750, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([104], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0742,  0.1021,  ...,  0.0234, -0.0135, -0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0231,  0.0277,  0.0439,  ...,  0.0679,  0.0693, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8750,   1.5938,  -4.5625,  ...,  -5.5312,   0.5156,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781,  0.6641, -1.4922,  ...,  0.6523, -0.1035, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([105], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[0.0342, 0.0197, 0.0522,  ..., 0.1982, 0.0118, 0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1953, -0.1738,  0.0131,  ..., -0.0781,  0.1279, -0.0933]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   4.2812,  -3.2188,  ..., -10.5000,  -5.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3633,  1.7344, -0.6094,  ..., -0.3887, -0.4805, -4.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([106], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371,  0.0522, -0.1157,  ...,  0.0869,  0.0635, -0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680, -0.0801,  0.0569,  ...,  0.0364,  0.0986, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9961, -0.4922,  3.6562,  ...,  0.3867,  1.7578,  3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  0.7578, -2.2031,  ...,  3.7031, -1.2266, -0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([107], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2109, -0.0269, -0.0122,  ...,  0.0684, -0.1260, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2363,  0.2080, -0.0077,  ..., -0.1670, -0.1992,  0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   2.0469,  11.0000,  ...,  -3.8438,   9.9375,   2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250, -0.2061, -0.2188,  ...,  0.1582,  1.3828, -3.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([108], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1187, -0.0762,  0.0247,  ...,  0.1279,  0.0747, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0967, -0.1377, -0.0854,  ..., -0.0051,  0.3008, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.1250,   4.9375,  15.5625,  ..., -10.8750,   5.1875,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6367,  0.8945, -3.2031,  ...,  0.3574, -1.4062,  0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([109], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.1143,  0.0957,  ..., -0.0649, -0.1074,  0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0615, -0.2754,  0.0928,  ...,  0.0811, -0.0247,  0.0013]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.0000,  11.3750,   4.8750,  ..., -11.1875,   1.8594,   0.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  0.3789,  3.8906,  ..., -1.9922,  3.7031, -2.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([110], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0454, -0.0918,  0.1465,  ...,  0.0698, -0.0879,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.1680, -0.0398,  ..., -0.0562, -0.0806, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,   5.8125,  -3.6250,  ...,  -3.5312,  -0.3340,  -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.0698,  0.0221,  ...,  0.6484, -0.3633, -1.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([111], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054,  0.0669, -0.0284,  ...,  0.0032, -0.0542, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3164, -0.2129,  0.0018,  ..., -0.5547, -0.1904,  0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   1.7969,  -2.6406,  ...,   1.0781,  -1.1016,  -7.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1172,  3.1719,  1.3125,  ...,  2.5625, -0.5938,  2.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([112], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0610, -0.0074,  0.1279,  ..., -0.0215, -0.1562, -0.0898]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1914, -0.0131, -0.1279,  ..., -0.1167, -0.0118,  0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7188,  3.0469,  1.9844,  ...,  1.3203,  3.0625,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344,  0.2471, -2.0781,  ..., -1.0625, -1.7344, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([113], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635,  0.0034,  0.0066,  ...,  0.0481, -0.0986, -0.1738]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.4512, -0.1416,  ..., -0.4434, -0.1914, -0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.2812, -1.5391,  ...,  1.9922,  2.6406, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.1328, -0.3945,  ...,  5.2500, -1.2266,  0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([114], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0137,  0.0649,  ..., -0.0245, -0.1318, -0.0845]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3457,  0.0972,  0.0349,  ...,  0.3203,  0.1084,  0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.3281,  2.6562, -4.6562,  ..., -5.0312,  4.6875,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -1.7188, -0.8867,  ..., -0.8984,  0.0084, -0.6758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([115], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0006, -0.0332, -0.0251,  ..., -0.0059, -0.0253, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1089, -0.3887,  0.0659,  ..., -0.1504, -0.0889,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   1.0391,  -2.5781,  ...,   1.1406,   1.0781,  -0.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  1.9531,  0.9258,  ...,  1.9688, -0.6836,  3.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([116], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640,  0.0046,  0.1113,  ...,  0.0508, -0.0938, -0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832, -0.0574, -0.1650,  ..., -0.1387,  0.0098,  0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.5625,   5.1250,  -1.2266,  ...,  -6.9688,  -1.4062,   6.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8672, -0.7461, -2.3750,  ...,  1.1250,  0.7344, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([117], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0986, -0.0520,  ...,  0.0918, -0.0608, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1465, -0.4141, -0.1426,  ...,  0.0645,  0.1572, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -0.8750,  2.9062,  ..., 10.0625, -7.1562, -3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7422, -0.8203,  2.3750,  ...,  2.4062, -5.0938, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([118], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0154, -0.0815,  0.0635,  ..., -0.0400,  0.0287,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1060, -0.0522,  0.0942,  ..., -0.0089, -0.1562,  0.0308]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   5.5000,   1.6719,  ...,  -3.3594,  -0.8438,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9609, -0.9688, -0.9688,  ...,  1.2969, -0.8984, -3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([119], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1216,  0.0835,  0.0693,  ...,  0.2100, -0.0723,  0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.0806,  0.0212,  ..., -0.0361,  0.1089, -0.0386]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.2812,  -1.4375,   1.6875,  ..., -13.1250,   2.3906,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4219,  0.1113, -1.9609,  ...,  0.6758, -0.6914, -7.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([120], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0287,  0.0757, -0.1377,  ...,  0.1196,  0.0469, -0.0576]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1699, -0.0525,  0.0430,  ...,  0.0425,  0.1040, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1094, -1.2188, 10.0625,  ..., -3.6875, -4.2500,  6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5938,  0.2109, -2.5156,  ..., -1.4844, -1.1719, -3.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([121], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0104, -0.0840, -0.0052,  ...,  0.2314, -0.0732, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.1719,  0.2383,  ...,  0.0859,  0.2002,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.7500,  8.0625,  7.4375,  ...,  0.4453,  5.1562, -0.5391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1484, -0.0645, -1.9375,  ...,  0.1108,  2.5469, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([122], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0605, -0.0444,  0.0190,  ...,  0.1689,  0.0295, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0996, -0.0742, -0.0688,  ...,  0.0386,  0.2158, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3125,  5.6562, 12.6250,  ..., -2.5469, 10.3750,  1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9062e-03,  1.6797e-01, -8.1875e+00,  ..., -1.6309e-01,\n",
      "         -2.4688e+00,  1.9609e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([123], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0449,  0.1108,  0.1050,  ..., -0.0178, -0.1465,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0977, -0.2295,  0.1069,  ...,  0.0947, -0.0317,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.7500,   2.9062,   5.8125,  ...,  -5.5000,   7.5000,   3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9375,  3.2500,  1.2656,  ...,  0.6406,  4.9688, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([124], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0015, -0.0996,  0.1504,  ...,  0.1064, -0.1279,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0383, -0.0337,  ..., -0.0131, -0.0532, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.5000,  6.5625, -0.3359,  ..., -8.0000,  3.6875, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1719,  0.8516, -0.5117,  ...,  0.5547, -0.4707, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([125], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014,  0.0713, -0.0106,  ...,  0.0188, -0.0649, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1973,  0.0089,  ..., -0.5234, -0.1973,  0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250,  3.3438, -0.6133,  ..., -2.7656, -1.1953, -1.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8711,  3.8125,  1.5625,  ...,  3.4062, -0.2100,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([126], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0417, -0.0137,  0.1270,  ...,  0.0229, -0.1895, -0.0356]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1816,  0.0334, -0.1250,  ..., -0.0684, -0.0154,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4375,  6.5312,  3.9062,  ..., -5.5312,  1.7500,  1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.0596, -1.6406,  ..., -0.4199, -1.3516, -0.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([127], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0559,  0.0102,  0.0098,  ...,  0.0684, -0.0986, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.4609, -0.1235,  ..., -0.4453, -0.1973, -0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000,  2.2812, -0.3398,  ...,  3.7812,  2.5625, -4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8047, -0.5977, -0.5352,  ...,  6.6250, -1.0234,  0.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([128], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0513,  0.0178,  0.0547,  ..., -0.0110, -0.1445, -0.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3340,  0.1167,  0.0505,  ...,  0.3242,  0.1050,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1562,  4.3438, -0.4043,  ..., -3.9062,  4.8438, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5625,  0.0596, -2.4062,  ..., -1.5234, -0.2871, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([129], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0337, -0.0234,  ...,  0.0135, -0.0183, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1279, -0.3848,  0.0874,  ..., -0.1826, -0.1016,  0.0417]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,   5.9375,  -0.0566,  ...,   0.4688,  -0.8984,  -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4219,  2.7031, -0.0713,  ...,  1.8906, -0.1216,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([130], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0547,  0.0023,  0.1191,  ...,  0.0845, -0.1230,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2891, -0.0288, -0.1641,  ..., -0.0972,  0.0253,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   9.6875,   1.9844,  ...,  -3.2188,  -7.3750,  -1.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6406, -0.8203, -3.0469,  ..., -1.7266,  0.3770, -1.8672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([131], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0405,  0.0291,  0.1021,  ..., -0.0522,  0.0569, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1826, -0.1357,  0.1504,  ..., -0.3164,  0.0913, -0.4023]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.8750,  1.4297,  3.3281,  ...,  8.5000, -9.5000, -6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  1.4688,  2.9219,  ...,  1.2891, -6.3750, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([132], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0486, -0.1211,  0.0298,  ..., -0.0840, -0.0442, -0.0157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0757,  0.0003,  0.0659,  ..., -0.0388, -0.1318,  0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0625,  3.1875, -0.4590,  ..., -8.3750,  2.2031,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828, -1.6328, -1.3359,  ...,  2.9219, -1.5938, -4.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([133], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0801,  0.0496,  0.0493,  ...,  0.1650, -0.1113,  0.0100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1846, -0.0723,  0.0601,  ..., -0.0586,  0.0967, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.6250,   2.4375,   1.1250,  ..., -10.1875,  -0.3867,  11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8828,  0.5078, -3.3125,  ...,  1.2969,  1.2031, -6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([134], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0723, -0.1396,  ...,  0.1089,  0.0349, -0.0603]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1553, -0.0486,  0.0449,  ...,  0.0337,  0.1118, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,   4.0000,  10.3125,  ...,   4.9062,   0.6523,   4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797,  0.2363, -0.6602,  ...,  2.0000, -2.7812, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([135], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0491, -0.0386,  0.0135,  ...,  0.0762, -0.1611, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.4238, -0.1001,  ..., -0.0640, -0.0041,  0.2295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5000,   3.4531,   6.8125,  ...,   1.6719,   4.8750,   1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3672, -0.3828, -3.4844,  ...,  1.9844,  1.4453, -2.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([136], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0669, -0.0723,  0.0033,  ...,  0.0742,  0.0476, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1157, -0.0815, -0.0273,  ...,  0.0261,  0.2490, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  2.0312,  7.7500,  ...,  0.3906,  5.4688,  1.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.5703, -8.3125,  ...,  1.1641, -2.6406,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([137], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0297,  0.1079,  0.1025,  ..., -0.0635, -0.1338,  0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0581, -0.2373,  0.0840,  ...,  0.0933, -0.0240, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.0273,   0.3008,  ...,  -2.7500,   3.0312,   1.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  4.4688,  0.9766,  ...,  0.6094,  3.3281, -2.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([138], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0046, -0.1016,  0.1514,  ...,  0.1089, -0.1118,  0.1177]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1719, -0.0104, -0.0251,  ..., -0.0151, -0.0498,  0.0123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7188,   5.2812,  -6.9375,  ..., -11.3750,   2.6250,  -3.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1562,  0.9062, -1.1719,  ...,  1.3125, -2.2031, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([139], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0071,  0.0771, -0.0084,  ...,  0.0137, -0.0396, -0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2949, -0.1992,  0.0148,  ..., -0.4980, -0.2012,  0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625,  3.3438,  1.0234,  ..., -2.8125, -2.3438, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6367,  3.0781,  0.3926,  ...,  5.1250, -0.7695,  2.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([140], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.0062,  0.1299,  ...,  0.0300, -0.1768, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0322, -0.1123,  ..., -0.0540, -0.0130,  0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.0000,   3.1250,   3.6094,  ...,  -6.7500,   3.0469,   0.4102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7500,  0.8320, -1.4688,  ...,  0.8672, -2.6094, -1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([141], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0569,  0.0164,  0.0121,  ...,  0.0664, -0.0815, -0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1934, -0.4531, -0.1328,  ..., -0.4473, -0.1982, -0.3887]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  1.8750, -1.6250,  ...,  2.3750,  2.9375, -0.6172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3359,  0.0400,  ...,  5.9375, -2.2031,  1.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([142], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0220,  0.0557,  ..., -0.0094, -0.1318, -0.0796]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.1099,  0.0466,  ...,  0.3105,  0.1074,  0.1099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  1.1484, -5.4062,  ..., -5.3438,  3.0469, -1.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9453, -1.0703, -1.1406,  ..., -0.7617, -1.7812, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([143], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0239, -0.0262, -0.0258,  ...,  0.0119, -0.0002, -0.0854]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1367, -0.3594,  0.1016,  ..., -0.1768, -0.1060,  0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7812,  2.5625, -2.9531,  ...,  2.2188, -3.5625, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4707,  2.4062,  2.0312,  ...,  2.9531, -0.1885,  4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([144], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0576,  0.0080,  0.1133,  ...,  0.0933, -0.1201,  0.0168]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2871, -0.0249, -0.1475,  ..., -0.0820,  0.0232,  0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,   5.3438,   5.0000,  ...,  -0.7500,  -4.1562,   4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8945,  1.8906, -1.2266,  ...,  0.9688, -0.2471, -0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([145], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0127,  0.0508,  0.0796,  ..., -0.0156,  0.0106, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1660, -0.0317, -0.0439,  ...,  0.2012, -0.0620, -0.1436]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4375,  3.5781,  5.3438,  ...,  7.3125, -4.8438, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2812,  1.6250,  2.8438,  ...,  4.0625, -5.8438, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([146], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0806, -0.1416,  0.0500,  ..., -0.0742, -0.0334,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396,  0.0530,  0.0972,  ...,  0.0240, -0.1631,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0000,   5.2188,  -1.3203,  ...,  -3.7344,   4.4062,  10.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0391, -0.4570,  0.6211,  ...,  1.0547, -2.3750, -3.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([147], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0830,  0.0850,  0.0757,  ...,  0.1982, -0.1182,  0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1729, -0.0574,  0.0542,  ..., -0.0408,  0.1108, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.9375,   3.5000,  -0.5547,  ...,  -6.6875,   3.3750,  15.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9492, -0.1680,  0.1826,  ...,  0.7500, -1.3359, -3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([148], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679,  0.0659, -0.1445,  ...,  0.1138,  0.0520, -0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504, -0.0320,  0.0488,  ...,  0.0364,  0.1143, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   1.0859,   3.2812,  ...,   3.3125,   7.3125,  -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1592, -0.2178, -0.6602,  ..., -0.7500, -0.8984, -0.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([149], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0415, -0.0757,  ...,  0.0684, -0.0698, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2236, -0.1094,  0.1147,  ...,  0.0757, -0.0771, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.6406, -3.5625,  0.2344,  ...,  3.3125,  3.4375,  5.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2891, -0.0918, -0.1758,  ...,  4.2500, -2.8125, -1.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([150], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0474,  0.0791, -0.0986,  ..., -0.0231,  0.1562, -0.0259]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3242,  0.5195,  0.1768,  ...,  0.1875,  0.1924,  0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.9375,  -0.3594,   3.9219,  ...,  -0.7188,  -2.5000,  -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -1.1641,   7.2812,   1.0000,  ...,  10.6875,  -1.9219, -10.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([151], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874, -0.0317, -0.0869,  ..., -0.0952,  0.0004,  0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181,  0.1504, -0.1182,  ...,  0.0361, -0.0947, -0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375,  6.0625,  6.9062,  ..., -4.1875,  0.6406, -1.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4668,  6.0000,  3.4688,  ..., -2.6562,  1.9062, -5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([152], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1475,  0.0128, -0.0211,  ...,  0.1816, -0.0938, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4570,  0.1279, -0.0097,  ...,  0.0530, -0.1494,  0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.3750, -3.4062, -2.1094,  ..., -0.7812, 10.5000, 18.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7500, -4.4375,  ...,  0.2227,  0.8438,  2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([153], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0417, -0.0894, -0.0630,  ..., -0.0133,  0.0840,  0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0146,  0.0432,  0.0276,  ..., -0.2109,  0.0129, -0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5312, -3.9531,  3.9219,  ..., -2.5469, 11.0000,  2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2188, -1.5000, -3.4375,  ...,  0.5586,  1.2266, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([154], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1318, -0.0908,  0.0923,  ..., -0.0415,  0.0393,  0.0057]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2373, -0.1445, -0.1387,  ..., -0.1094,  0.0718, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7617, -5.1875, 10.3750,  ..., 12.8750,  6.2812, -1.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7930, -1.7656, -1.8438,  ...,  2.1250,  1.4766,  0.0527]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([155], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0781, -0.0084,  0.0166,  ...,  0.2295, -0.0830, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3496,  0.1582,  0.2422,  ...,  0.0183,  0.1855,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.0000,  0.6484, -0.3594,  ..., -4.9688, 14.9375,  0.4180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8164, -0.6797, -4.6875,  ...,  1.5312,  1.3438, -1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([156], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0864, -0.0325,  0.0537,  ...,  0.0104,  0.0544, -0.0106]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.0281, -0.0452,  ..., -0.0215,  0.0271,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8125e+00, -3.7812e+00,  5.5312e+00,  ...,  7.8125e-03,\n",
      "          5.3750e+00,  9.0000e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5742,  1.5625,  0.0410,  ...,  6.0312, -4.9375, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([157], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0073,  0.0693, -0.0967,  ...,  0.0151,  0.1182, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.4648,  0.1611,  ...,  0.1260,  0.1992,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,  -0.6211,   0.8281,  ...,  -5.2500,  -2.6250,  -4.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4375,  3.6562,  1.2422,  ..., 10.0000, -2.1250, -8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([158], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1240, -0.0306, -0.0806,  ..., -0.0918, -0.0217,  0.2080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0106,  0.1338, -0.1138,  ...,  0.0157, -0.0728, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.0000e+00,  6.6250e+00,  1.1312e+01,  ..., -6.6875e+00,\n",
      "         -3.9062e-03,  5.7812e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.3438,  3.5156,  3.1094,  ..., -0.4004,  2.6719, -3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([159], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 1.2207e-04,  7.9346e-03,  1.5625e-02,  ...,  1.4648e-01,\n",
      "         -3.3936e-02,  4.2236e-02]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4375,  0.2988,  0.0035,  ..., -0.0129,  0.2275, -0.0007]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6875,   2.2031,  -3.5938,  ...,  -0.8945,  -2.0312,  12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.6367, 2.0781, 1.8750,  ..., 0.0151, 0.2168, 0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([160], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0344, -0.0693,  0.1543,  ...,  0.1187,  0.0598, -0.0058]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0933, -0.1445,  0.0330,  ...,  0.0398,  0.1982, -0.0009]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.3438,  4.6875,  3.9375,  ...,  1.3906,  9.9375,  5.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -0.9375,  0.7031,  ..., -1.5859, -0.4629, -1.0859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([161], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0640, -0.0052, -0.0231,  ...,  0.0233, -0.0557, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0047,  0.0913, -0.3477,  ...,  0.1973, -0.0552, -0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.0938,  3.3438,  4.6875,  ..., 10.9375,  2.8594,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719, -0.5312, -2.7031,  ...,  2.0625,  0.9609, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([162], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0293,  0.0258, -0.0688,  ...,  0.0444,  0.0581,  0.0070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0869, -0.1904, -0.1895,  ..., -0.0073,  0.1123,  0.0228]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0938,  9.1875,  6.3750,  ...,  6.1250, -3.1406,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1914, -0.1885, -0.5625,  ..., -0.2969,  0.9062, -1.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([163], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1729,  0.0130,  0.0549,  ...,  0.2832, -0.0938, -0.1992]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3535, -0.0442, -0.0718,  ...,  0.1050, -0.0669, -0.3965]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.4375, -5.5625,  8.5000,  ...,  5.1875, -8.2500,  3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906,  0.8125, -0.9219,  ...,  1.0312, -0.6641, -0.0303]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([164], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0405,  0.0923,  ...,  0.1875, -0.1650,  0.0101]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0004,  0.0918, -0.0659,  ..., -0.0204, -0.2217,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,   6.6250,   5.5625,  ...,   5.6875,  11.9375,   3.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4531, -1.4766, -0.2344,  ..., -1.1719,  0.1914, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([165], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1621, -0.0281,  0.1108,  ..., -0.1050, -0.0022, -0.0161]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555, -0.0938, -0.0344,  ...,  0.2539,  0.1709,  0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.2500,   9.1875,   2.8594,  ...,   6.4375,   5.8438,   2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1836,  0.2266, -0.9062,  ..., -1.3125,  2.4688, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([166], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0229,  0.0688,  ...,  0.1562,  0.0508, -0.0309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1123, -0.1484, -0.1206,  ...,  0.0532,  0.1436,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.1875,   9.4375,   7.0000,  ...,   2.3438,   6.5938,  -4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5664,  0.9727, -3.7969,  ...,  0.2041, -1.3828, -0.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([167], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.1348,  0.0869,  ..., -0.0649, -0.0972,  0.1260]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0640, -0.2432,  0.1094,  ...,  0.0654, -0.0347, -0.0498]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.2500,   4.0312,   7.7500,  ...,  -2.5625,   5.1875,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109,  1.3438,  0.5781,  ..., -3.0156, -1.6797, -5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([168], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0352, -0.0291,  0.0820,  ...,  0.0325, -0.0610, -0.0210]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1445, -0.0588,  0.0559,  ..., -0.1367,  0.0767,  0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6250, -0.1953,  3.2969,  ...,  0.0156, -6.9688,  2.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0161,  0.2256,  0.9297,  ..., -1.6328, -1.3203, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([169], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0259, -0.0515,  0.0291,  ...,  0.0474, -0.0669, -0.0190]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703, -0.1289,  0.1328,  ...,  0.1348,  0.0806, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -1.3594,  5.4688,  ...,  1.1562, -7.0625,  2.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.4688,  1.1797, -4.2812,  ..., -1.6875,  1.2812, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([170], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0250,  0.0562,  0.0447,  ..., -0.0415,  0.0181,  0.0087]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0513,  0.1084,  ..., -0.0801,  0.1562, -0.0378]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234, -2.0156,  3.9375,  ..., -3.6094, -4.4062,  3.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0156,  0.7305, -5.0938,  ..., -2.2344, -1.8359, -7.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([171], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269,  0.0454,  0.1953,  ..., -0.0347, -0.0845, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.0588, -0.0312,  ...,  0.2422,  0.0698, -0.0525]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9375,  0.2617, -2.0625,  ...,  2.4062, -9.4375,  3.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3535,  0.9531, -2.9531,  ..., -1.7422,  0.9492, -0.9492]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([172], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0488, -0.0033,  0.0620,  ...,  0.0640, -0.0305,  0.0135]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0181, -0.0148,  0.0923,  ...,  0.0339,  0.0771, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0938,  1.3750, -9.1875,  ..., 11.6250, -2.0000,  5.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -2.7500,   2.4844,  -4.0625,  ...,  -2.5000,   5.0625, -10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([173], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0332,  0.0410,  0.0435,  ..., -0.0444,  0.0356,  0.0131]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1377, -0.0014,  0.0957,  ..., -0.0732,  0.1455, -0.0586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.6875,  7.7812, -7.0938,  ...,  7.7812,  2.1250, 12.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1504,  1.4609, -4.5938,  ..., -7.6250, -1.2656, -7.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([174], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0623,  0.1201,  0.1465,  ..., -0.0125, -0.0226, -0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0066, -0.0615,  0.0032,  ...,  0.2285,  0.0457,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828,  3.1250,  1.1562,  ...,  3.5469, -0.7852, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.8906, -3.8750,  ..., -0.0742,  0.7109, -0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([175], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0544,  0.0085,  0.0552,  ...,  0.0250, -0.0654,  0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0471,  0.0229,  0.1104,  ...,  0.0141,  0.0845, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -1.3750,  -4.5625, -13.2500,  ...,  17.0000,   2.8438,  -8.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6094, -1.3516, -4.9688,  ...,  3.4375,  3.6250, -4.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([176], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0386,  0.0430,  0.0417,  ..., -0.0488,  0.0408,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0398,  0.0967,  ..., -0.0640,  0.1357, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312,  -5.0000, -17.0000,  ...,  10.7500,   7.3438,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.4062, -0.3320, -3.2969,  ...,  3.1094, -1.5234, -5.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([177], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0223, -0.0259,  0.0874,  ..., -0.0486,  0.0586, -0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0439,  0.0493,  0.0659,  ..., -0.0315,  0.0640,  0.0214]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  6.7188,   1.6719,  -9.5625,  ...,   3.0312, -12.0625,  -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1797, -2.9531, -1.1719,  ..., -4.2500,  1.3750, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([178], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0859,  0.0437,  ...,  0.0640,  0.0679, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1484, -0.1201,  0.2236,  ..., -0.0203,  0.1035, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.7812, -1.3672, -1.7969,  ...,  7.3438, -1.8125, -1.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031,  1.9844, -1.9141,  ..., -1.7344,  0.0469, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([179], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0703,  0.0212,  0.0854,  ...,  0.0052, -0.0053, -0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603,  0.0150,  0.0417,  ..., -0.0186,  0.0898, -0.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.7188,  3.1406, -6.6250,  ..., 16.1250, -4.3750,  4.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 4.2188, -3.6094, -4.1562,  ..., -0.2090,  2.2656, -5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([180], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0095,  0.0491,  0.0430,  ..., -0.0559,  0.0598,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1680,  0.0376,  0.0762,  ..., -0.0327,  0.1348, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1875,  6.4375, -1.6562,  ..., 13.1875, -5.0625,  8.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.5312, -1.4922, -0.1875,  ..., -5.1562, -2.1094, -5.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([181], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0042, -0.0366,  0.0801,  ..., -0.0500,  0.0723, -0.0986]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0386,  0.0645,  0.0786,  ..., -0.0339,  0.0791,  0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.3516,   2.2188,  -7.1562,  ...,   4.2500, -10.3125,   3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0625,  0.3262,  0.6250,  ..., -4.6562,  0.8945, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([182], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0420,  0.0154,  0.0698,  ...,  0.0371,  0.0256,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0898,  0.0167,  0.0437,  ...,  0.0228,  0.0598, -0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,   6.7188, -21.0000,  ...,   9.4375, -10.2500,  -0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1562, -1.3516, -3.4219,  ...,  1.3281,  2.2188, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([183], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0403,  0.0400,  ..., -0.0540,  0.0645,  0.0029]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1904,  0.0422,  0.0869,  ..., -0.0292,  0.1318, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.1875,  14.6250, -26.1250,  ...,   3.3906,  -6.8125,   9.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 5.1875, -0.0527, -3.4688,  ...,  1.9688, -5.3125, -6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([184], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0052,  0.0211,  0.1367,  ..., -0.0199, -0.0408, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0102,  0.1074,  0.0894,  ...,  0.0618,  0.0874, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5312, -4.5312,  1.3203,  ...,  3.6406, -4.5938,  9.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6641,  2.2344, -2.0938,  ..., -0.4453, -0.6953, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([185], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0089,  0.0679,  ..., -0.0019,  0.0001,  0.0166]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0820,  0.0162,  0.0625,  ...,  0.0021,  0.0859, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.8750,  10.8125,  -2.5625,  ...,   8.6875,  -0.4414,  11.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8125, -2.5312, -0.8984,  ..., -2.7812,  0.4199, -1.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([186], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0237,  0.0322,  0.0393,  ..., -0.0645,  0.0562,  0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2051,  0.0461,  0.0908,  ..., -0.0236,  0.1309, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3125,  16.5000,  -3.6719,  ...,   3.1250,   0.6211,  20.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -1.2500,  2.4531,  ..., -4.1562, -5.6562, -3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([187], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0081, -0.0388,  0.0972,  ..., -0.0452,  0.0549, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0315,  0.0608,  0.0630,  ..., -0.0232,  0.0845,  0.0310]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.1250,  -2.1562, -14.9375,  ...,   1.9766, -22.7500,   3.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2246,  0.4082,  2.5000,  ..., -1.5078, -1.2734, -2.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([188], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0552,  0.0044,  0.0703,  ...,  0.1602, -0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2441, -0.1235,  0.0281,  ..., -0.0737,  0.1377, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.6875,  -7.2188,   2.8281,  ...,   5.4688,   2.8281,   1.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0488,  0.5234,  3.6250,  ...,  0.4199,  4.4688, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([189], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0422, -0.0938,  ...,  0.1309, -0.1289, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0415,  0.1387, -0.0889,  ...,  0.1445,  0.1494,  0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   2.8750,   9.0000,  ...,  -2.0312,   5.7500,   0.9258]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3203,  1.6406,  3.4219,  ..., -1.2344,  0.0947, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([190], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0635, -0.0454, -0.0184,  ..., -0.1436,  0.0635, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.0913, -0.2109,  ...,  0.2578,  0.3457, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.4375, -0.7422,  6.8125,  ...,  1.9844,  3.3438,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734,  0.6953, -1.3047,  ...,  0.6211,  2.4844, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([191], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0347,  0.0437,  ...,  0.1123,  0.0540, -0.1040]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1318, -0.1367, -0.1621,  ...,  0.0222,  0.1963, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.1719, -8.0625,  5.9375,  ...,  3.7656, 10.1875,  2.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6094,  3.3594, -0.9492,  ...,  5.1875, -6.0312, -2.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([192], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0166,  0.0752, -0.0776,  ..., -0.0101,  0.1572, -0.0591]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3652,  0.4648,  0.2090,  ...,  0.2051,  0.1289,  0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.1250,  -1.3828,   1.8750,  ...,  -1.3047,  -1.8984,  -3.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  4.6875,  2.4062,  ..., 10.7500, -1.7969, -9.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([193], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1108,  0.0035, -0.0752,  ..., -0.0850,  0.0019,  0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.1367, -0.0903,  ...,  0.0557, -0.1289, -0.1001]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.6875,  2.2188,  2.3438,  ..., -1.6562,  4.6562,  2.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5312,  3.9375,  0.5703,  ..., -2.0781,  1.6484, -2.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([194], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0430, -0.0004,  0.0762,  ...,  0.0527,  0.0044, -0.0605]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4219,  0.0089, -0.0142,  ...,  0.3301,  0.1494,  0.0035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.3125,   2.1250,  -7.1562,  ...,  -2.5469,   3.4062,  12.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828,  1.1875, -0.0869,  ..., -0.1582,  0.0640, -0.2852]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([195], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0128, -0.0190,  0.0889,  ...,  0.0938,  0.1279, -0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0613, -0.1230,  0.0201,  ..., -0.1445,  0.2188, -0.0354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1250,  -1.2500,   0.4980,  ...,  -2.0000,   4.5625,   0.2754]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1797,  0.1895,  2.1406,  ...,  1.7578,  3.2656, -3.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([196], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0374, -0.1396, -0.1387,  ...,  0.0417, -0.0093, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2734, -0.3164, -0.2832,  ..., -0.3320, -0.3789, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500, -2.5156,  7.4062,  ..., -1.0469,  2.0625,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7734,  0.3086,  1.0625,  ..., -2.4219, -0.3164,  0.2715]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([197], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0049,  0.0299, -0.1099,  ...,  0.3105, -0.0564, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  0.2773,  0.0693,  ...,  0.1045,  0.0222, -0.0253]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.3750,   5.6250,   2.5000,  ..., -10.1250,   4.6250,   3.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2207,  4.0312,  3.9688,  ..., -0.4668, -0.6328,  3.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([198], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0371, -0.0654,  0.0057,  ..., -0.1328,  0.0613, -0.1157]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2236,  0.0181, -0.2461,  ...,  0.2734,  0.2812,  0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -0.3242,  -5.6875,  ...,  -2.6719,  -0.4883,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3477,  1.0078, -2.6875,  ..., -0.1240,  0.1211,  0.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([199], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0014, -0.0566,  0.0498,  ...,  0.0295,  0.0742,  0.0025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1055, -0.0830, -0.0139,  ..., -0.1406,  0.1748, -0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.5625,   2.5312,   2.3906,  ...,   0.0664,  -2.2812,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2734, -1.6875,  2.2344,  ..., -0.4727, -0.2852, -2.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([200], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0275, -0.0879, -0.0281,  ...,  0.0366, -0.0378, -0.1465]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0859, -0.1162,  0.2412,  ..., -0.4141, -0.1465, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.7500,  -1.0312,  -1.0312,  ...,  -5.6875,  -1.5078,  10.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  1.0703, -1.2500,  ..., -1.3516, -5.0625, -5.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([201], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-3.1006e-02,  4.5898e-02,  8.6914e-02,  ...,  1.5234e-01,\n",
      "         -2.7710e-02,  1.2207e-04]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4961,  0.0732, -0.0786,  ..., -0.2090,  0.3418, -0.0311]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.6250,   1.3750,  -4.6250,  ...,  -0.2266,   0.8750,   1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2344, -1.7109, -1.2344,  ...,  1.8438, -0.5234, -0.8398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([202], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0442, -0.0248,  0.0141,  ...,  0.1533,  0.1504, -0.0942]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3145,  0.1895,  0.2295,  ..., -0.0566, -0.1982, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -3.4219, -0.4863,  ...,  5.7188,  7.4062, -1.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3672,  0.6992, -3.0312,  ..., -1.1016,  0.8125,  0.2734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([203], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2295, -0.2207, -0.0649,  ..., -0.0718, -0.0923,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0064, -0.2021, -0.1973,  ..., -0.4062,  0.0801,  0.2236]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2500, -0.7188,  2.7500,  ..., -0.0391, -5.0312,  7.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773,  1.3750,  0.8516,  ...,  0.3047,  0.6055, -0.8594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([204], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201,  0.0327,  0.0294,  ...,  0.2188, -0.1846, -0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1235,  0.0080, -0.0635,  ..., -0.1475, -0.1680,  0.0598]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.4375,   0.1016,   1.7344,  ...,   3.3594,  -1.9766,  -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -1.4297, -0.0513,  ...,  1.0625, -2.2031, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([205], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0145, -0.0177,  0.0205,  ...,  0.0430,  0.1504, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.0029,  0.0178,  ..., -0.0640,  0.0352,  0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.7500, -2.5781,  1.4766,  ...,  2.0625,  5.3750, 10.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.6250,  0.2285, -2.2656,  ..., -2.4219,  2.3906, -2.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([206], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1406, -0.0908,  0.0466,  ...,  0.0312,  0.0267,  0.0444]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2715,  0.1064,  0.0728,  ...,  0.0840, -0.0510,  0.0923]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.2500,  -9.8125,  -4.0938,  ...,   6.5000,   0.0625,   4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3828, -0.7617, -4.3438,  ..., -2.0938, -0.7617, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([207], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0254, -0.0308,  0.0713,  ...,  0.0791, -0.0344, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2559,  0.0840, -0.0801,  ...,  0.0131, -0.3262,  0.2891]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3125,  -6.8750,  -3.0000,  ...,   7.5000,  -0.9414,   8.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.4375, -0.5898, -0.8984,  ..., -0.6484,  1.4375, -5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([208], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0121,  0.0052, -0.0405,  ...,  0.1064, -0.1533, -0.0693]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.1836,  0.0071,  ..., -0.1787, -0.0183, -0.0322]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,  -0.9141, -10.8750,  ...,   7.6875,   6.4062,   8.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7930, -1.3906, -1.1797,  ...,  6.0000,  2.3594, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([209], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2090,  0.0422, -0.0266,  ...,  0.1953,  0.0400, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1055, -0.0079,  0.0879,  ...,  0.5273,  0.1064, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.7500,   3.9375,  -6.9062,  ...,   8.4375,   2.1250,   3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8750,  2.4062, -3.7031,  ...,  1.5000,  0.1758, -0.3945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([210], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0378, -0.2236, -0.0425,  ...,  0.2852,  0.0820, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1016,  0.1079, -0.1123,  ..., -0.0420,  0.0840,  0.1123]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.8438, -10.2500,  -6.4375,  ...,   7.3125,   2.4219,  -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.7891, -1.5938,  ...,  0.2539, -1.3125, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([211], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0884, -0.0625,  0.0178,  ...,  0.0522, -0.0459, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1602, -0.1650, -0.1553,  ...,  0.0664,  0.1523,  0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9688, -4.6875,  0.7109,  ...,  5.7188,  9.3750, -6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2109, -0.4648, -1.4766,  ..., -2.1875, -3.1875,  0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([212], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0718,  0.0967, -0.0025,  ...,  0.0957,  0.0457, -0.0371]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0133,  0.0188,  0.0359,  ..., -0.1621, -0.0522,  0.1680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500,  1.8594,  6.8750,  ..., -2.5625,  6.0625,  0.6602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9531, -1.5703, -3.1406,  ..., -0.8594, -0.3652, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([213], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0498, -0.0120, -0.0415,  ..., -0.0267,  0.0344, -0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147,  0.0156,  0.0996,  ...,  0.0032,  0.0033,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188, -5.4688,  0.9922,  ..., -1.6328, -9.1250, -2.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2344, -0.6055,  0.2812,  ..., -2.5312, -0.2988,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([214], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787,  0.2139,  0.0083,  ..., -0.0581, -0.0072, -0.1582]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1045, -0.0708, -0.1475,  ..., -0.1523,  0.0121, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062, -7.9375, -4.5938,  ..., -0.1250, -7.0938, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4453, -1.2031, -1.3359,  ..., -2.6250, -1.4062, -0.7461]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([215], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0557, -0.0625,  0.0015,  ..., -0.1133,  0.0200,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0679, -0.0146,  ...,  0.1157,  0.1138, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0000, -6.4688, -5.0625,  ...,  6.7500, -6.6250,  8.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2969, -3.1406, -3.8281,  ...,  2.7031, -3.3438, -4.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([216], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206, -0.0952,  0.0859,  ..., -0.0371, -0.0078, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118, -0.0977, -0.0192,  ...,  0.1309,  0.0728, -0.0084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.4688,  -4.5000, -13.4375,  ...,   3.9844,   4.2812,  -1.0078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7734,  2.1719, -1.7812,  ..., -1.6406, -3.7969, -0.5039]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([217], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0003, -0.0223,  0.0947,  ...,  0.0269, -0.0747, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.1030, -0.0625,  ..., -0.1992,  0.2031, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0586, -6.8750, -6.1250,  ...,  5.6250,  0.3320,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8047,  0.8359, -5.6562,  ...,  0.3066, -0.9727, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([218], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347,  0.0820,  0.1069,  ..., -0.0928,  0.0327, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1738,  0.0022,  0.0209,  ...,  0.0398,  0.0645, -0.0483]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -1.9922, -1.1094,  ...,  6.5312,  1.7344,  9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0781, -3.3438, -4.0312,  ...,  4.5000, -3.0156, -7.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([219], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0101, -0.0310,  0.0374,  ..., -0.0248,  0.0588, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0243,  0.0483,  0.0471,  ..., -0.0439,  0.0703,  0.0225]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.0625,   6.8438, -10.1875,  ...,  -0.8438,   3.7188,  -2.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406,  0.7656, -3.4219,  ..., -1.2422, -1.2422, -1.1016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([220], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0261,  0.0211, -0.1226,  ..., -0.0240, -0.0713,  0.0182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0050, -0.2812,  0.1089,  ..., -0.0972,  0.0781, -0.1187]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.2500,  0.4727, -2.5312,  ..., -1.2188, -0.5625,  6.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3516,  0.4043, -0.8906,  ..., -0.1191, -0.8672, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([221], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0278, -0.0342,  0.0014,  ..., -0.0276,  0.0496, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1079, -0.1396, -0.1138,  ..., -0.0674,  0.1187,  0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.9375,  -0.2773, -11.5000,  ...,   2.4688,   1.2812,   2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -1.2109, -1.4766,  ..., -1.2891, -1.7969, -0.3984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([222], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0513, -0.0189,  0.0771,  ..., -0.1338,  0.0918, -0.0203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0216, -0.0508,  0.0908,  ..., -0.0728,  0.0117, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8125,  4.5000, -5.0312,  ...,  6.4375, -9.1875,  5.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3672,  2.1562, -1.0000,  ..., -0.2090, -1.4219, -0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([223], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1572,  0.1162, -0.0645,  ..., -0.1660, -0.0317, -0.1357]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641,  0.1406, -0.1719,  ..., -0.0454, -0.1738,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000, -3.0469, -4.2188,  ...,  2.9375, -0.7891,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8984, -0.5781, -2.2812,  ...,  0.1367, -1.4531,  0.8008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([224], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1914, -0.1011, -0.1113,  ...,  0.0991,  0.0027, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.1060, -0.5508,  ...,  0.0635,  0.0010,  0.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3438, -2.7188, -1.6328,  ...,  7.4375,  3.2500, -4.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.2344, -2.0469,  2.9688,  ...,  0.8750, -2.1562,  1.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([225], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0269, -0.1162, -0.1279,  ...,  0.0317, -0.1875, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0293, -0.1211, -0.0554,  ...,  0.1406,  0.2188, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578, -2.2812,  0.6836,  ...,  7.8750,  2.4688, 10.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0112,  1.1562, -0.7539,  ..., -0.9805, -0.2441, -0.6641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([226], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0141,  0.0535,  0.0339,  ..., -0.0366, -0.0325,  0.0173]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172, -0.0762, -0.0684,  ..., -0.0806,  0.0957,  0.0115]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1211, -1.9531, -8.0000,  ...,  1.2344,  2.8750,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9023, -1.3594, -0.9531,  ..., -0.7734, -0.1602,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([227], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0322, -0.1309, -0.0139,  ..., -0.0581,  0.0099, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1641, -0.2734,  0.0684,  ...,  0.0596,  0.1787, -0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4062, -1.1562, -9.0625,  ...,  3.8750,  3.9062,  3.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0156, -0.4707, -1.2812,  ..., -0.8672, -1.1406,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([228], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0188,  0.1138,  0.0850,  ..., -0.1377,  0.0322, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520,  0.1572, -0.0991,  ..., -0.1289,  0.0278,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.4375, -6.1250, -9.9375,  ...,  1.0312,  2.4375,  3.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1016, -0.0588,  0.0527,  ..., -1.7500, -1.3359, -0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([229], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0077,  0.0459, -0.0118,  ..., -0.0659, -0.0806, -0.2021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1426, -0.0532,  0.0776,  ...,  0.1230, -0.0698,  0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3281,  3.4219, -5.5938,  ...,  5.5625,  5.3438,  4.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6172, -0.6641, -0.2021,  ..., -2.3906, -2.0469,  0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([230], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1191,  0.0542,  0.1016,  ..., -0.1846,  0.0723, -0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.1455,  0.2461,  ...,  0.0588, -0.1235, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.3281, -0.8633, -4.4688,  ...,  1.4453,  3.3906,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8125,  1.3984,  0.3125,  ..., -0.9062,  0.1221,  0.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([231], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0173,  0.0708,  0.1211,  ..., -0.1484,  0.1162, -0.0903]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0771, -0.1157,  0.1953,  ..., -0.1377,  0.0723,  0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7812, -4.4375, -2.1562,  ...,  6.6562, -0.9141,  6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9219, -0.9570, -1.7344,  ..., -1.8203, -2.6250, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([232], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0850, -0.0009, -0.0737,  ..., -0.1514, -0.0610, -0.0405]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0879,  0.2793,  0.0630,  ..., -0.1895, -0.2021,  0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2188,  0.3945, -3.0938,  ...,  2.2344, -3.7969,  5.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5625,  1.5625,  1.1328,  ..., -0.0088, -1.0703, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([233], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.0090,  0.0737,  ...,  0.0391,  0.0654, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0574, -0.1436, -0.0649,  ..., -0.0208,  0.1611,  0.1089]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,  -2.4688,  -3.0938,  ...,   0.9219,   1.3750,   5.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5859, -4.1562, -1.2500,  ...,  4.5000, -0.2578, -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([234], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0266,  0.0045,  0.0518,  ..., -0.0148,  0.0019, -0.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0894,  0.1138,  0.0718,  ...,  0.1289,  0.0859, -0.0518]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.8125,   0.9531,  -4.1250,  ...,   0.9219,  -3.6875,   6.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.9844,  0.0894, -7.2500,  ..., -0.4375,  4.9062, -4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([235], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006,  0.0017,  0.1025,  ..., -0.0459, -0.0135, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1152,  0.2754, -0.0388,  ...,  0.0559, -0.0698,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.0625,  -2.8906,  -6.7812,  ...,  -3.7812,  -1.4062,  -0.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1406, -3.1094, -4.5938,  ..., -0.9844,  1.0312, -3.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([236], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0034,  0.0786,  0.1689,  ...,  0.0786,  0.0271, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2578,  0.1660, -0.1406,  ...,  0.0938, -0.2793,  0.3398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.6250,   0.9727,  -1.7734,  ...,   2.2969,  -0.9453,  -3.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.0625, -1.7578, -0.1875,  ...,  6.3125,  4.4688, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([237], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1592, -0.1045,  0.1914,  ...,  0.1543,  0.0072, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0442, -0.2314,  0.0262,  ..., -0.1484,  0.0781, -0.0427]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,  -2.7188,  -0.3203,  ...,   7.5000,  -6.2500,  -6.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ -4.5312,   1.7891,  -1.7266,  ..., -10.5000,  -3.0938, -15.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([238], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1104,  0.0806,  0.0972,  ..., -0.2891,  0.0352, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1650,  0.1279,  ..., -0.1621, -0.1299, -0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.4375,  -0.2422,  -6.0938,  ...,   4.4062,   3.4531,  -5.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.1094, -2.4375, -1.1406,  ...,  5.7500,  1.4062, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([239], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0116,  0.0306,  0.1143,  ..., -0.0610,  0.0164, -0.2617]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416,  0.0972,  0.0184,  ...,  0.1934,  0.2773, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.5625,   1.0469,   1.1875,  ...,   2.9844,   3.7188,   1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9141,  1.2031, -2.3438,  ...,  2.6406, -0.5547, -2.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([240], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0503, -0.1465, -0.0308,  ...,  0.2178,  0.0996, -0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1357,  0.0579, -0.1670,  ...,  0.0228,  0.1465,  0.0664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.8125,  -6.3438, -10.8750,  ...,   3.7500,   3.7500,   2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297, -4.3750, -0.3203,  ...,  1.2969,  0.5586,  0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([241], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0649, -0.0378,  0.0535,  ..., -0.0884, -0.0205, -0.0630]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3613,  0.3379,  0.2461,  ..., -0.0028, -0.0038,  0.3809]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7812,  -2.4688, -14.8125,  ...,   2.7656,   0.5195,  -1.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -3.0156, -0.0547,  ...,  2.9531, -2.8125,  0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([242], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1084,  0.0352, -0.0210,  ...,  0.1123,  0.0635, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0603, -0.3633,  0.1553,  ...,  0.4434,  0.0547, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.7188,  2.9062, -6.3438,  ...,  8.7500,  4.8438,  5.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5938, -1.0625, -0.1299,  ..., -2.4844, -4.2500, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([243], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0317,  0.0398,  0.0200,  ..., -0.1328,  0.0103, -0.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0413, -0.1011,  0.2266,  ..., -0.1475, -0.0757, -0.0381]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2500, -7.1250,  6.2500,  ...,  3.6250,  1.5625, -0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4023, -0.8906, -1.0938,  ..., -1.4141, -3.2344, -1.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([244], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0276, -0.1035,  0.0542,  ..., -0.1592, -0.0403, -0.0422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0532, -0.0732,  0.1030,  ..., -0.0496, -0.0403,  0.0306]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6875,  3.3438,  4.6875,  ..., -5.4688, -5.0312,  1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2734, -1.3203,  0.6953,  ..., -1.2891, -0.5430, -0.0298]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([245], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0055,  0.1250, -0.0396,  ..., -0.0474,  0.0518, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0449, -0.3613,  0.1152,  ...,  0.0118,  0.0014, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.5625, -1.9688,  0.4434,  ..., -1.9141, -5.7500, -0.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8398, -0.8984, -0.0801,  ..., -0.2930, -0.8047, -0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([246], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0369,  0.0596,  0.0466,  ..., -0.0334,  0.0879, -0.0884]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1025, -0.0767,  0.0381,  ...,  0.0045,  0.0075, -0.0134]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.5312, -9.0000, -9.7500,  ...,  4.1562, -0.4980,  5.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906, -2.0781, -1.8203,  ...,  2.1406, -1.6016, -0.6523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([247], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1201, -0.0488,  0.0227,  ...,  0.0605, -0.1045, -0.1787]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009,  0.1328, -0.0374,  ..., -0.1084, -0.1436,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9375, -1.6250, -6.7188,  ...,  1.1172,  4.1250,  5.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3203, -1.3516,  0.4414,  ..., -1.8438, -0.3555,  0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([248], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1206,  0.0879,  0.1777,  ...,  0.2520,  0.0791, -0.0127]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0209, -0.1680, -0.3281,  ...,  0.3242,  0.1709, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2812,  3.2812, -3.3125,  ...,  7.8125,  2.1562, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9883, -1.0469, -1.6328,  ..., -2.1406,  1.2188, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([249], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1553,  0.1738,  0.0493,  ...,  0.0033,  0.0309, -0.0090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2676, -0.1807,  0.4961,  ..., -0.4355,  0.0439,  0.2109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.7812,   1.0938, -10.5000,  ...,   1.2422,   5.0938,   8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9375, -0.0198, -0.1777,  ...,  0.1201, -0.3965, -1.3047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([250], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0110,  0.0265,  0.0586,  ..., -0.0178, -0.0039, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.1318, -0.0515,  ..., -0.0718, -0.0056,  0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5000,  -2.0625, -14.3750,  ...,   1.6875,   7.1875,   6.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4531, -0.7930,  0.4805,  ..., -0.2480, -1.6953,  0.3496]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([251], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0325,  0.0486,  0.0074,  ..., -0.0444,  0.0198, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2383,  0.1143, -0.0037,  ..., -0.0432,  0.0498,  0.1572]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -9.3750,  -5.7188, -12.8750,  ...,   5.8125,   1.0938,   0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2539, -1.8984, -0.6133,  ...,  1.8594, -2.9375, -0.0146]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([252], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-7.9102e-02,  1.9775e-02, -8.5449e-02,  ...,  3.3691e-02,\n",
      "          1.8311e-04, -2.2656e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0393, -0.0869,  0.2598,  ...,  0.2832, -0.0684, -0.2178]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4629, -3.6250, -3.5625,  ...,  5.6250,  7.8125,  0.6016]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3906, -0.4473, -0.5391,  ..., -3.6875, -3.6250, -0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([253], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0004,  0.0503,  0.0476,  ..., -0.1084, -0.0118, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0938, -0.0091,  0.2656,  ..., -0.1836, -0.0121, -0.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2969, -6.7812,  8.3125,  ...,  3.5469,  3.0156, -1.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7031, -0.4258, -1.5625,  ..., -2.8281, -2.2188, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([254], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0067,  0.0164, -0.0167,  ...,  0.1787, -0.1172, -0.0510]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2832,  0.1182,  0.2695,  ...,  0.0049,  0.1641,  0.0488]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125,  7.7188, -0.5859,  ...,  2.6250,  4.3125, -0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0859,  0.4492, -1.6094,  ..., -1.1328,  0.5703, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([255], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0977, -0.0532, -0.0732,  ...,  0.0471, -0.0479, -0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0481, -0.3965,  0.1592,  ...,  0.0150,  0.0457, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  7.0625, -2.7031,  ..., -1.6250,  2.4688,  2.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363,  0.6016, -0.1279,  ..., -0.8594, -0.7422, -0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([256], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1367, -0.1367, -0.0420,  ...,  0.0317, -0.0620, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943, -0.4434,  0.1079,  ..., -0.0645, -0.3047,  0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.2500,  1.2812,  5.0938,  ...,  3.2500,  3.6562,  2.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2578,  0.1650, -1.1484,  ..., -2.7656, -3.5625, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([257], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0444,  0.0315,  ..., -0.0344,  0.0238, -0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1338,  0.0315, -0.0210,  ..., -0.1494, -0.0040, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.5625,  4.3438, 13.4375,  ...,  4.6875,  6.9375,  2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9180, -3.2812, -1.6875,  ..., -1.1094,  0.7500, -0.1885]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([258], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0615, -0.0332,  0.0010,  ..., -0.0598, -0.0483, -0.1240]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0491,  0.0645,  0.0664,  ...,  0.0209, -0.0654,  0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9062,  2.6875, -2.2812,  ...,  3.2344, -1.3438,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4258,  0.9688,  0.1523,  ..., -0.1001, -1.3672, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([259], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664,  0.0361,  0.0874,  ...,  0.0618,  0.0825, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1133, -0.1406, -0.0708,  ..., -0.0840,  0.1543,  0.0776]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.5000, -1.2812, -1.9219,  ..., -8.1250,  1.9844, 11.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3281, -1.1406, -0.6992,  ...,  1.5859, -1.7344, -0.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([260], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0137, -0.0452,  0.0129,  ..., -0.0325, -0.0408, -0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0239,  0.0718,  ...,  0.0339,  0.0354,  0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.2812, -1.7422,  0.3008,  ...,  2.4688, 10.5000,  2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 3.7344,  1.4375, -7.6250,  ..., -2.0625,  5.4062, -1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([261], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0713,  0.0087,  0.0430,  ..., -0.0513,  0.0073, -0.0825]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0825,  0.3750,  0.0073,  ...,  0.0231, -0.0840,  0.1143]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125, -2.3125, -5.9375,  ..., -9.3125,  9.5625, -0.9453]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8906,  0.5859, -5.6875,  ..., -0.9180,  2.0156, -0.4336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([262], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0376,  0.0996,  0.1855,  ...,  0.0708,  0.0593, -0.2100]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598,  0.1699, -0.1650,  ...,  0.1270, -0.2793,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7969,  0.0234, -2.9219,  ...,  3.3125, 16.0000, -0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8906,  1.1719, -5.0312,  ...,  4.3125,  1.9844,  2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([263], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0062,  0.0330,  ..., -0.1865,  0.0479, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1167, -0.0483,  0.1338,  ..., -0.0947, -0.0889,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000, -2.9531, -3.1562,  ...,  9.2500, -2.9062, -3.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0781, -1.2969, -2.5000,  ...,  0.6875,  0.8281, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([264], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1777,  0.1084,  0.0554,  ..., -0.2412,  0.0254, -0.2910]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0229, -0.0291,  0.0012,  ..., -0.2773,  0.0286,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.9375,  2.6875, -0.3828,  ...,  8.3750, -2.1562,  2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.2637, -5.5312,  ...,  0.6641,  0.2773, -0.9180]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([265], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0586, -0.1738, -0.0016,  ...,  0.2344,  0.0986, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0820,  0.1006, -0.1426,  ...,  0.0270,  0.1299,  0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4941, -4.0938, -5.7500,  ..., -7.7188, 11.5000,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.7578, -0.7656,  ...,  0.4375, -0.5234, -0.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([266], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0525,  0.0801,  ..., -0.0664, -0.0182, -0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3770,  0.3809,  0.2256,  ...,  0.0265,  0.0229,  0.4004]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -1.3047, -3.3594,  ..., -5.6875,  8.7500, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747, -0.2207, -1.7266,  ...,  2.3125, -1.2734, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([267], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0000,  0.0908, -0.0277,  ..., -0.0100, -0.1338, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4570, -0.1963, -0.0123,  ..., -0.5742, -0.2402, -0.0295]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250, -0.8906, 14.8750,  ..., -4.2500,  1.9297, 11.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.0469,  0.0723,  1.0234,  ..., -0.2012, -4.4062, -0.5742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([268], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0452,  0.0732,  0.1357,  ..., -0.0630,  0.0679, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0552, -0.1055, -0.0835,  ...,  0.0432,  0.0554, -0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7812, -2.7812, 14.1875,  ...,  1.0312, -3.7812,  4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.9297,  2.4531, -0.0752,  ...,  0.5547, -2.3750,  0.8086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([269], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0203,  0.0864,  0.1592,  ..., -0.0791, -0.0449, -0.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0967,  0.0938,  0.1826,  ...,  0.1206,  0.1040, -0.0142]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.7500, -4.6562,  4.1562,  ...,  8.3750,  2.0625, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3457,  0.9961,  8.0000,  ..., -5.5625, -4.2812,  3.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([270], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0044, -0.0996, -0.0099,  ..., -0.0967,  0.0081, -0.0159]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0359, -0.1084,  0.0522,  ...,  0.1660,  0.2256, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.0938, -3.8125,  1.9375,  ...,  2.6562,  1.3750,  0.6719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5156, -3.5156, -2.2500,  ..., -4.5625, -0.5234, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([271], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0845, -0.0160, -0.0090,  ..., -0.1011, -0.0762,  0.0330]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1895, -0.0023, -0.0085,  ..., -0.0269, -0.0820, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9062, -1.1953,  4.1250,  ...,  2.4844, -1.4844,  9.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9219,  0.8789,  0.4473,  ..., -1.8516, -1.1875, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([272], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0020,  0.0603,  0.0977,  ...,  0.1147, -0.0261, -0.0889]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.1138, -0.1348,  ..., -0.0933,  0.0277,  0.0659]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.0469, 10.5000,  3.9531,  ..., -7.4375,  4.5000, 13.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3594, -4.9688, -1.2891,  ...,  0.2070,  0.0299, -2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([273], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.0688, -0.0112,  ...,  0.1826,  0.0262, -0.0474]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1147, -0.2236,  0.3105,  ..., -0.0029, -0.0605,  0.0349]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.6875,  2.4219,  0.3203,  ..., -5.7500,  4.7500, 13.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000, -2.3438, -4.2188,  ..., -0.9297, -0.0762, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([274], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1030,  0.0015,  0.0364,  ...,  0.1953,  0.1299, -0.0264]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0938, -0.1533,  0.0669,  ...,  0.0383, -0.0513,  0.3223]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.6406, -3.8906,  1.3906,  ..., -1.0547,  8.4375,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1016, -1.8125, -3.5938,  ..., -1.7188, -2.4531,  0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([275], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0049,  0.0630,  0.0227,  ...,  0.1074, -0.0233,  0.0045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0093, -0.1865,  0.0781,  ..., -0.1445, -0.3105, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0000,  0.5547,  7.2500,  ...,  0.4766, 10.7500,  4.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188,  1.3281, -0.2812,  ..., -3.4531, -3.2656, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([276], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1040,  0.1006,  0.0201,  ..., -0.1079, -0.0879, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2656,  0.2051, -0.0781,  ..., -0.0830, -0.2617,  0.3105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-15.1875,  -1.3125,  -1.0312,  ...,   6.5312,  -1.0156,  10.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7148,  0.9297, -2.4375,  ...,  0.2070,  2.5469, -1.5234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([277], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0283, -0.1279,  0.0229,  ...,  0.1670,  0.2539, -0.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2373,  0.2275, -0.2598,  ...,  0.0791,  0.4648, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1641,  0.5078, -5.5312,  ...,  2.0312,  5.9688, -1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2520, -4.7812, -0.1475,  ..., -0.0248, -2.3594,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([278], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0320, -0.0063,  0.0215,  ..., -0.1904,  0.0610, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0287,  0.0013,  ..., -0.0591, -0.1494,  0.3262]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9062,  9.0625, -4.4062,  ...,  1.0781,  2.1875,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2539, -0.9375,  1.0781,  ...,  0.5234, -1.4297, -2.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([279], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366,  0.0386, -0.1582,  ..., -0.0640, -0.0874,  0.0430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0830, -0.4863,  0.0315,  ..., -0.0464,  0.0864,  0.1514]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.1562,  1.0859, -1.6016,  ..., -4.0625, -6.5938,  4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430,  0.6211,  1.4062,  ...,  1.5469, -1.6953, -1.7109]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([280], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0256, -0.0107, -0.0942,  ..., -0.0193, -0.0305, -0.0972]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2598, -0.1963, -0.0009,  ..., -0.0879, -0.1514,  0.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.1250, -1.9453, -1.9297,  ..., -1.7891, -5.7500,  4.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8438, -0.7031, -1.7500,  ..., -0.0352, -5.8750, -0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([281], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0108,  0.1035, -0.1143,  ...,  0.0776,  0.0947, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4277, -0.3965, -0.4316,  ..., -0.5039,  0.2832,  0.2949]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.7500, -2.1094, -5.4375,  ...,  2.7188,  0.1758,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.3750, -0.9219, -1.7969,  ..., -1.5000, -4.1562, -1.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([282], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0269,  0.1021,  0.0598,  ..., -0.0559, -0.0359, -0.1377]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0459,  0.2715,  0.0620,  ..., -0.2275, -0.0010, -0.1201]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3750,  2.5938,  0.6172,  ...,  3.0469, -9.4375,  6.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0623, -1.4688, -0.4082,  ..., -0.4336, -3.8125, -5.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([283], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0179, -0.0967,  0.0334,  ..., -0.1104, -0.0106, -0.0216]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0801, -0.0825,  0.1094,  ..., -0.0613, -0.0388,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7188,  2.0312,  1.1406,  ..., -0.3984, -3.1406,  1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5156,  0.7344, -0.9688,  ..., -0.5859, -1.1094, -1.1953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([284], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0493,  0.0996,  0.0884,  ...,  0.0610,  0.1187, -0.0549]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1396, -0.1089, -0.0498,  ..., -0.1221,  0.1475,  0.0547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1602,  0.8047,  4.1875,  ..., -5.5625,  5.9062,  6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2734, -1.8594, -2.2500,  ...,  4.3438, -0.5273, -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([285], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0820,  0.0581, -0.0192,  ...,  0.1689, -0.0243, -0.0618]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0435, -0.1035,  0.2832,  ..., -0.0133, -0.0172,  0.0304]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -1.5469,  3.3125,  ..., -2.9375,  8.4375,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6016, -0.9688, -4.5625,  ...,  3.0469,  0.4922,  0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([286], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0184,  0.0576,  0.0488,  ...,  0.1357,  0.1445, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1816,  0.0708,  0.0292,  ..., -0.0081, -0.0747,  0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2656, -2.2812,  4.0312,  ..., -0.4219,  3.1719,  6.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7734, -0.6523, -5.7188,  ..., -1.2578, -3.4844, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([287], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0088,  0.1011,  0.0635,  ...,  0.0703, -0.0100,  0.0129]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0046, -0.0630,  0.0552,  ..., -0.1025, -0.2969, -0.0017]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1367,  2.6094, 15.4375,  ...,  0.9375,  4.5625,  0.0801]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-6.1562, -0.6055,  0.3633,  ..., -2.8438,  2.8125, -3.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([288], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1089, -0.0037,  0.0791,  ...,  0.1123,  0.0044, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4355,  0.2129,  0.2158,  ...,  0.1338,  0.0781,  0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.4375,   0.8125,  -0.7891,  ...,   4.3125,  -3.3750,   7.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5625, -1.4297, -3.7969,  ...,  3.9531,  1.4922, -3.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([289], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1108, -0.1348,  0.0815,  ...,  0.2070,  0.2148, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2109,  0.2109, -0.2422,  ...,  0.1631,  0.3809, -0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.5625, -3.9531, -6.4375,  ..., -7.4375,  8.3750, -1.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.5938, -2.8125, -5.0000,  ..., -2.9531, -1.1875,  0.3926]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([290], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0092, -0.0317,  0.0583,  ..., -0.1348, -0.0233, -0.1348]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3535e-01,  1.6309e-01,  1.4404e-02,  ...,  2.8229e-04,\n",
      "         -7.5195e-02,  3.5156e-01]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562,  6.8438, -4.5625,  ..., -3.2500,  0.8398, -3.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -1.4219, -0.6758,  ..., -0.5703, -2.2344, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([291], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0757,  0.0076, -0.1113,  ..., -0.0791, -0.1260,  0.0435]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1099, -0.4238,  0.0476,  ..., -0.0148,  0.1025,  0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5625,  2.6875, -1.9922,  ..., -2.9688, -9.7500,  2.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.8906, -1.0156, -1.2500,  ..., -1.6953, -0.6523, -1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([292], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0874,  0.1826, -0.0272,  ..., -0.0825,  0.0635, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1416, -0.3398, -0.0928,  ..., -0.2490,  0.2695,  0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7500,  0.8516, -1.3516,  ..., -3.6562,  3.3438, -1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8594,  1.8672,  0.5273,  ..., -1.7891, -4.6562,  0.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([293], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0562, -0.1367,  0.0801,  ...,  0.0052, -0.0342, -0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3691, -0.2617, -0.0028,  ..., -0.6445,  0.4414, -0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2969,  0.5078, -6.2812,  ..., -1.6094, -2.2500,  6.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7031, -0.4473, -1.3984,  ..., -0.8203, -5.2500, -1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([294], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0728,  0.0835, -0.0132,  ..., -0.0593,  0.0461, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0378,  0.0830,  0.1182,  ..., -0.1172, -0.0510, -0.1318]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.4062,  0.8828,  ...,  2.6719, -9.5625, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.6250,  0.2910, -0.1416,  ..., -0.6094, -4.1250, -9.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([295], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0679, -0.0996,  0.0063,  ..., -0.1074, -0.0055, -0.0103]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0889, -0.1094,  0.1235,  ..., -0.0281, -0.0374,  0.0220]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0234,  1.8281, -3.8438,  ...,  0.4961,  2.6094,  3.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.0938,  1.5234,  0.2988,  ...,  0.8906, -2.2188, -1.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([296], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0591,  0.0962,  0.0542,  ...,  0.0654,  0.1279, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309, -0.1147, -0.0481,  ..., -0.1299,  0.1475,  0.0476]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2832,  3.6250,  3.0156,  ..., -5.3750,  0.8555,  7.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -1.8359, -2.5625,  ...,  2.9844, -0.7188, -3.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([297], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0811,  0.0557, -0.0396,  ...,  0.1719, -0.0134, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0476, -0.0801,  0.2949,  ..., -0.0127, -0.0183,  0.0654]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9062, -0.4648,  1.7734,  ..., -7.5625,  4.2500,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3906, -1.5234, -3.2656,  ...,  1.3125, -1.9766, -0.9883]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([298], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0240,  0.0591,  0.0352,  ...,  0.1338,  0.1621, -0.0757]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1943,  0.0967,  0.0371,  ..., -0.0011, -0.0679,  0.3086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -1.6406,  3.1562,  ..., -4.3438, -0.5664,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9922, -0.3398, -4.8750,  ..., -0.3789, -2.7031, -2.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([299], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.1074,  0.0544,  ...,  0.0684, -0.0049,  0.0060]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0099, -0.0530,  0.0518,  ..., -0.0972, -0.3008,  0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6562,  3.1094, 10.3125,  ..., -3.0625,  3.4219,  4.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.5625,  2.0469,  2.4219,  ..., -0.5039,  0.5352, -0.9766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([300], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177,  0.1099, -0.0228,  ..., -0.0127,  0.0449, -0.1758]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2617,  0.3340, -0.0825,  ..., -0.0762,  0.1069,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.6875,   0.8594,   0.2656,  ...,   3.7188,  -2.8906,   9.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.2500, -0.5898, -3.4688,  ...,  6.4375,  0.2637, -1.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([301], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0583, -0.1504,  0.0698,  ...,  0.1807,  0.2637, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2285,  0.3379, -0.1128,  ...,  0.1641,  0.4746, -0.1865]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.1875,  -6.6250,  -3.8125,  ..., -10.6250,   4.3438,   2.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.8750,  1.2500, -3.9062,  ..., -3.2812, -3.2969, -0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([302], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0503, -0.0125,  0.0413,  ..., -0.1738,  0.0317, -0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1924,  0.1670,  0.0142,  ..., -0.0182, -0.1040,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.8281,  8.8750, -6.1562,  ..., -3.9531, -0.5859, -3.5781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7305, -1.0938, -0.0923,  ...,  0.3867, -3.8750, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([303], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767,  0.0488, -0.1123,  ..., -0.0542, -0.1104,  0.0601]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1216, -0.4004,  0.0466,  ..., -0.0398,  0.0669,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.5000,  0.1562, -0.9375,  ..., -1.1250, -3.3438, -4.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6445, -0.6289, -0.6719,  ...,  2.7500, -3.9062, -1.5078]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([304], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0476, -0.0083, -0.0206,  ...,  0.0337,  0.0330, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1113, -0.2695,  0.2520,  ..., -0.1514, -0.1641, -0.2148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.9375, -1.5078, -4.0938,  ..., -4.0625, -0.9766,  1.7812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8984,  1.3359, -0.3555,  ...,  0.5273, -5.8438, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([305], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0439,  0.1162, -0.1611,  ...,  0.1553, -0.0198, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0479, -0.3574, -0.2393,  ..., -0.4551,  0.2305,  0.1709]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.0547,  2.3750, -6.9688,  ..., -0.2451, -1.1641,  4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2070,  0.0146, -1.1016,  ..., -0.5078, -4.4688, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([306], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0096,  0.0928,  0.0532,  ..., -0.0352, -0.0603, -0.1367]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0747,  0.2539,  0.0547,  ..., -0.2246, -0.0118, -0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.2344,  0.9102,  1.1641,  ...,  4.9688, -7.7188,  0.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.7109,  0.4922,  0.6758,  ...,  0.8125, -4.3750, -8.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([307], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0310, -0.1074,  0.0457,  ..., -0.1035, -0.0216, -0.0327]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1094, -0.1147,  0.1221,  ..., -0.0488, -0.0317,  0.0396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4375,  1.6562, -1.2969,  ...,  2.7500,  7.8750,  5.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.8047,  1.9766,  1.8984,  ...,  0.1162, -1.0703, -1.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([308], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0571,  0.0879,  0.0674,  ...,  0.0613,  0.1318, -0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1416, -0.1089, -0.0486,  ..., -0.1436,  0.1602,  0.0242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9688, -1.1641,  1.2031,  ..., -3.5312, -1.1172,  9.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5859,  0.6172,  1.9609,  ...,  0.7109, -1.3047, -1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([309], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0298,  0.0806, -0.0190,  ..., -0.0532, -0.0679, -0.2217]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0923,  0.1465,  0.0035,  ..., -0.0111,  0.0613,  0.0376]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.9375, -0.8984, -6.1875,  ..., -0.8555,  4.3438, -0.5508]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938, -0.1982, -6.1562,  ..., -1.6562,  5.1875, -3.0469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([310], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0317,  0.0090,  0.0820,  ..., -0.0247, -0.0322, -0.0364]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0981,  0.3613, -0.0027,  ..., -0.0017, -0.0884,  0.1611]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -6.6875, -4.5938,  ..., -6.1875,  2.6406, -3.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3125, -1.0156, -2.7812,  ..., -0.8555,  0.5039, -3.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([311], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0219,  0.1196,  0.1914,  ...,  0.0708,  0.0515, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676,  0.2188, -0.1709,  ...,  0.1270, -0.2500,  0.3555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.3750, -6.7812, -4.3750,  ...,  6.4688,  7.1562, -1.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-5.1250,  3.4375, -2.4062,  ...,  3.8906,  2.7344,  1.9141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([312], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0273, -0.0435, -0.0129,  ..., -0.1904, -0.0874,  0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1162, -0.1562, -0.0962,  ..., -0.2451, -0.2393,  0.0747]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.7578,  0.7188, -3.1562,  ..., 14.0000,  0.2988,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.7656,  0.2451, -1.4531,  ...,  3.3438,  1.6406,  1.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([313], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1016,  0.0618,  0.0422,  ..., -0.3457, -0.0297, -0.1973]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0466, -0.1904,  0.0972,  ..., -0.2559,  0.0410, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.7812, -2.6562,  0.5938,  ...,  7.1562, -0.2852,  1.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9023,  1.7812, -4.4375,  ...,  2.0156,  0.8711, -2.6562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([314], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684, -0.1318, -0.0249,  ...,  0.2188,  0.1133, -0.1963]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1147,  0.1069, -0.1426,  ..., -0.0271,  0.1572,  0.1206]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.4453, -10.0000,  -0.7852,  ...,  -2.7031,   2.7500,  -4.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1201, -1.8281, -1.4688,  ..., -0.2656,  1.4062, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([315], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0366, -0.0557,  0.0796,  ..., -0.0884, -0.0156, -0.0352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3418,  0.3984,  0.2227,  ...,  0.0212,  0.0349,  0.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.6875,  -6.5312,   4.3438,  ...,  -3.2969,  -4.3438, -14.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2188, -1.6797, -2.8125,  ...,  0.2754, -1.0312,  0.7148]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([316], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0618, -0.1904,  0.0126,  ..., -0.1924, -0.1787,  0.0762]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1235, -0.2217, -0.2754,  ..., -0.2910, -0.1924,  0.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.2734, -2.5469, -3.1094,  ...,  0.8281,  4.1562, -2.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2812, -1.3125, -3.1406,  ...,  0.6719, -1.9531, -2.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([317], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0737,  0.1338,  0.1182,  ...,  0.0132, -0.1328, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1299,  0.1406, -0.0437,  ...,  0.0251, -0.0630, -0.1416]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5312,  2.5312, -7.5625,  ..., -0.4102,  2.2500, 11.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8633,  0.5078, -2.1875,  ..., -1.9922, -1.9297, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([318], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0151,  0.1245, -0.0167,  ..., -0.1641, -0.0703, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0071, -0.0583,  0.3105,  ..., -0.1885, -0.0145,  0.0164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.6875,  0.7734, -1.6406,  ...,  0.0518, -2.4219,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  1.8906, -2.0312,  ..., -0.7656, -1.4609, -0.8945]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([319], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0112,  0.0879,  0.0106,  ...,  0.0201, -0.0186, -0.0293]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0009, -0.1143, -0.0466,  ..., -0.2598, -0.4375, -0.0032]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2578, -0.5586,  0.5625,  ..., -0.3496,  6.4688,  6.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062,  2.8594, -1.3828,  ...,  0.0820,  2.7500, -2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([320], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1631,  0.1108, -0.0266,  ...,  0.0109,  0.1299, -0.0459]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3555,  0.2988,  0.0099,  ..., -0.0869,  0.2178,  0.0167]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -4.8750,  -2.1719,  ...,  -0.2520,  -7.7188,   3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1670,  3.8438, -1.2500,  ...,  8.3750, -1.1094, -7.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([321], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1348, -0.0510, -0.0762,  ..., -0.1108,  0.0150,  0.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0540,  0.1138, -0.0166,  ...,  0.0659, -0.0018, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.1250,  -6.8125, -10.3125,  ...,   4.0625,  -0.1602,   4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2969,  2.1094, -1.8906,  ..., -3.6250,  1.3828, -3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([322], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2168,  0.0233,  0.0273,  ...,  0.0330,  0.1582, -0.0840]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0154, -0.3125, -0.1270,  ..., -0.3301,  0.0287, -0.1699]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6406, -6.6875, -1.4062,  ...,  4.6250,  1.1406, -3.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4863, -0.5234, -0.2969,  ..., -2.0000,  1.8438,  0.7578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([323], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0198,  0.1406,  0.0649,  ..., -0.0564, -0.0479, -0.1191]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500, -0.1738,  0.0129,  ..., -0.2217, -0.0649, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 6.4688, -5.5938, -2.7500,  ...,  2.8750,  5.8125, -1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9688, -0.1621, -0.5000,  ..., -1.3047, -1.1484,  0.1211]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([324], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0532,  0.0967, -0.0732,  ..., -0.0952,  0.0469, -0.1050]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188, -0.0272, -0.2734,  ..., -0.0684,  0.1162, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.5938, -5.0000, -3.5781,  ...,  1.0469,  1.5859,  4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3984, -1.1328, -1.9375,  ..., -0.4355, -5.7188, -0.5664]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([325], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1006,  0.0160,  ..., -0.1011,  0.0315, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0118,  0.0581,  0.1240,  ..., -0.1387, -0.0684, -0.0913]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4336,  0.5938,  1.0938,  ...,  0.5352, -1.8516,  6.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1182, -1.1250, -2.1875,  ..., -1.5703, -2.4375, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([326], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0195,  0.0835, -0.0437,  ...,  0.0781,  0.0073, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0061, -0.1631,  0.0096,  ..., -0.3008, -0.4219,  0.0188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8438,  0.3516,  5.6875,  ..., -0.7266,  3.2969,  2.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8750,  3.7031, -1.3047,  ..., -4.0938, -3.6094, -1.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([327], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1113,  0.1279,  0.0405,  ..., -0.1992, -0.1016, -0.0928]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2148,  0.3203, -0.0410,  ..., -0.0361, -0.2148,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.5625,  -6.4062,  -1.2969,  ...,   2.0000,   5.1250,   3.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3281,  3.0781, -2.2812,  ..., -1.5000, -2.8125, -2.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([328], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2080,  0.0128, -0.0256,  ...,  0.0654,  0.1270, -0.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0542, -0.2734, -0.0923,  ..., -0.3672,  0.0820, -0.1895]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.9688, -9.0625,  7.6562,  ...,  6.9062, 10.3125, -6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2266,  1.6641, -2.4688,  ..., -1.7656, -4.0938,  1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([329], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0500,  0.0623,  0.0282,  ...,  0.0586, -0.0444, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0552, -0.0479,  0.1582,  ..., -0.1953,  0.1475, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1250,  3.7188,  1.8828,  ...,  1.1016, -2.7031,  1.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.3047, -1.5234, -5.5625,  ..., -1.3906, -2.4219, -0.9805]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([330], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.1118, -0.0072,  ...,  0.1250, -0.0732, -0.0815]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0679, -0.0918,  0.1777,  ..., -0.1797, -0.5391, -0.0105]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.0625,  0.6953,  9.7500,  ..., -2.2656,  1.0312,  1.4766]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9375,  2.5938,  1.8594,  ...,  1.4531,  0.3867,  0.1221]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([331], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0109,  0.1050, -0.0408,  ...,  0.0012, -0.0074, -0.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2471,  0.3691, -0.0383,  ..., -0.0649,  0.0801,  0.1670]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-18.2500,  -9.3125,  -5.0625,  ...,   5.6875,  -6.5000,   7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.5469,  2.3281, -0.9062,  ..., -1.3438, -1.7422, -3.3594]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([332], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2139, -0.0271,  0.0024,  ...,  0.1064,  0.1318, -0.0608]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0115, -0.2559, -0.0386,  ..., -0.3359,  0.1270, -0.2061]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-11.7500,  -5.6562,   7.0312,  ...,   6.2812,  -5.5625,  -0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594,  1.6094,  2.7812,  ...,  0.7305, -3.7500,  0.6680]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([333], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1279,  0.0610,  0.1250,  ...,  0.0605, -0.0815, -0.3320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0305,  0.1807,  0.1807,  ...,  0.0732,  0.0415, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  0.9141,  1.3359,  ..., 11.5625, -3.4219,  1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.9766, -1.3125, 10.6875,  ..., -3.4531, -0.9375,  1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([334], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0347, -0.0566, -0.0342,  ..., -0.0513,  0.0564, -0.0610]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0288, -0.0859,  0.0654,  ...,  0.1221,  0.1973,  0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.1562,  7.3125, -1.4688,  ..., -0.3555, -9.6875,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7266, -4.2500, -2.7344,  ...,  0.1006,  3.1719,  2.8906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([335], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1006, -0.0095, -0.0255,  ..., -0.0576, -0.0486,  0.0120]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1885,  0.0564,  0.0041,  ..., -0.0168, -0.0879, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3125,  0.5469, -4.4688,  ...,  3.5625,  1.9688,  0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2637,  1.4453,  0.1514,  ..., -0.2871, -1.5469, -1.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([336], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0796,  0.0369,  ...,  0.0688,  0.1069, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1001, -0.0991, -0.0293,  ..., -0.1211,  0.1660,  0.0449]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.9375, -1.1562, -1.0312,  ..., -6.0312,  2.4844, 13.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.3633, -0.9688,  2.0469,  ...,  3.5781, -1.2969,  1.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([337], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674,  0.0728,  0.0099,  ...,  0.0098, -0.0146, -0.2793]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1289,  0.0012, -0.0649,  ...,  0.0815,  0.1240,  0.0012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.7812,  -0.7578, -10.8125,  ...,   6.2812,  -1.2266,   2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5312, -0.2139, -5.4062,  ..., -1.8438,  4.5625, -3.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([338], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0645,  0.0752,  0.0420,  ..., -0.0378, -0.0062, -0.0771]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1211,  0.3203,  0.0135,  ..., -0.0082, -0.1045,  0.1475]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1875, -5.5938, -9.1250,  ...,  4.6250, -1.0859,  0.5117]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8203, -1.7656, -2.2031,  ...,  0.6602,  2.3750, -2.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([339], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0226,  0.1387,  0.1787,  ...,  0.0791,  0.0752, -0.1914]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2500,  0.1973, -0.1475,  ...,  0.1367, -0.2158,  0.3516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.6562, -6.0625, -9.2500,  ..., 15.1875, 10.2500,  0.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.9688,  1.4062, -3.9062,  ...,  3.5938,  2.3750,  4.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([340], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0012,  0.1348,  0.0447,  ...,  0.1445, -0.0183, -0.0005]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2002, -0.1030,  0.1514,  ...,  0.1582,  0.0026, -0.2451]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.3750,  -7.3438,  -8.0625,  ...,  12.4375,  -3.7969,  -4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5547,  5.2188,  2.7969,  ...,  0.6797, -0.0674, -8.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([341], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0947, -0.0052,  0.0195,  ...,  0.0913, -0.3398, -0.0388]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0432, -0.0513,  0.0962,  ..., -0.0189,  0.0396,  0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.4688, -3.6250, -0.8984,  ...,  6.1250, -3.2656, -3.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9141,  0.8945, -1.3125,  ...,  3.4219, -3.4219, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([342], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0762, -0.1689, -0.0317,  ...,  0.2656,  0.0908, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0703,  0.0942, -0.1436,  ...,  0.0193,  0.1523,  0.0952]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7031, -7.8125, -5.8438,  ...,  4.5938,  4.0625,  1.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5781, -1.3906, -0.6914,  ...,  0.4375,  0.4785, -0.3457]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([343], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0288, -0.0356,  0.0762,  ..., -0.0459, -0.0674, -0.0193]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398,  0.3789,  0.1895,  ..., -0.0210,  0.0732,  0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.5391, -7.7500, -4.0000,  ..., 10.8125, -2.0000, -0.6953]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -2.4375, -3.0625,  ...,  0.6211, -1.2578,  1.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([344], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0767, -0.0359, -0.0537,  ...,  0.0771, -0.1289, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1797, -0.1865,  0.0121,  ...,  0.0698,  0.0118, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.6719, -0.8047, -4.9062,  ...,  6.8125,  2.7812,  2.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.2500, -0.4570, -1.2969,  ..., -2.6875, -3.4531,  0.6133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([345], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0200,  0.1289,  0.0327,  ..., -0.0608, -0.0337, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0332, -0.0344,  0.1934,  ..., -0.1465, -0.0430, -0.0967]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[10.6875, -3.6719, -3.6875,  ...,  8.3750,  1.2188,  6.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.7188, -0.7031,  0.1465,  ..., -2.9688, -0.9023,  2.7500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([346], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0054, -0.0664, -0.1309,  ...,  0.0214, -0.1543, -0.1230]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0559,  0.1904, -0.0004,  ...,  0.2275,  0.0544,  0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3594, -5.6875,  3.9844,  ...,  6.1562, -1.3828,  7.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.1406, -0.9258, -1.3125,  ..., -1.9062, -3.0938, -0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([347], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1162,  0.1377,  0.0588,  ...,  0.0713, -0.0361, -0.0391]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0342, -0.0493,  0.0762,  ..., -0.1855, -0.5352, -0.0038]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.0625, -2.2188,  5.5938,  ..., -0.8398,  1.5469,  2.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  4.0312, -0.9180,  ..., -2.0312, -2.7500, -2.1719]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([348], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0933,  0.1128,  0.0693,  ..., -0.1865, -0.1045, -0.0718]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2334,  0.3105, -0.0630,  ..., -0.0250, -0.1924,  0.3633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.5625,  -9.6250,  -0.8203,  ...,   3.4844,  -2.6562,  10.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1992,  1.3672, -3.0156,  ..., -0.1895, -0.2227, -1.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([349], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2354, -0.0171, -0.0503,  ...,  0.0532,  0.1201, -0.0752]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0444, -0.2363, -0.0928,  ..., -0.3438,  0.0776, -0.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125, -12.1875,   7.2500,  ...,   2.2656,   2.1406,   3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4180,  0.4590, -0.6484,  ..., -0.5703, -0.8203,  0.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([350], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1387,  0.0425,  0.1504,  ...,  0.0625, -0.0781, -0.2637]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0381,  0.1719,  0.1729,  ...,  0.0771,  0.0410, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.7031, -2.5938,  1.8906,  ...,  7.6250,  2.5938,  2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4473,  1.0078,  4.7500,  ..., -1.0312, -2.2500,  1.5000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([351], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0010, -0.1572, -0.0649,  ...,  0.0625,  0.2139,  0.0232]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0625,  0.0036, -0.0859,  ...,  0.2480,  0.5195, -0.0337]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0781, -1.7422, -1.0234,  ...,  4.4062, -0.0391,  2.7969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0554,  0.7695, -0.7578,  ..., -0.6133, -1.3906, -0.8984]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([352], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0444,  0.0332,  0.0046,  ..., -0.0212,  0.0623, -0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0640, -0.0693, -0.0415,  ..., -0.1504,  0.0903, -0.0571]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.9219, -3.2031,  0.5391,  ...,  4.2500,  0.0820, 10.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844, -0.6797, -1.4531,  ..., -1.8125, -2.2812,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([353], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0186,  0.0253,  0.0117,  ..., -0.0874,  0.0732, -0.1426]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0615,  0.0513, -0.0618,  ...,  0.0188,  0.0708,  0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5547, -1.0469,  6.8125,  ...,  2.9531,  2.4062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0459, -1.0234, -3.2188,  ..., -1.6328, -2.2500, -0.0081]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([354], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0527, -0.0386,  ...,  0.0664,  0.0022, -0.0742]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0240, -0.1709, -0.0282,  ..., -0.3086, -0.3984,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5000, -0.7656, 12.1875,  ...,  6.1875,  4.1875, -0.4570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-4.6250,  0.8750,  1.3438,  ..., -0.9258,  0.9219, -1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([355], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1030, -0.0023,  0.0203,  ...,  0.0850,  0.0026, -0.1064]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4336,  0.2637,  0.1865,  ...,  0.1060,  0.1064,  0.2090]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.4688, -6.6250, -3.4531,  ...,  0.6602, -1.6172,  6.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0854,  0.9961, -1.7812,  ..., -0.4199, -1.5156, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([356], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2471, -0.0618, -0.0034,  ...,  0.1357,  0.1436, -0.0820]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0233, -0.3008, -0.1611,  ..., -0.2832,  0.0168, -0.1748]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4062, -6.6562,  7.9375,  ...,  2.7500,  5.3750,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0417, -0.4922,  0.5352,  ..., -0.2617, -2.3281,  0.5430]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([357], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0752,  0.0269,  0.1523,  ...,  0.0583, -0.1494, -0.3008]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0168,  0.1836,  0.0923,  ...,  0.0825,  0.0583, -0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.9297, -0.1719, -0.7578,  ...,  6.3125,  1.7500,  4.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8789, -1.1250,  3.6719,  ...,  1.7734, -0.9141,  1.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([358], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0182, -0.1689, -0.0547,  ...,  0.0217,  0.1631, -0.0033]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0286,  0.0023, -0.0654,  ...,  0.2734,  0.5156, -0.0344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[5.6875, 0.1289, 2.8594,  ..., 1.2500, 1.4062, 0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0659,  0.7109,  0.1562,  ..., -1.1172, -0.9180, -0.6484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([359], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0549,  0.0332,  0.0099,  ..., -0.0184,  0.0518, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0376, -0.0659, -0.0549,  ..., -0.1289,  0.0723, -0.0737]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.1875, -3.2812, -0.4141,  ...,  1.1328,  1.9219,  0.7773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.4336, -2.9062,  ..., -0.8516, -2.3594, -0.9336]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([360], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0201,  0.0184,  0.0352,  ...,  0.0082,  0.0265, -0.1133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0918, -0.0588,  0.1465,  ..., -0.0466,  0.0124, -0.0879]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.3125, -3.1250, -1.3125,  ...,  5.4062,  0.4961,  5.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.1484, -0.9688, -1.1094,  ..., -1.9688, -5.0312, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([361], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0193,  0.0452, -0.0125,  ..., -0.0120,  0.0055, -0.1445]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0393,  0.1719, -0.0400,  ..., -0.0732, -0.0047, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -10.0625,   0.3867,  ...,   5.6250,  -7.6875,   4.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6406, -1.0234,  2.0312,  ...,  0.5117, -3.4062,  4.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([362], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0359, -0.0718, -0.1514,  ...,  0.0386, -0.0801, -0.1494]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0664,  0.2441,  0.0903,  ...,  0.2598,  0.0879,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7969,  4.0625,  3.8594,  ..., -1.9688, -4.1562,  7.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2031, -0.1260, -4.3125,  ..., -1.0078, -1.7500, -1.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([363], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1094,  0.0815, -0.0178,  ...,  0.0918,  0.0176, -0.0698]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0586, -0.0369,  0.1084,  ..., -0.1875, -0.5000, -0.0019]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.1875,  0.7656, 11.2500,  ..., -5.6250,  1.1875,  3.7031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7070,  4.5938,  2.2344,  ...,  0.4590, -0.0068, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([364], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0076,  0.0562,  0.0022,  ..., -0.0474,  0.0284, -0.1689]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324,  0.3555, -0.0986,  ..., -0.0830,  0.1240,  0.1592]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.3750,  -9.6250,  -3.3594,  ...,   2.3438,  -7.2812,  10.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3984,  2.0156, -3.7969,  ...,  0.6758, -2.5000, -2.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([365], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.2393, -0.0815, -0.0216,  ...,  0.0889,  0.1406, -0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0190, -0.2344, -0.0752,  ..., -0.2988,  0.1523, -0.2363]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.5625, -13.8125,   4.3438,  ...,  -0.2676,  -1.4844,   4.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.1562,  1.7891,  ...,  2.5000, -2.3906,  3.1562]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([366], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1221,  0.0261,  0.1299,  ...,  0.0630, -0.0918, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0513,  0.1865,  0.1562,  ...,  0.0654,  0.0383, -0.0669]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.2969,  0.1484, -3.4219,  ...,  8.2500,  4.0312,  7.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.9805, -2.7188,  3.7188,  ...,  0.7969, -0.0273,  3.0312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([367], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0099, -0.1631, -0.0752,  ...,  0.0723,  0.1934, -0.0046]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0009,  0.0422, -0.0898,  ...,  0.2598,  0.4883,  0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 2.0156, -1.1172, -6.3438,  ...,  5.8750,  0.0371,  7.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3008,  0.2812,  0.8047,  ..., -0.1650, -1.1797, -0.8633]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([368], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1099,  0.0027,  0.0383,  ..., -0.0232,  0.0923, -0.0679]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0320, -0.0339, -0.0654,  ..., -0.0601,  0.1875, -0.2344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  1.2969, -12.3125, -12.0000,  ...,   7.2188,   3.1406,  -0.1094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.0938,  0.3789, -2.9531,  ...,  1.6797, -0.6289,  0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([369], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.1074,  0.0518,  ...,  0.1270, -0.0227, -0.2051]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1553, -0.3750,  0.0454,  ..., -0.0811,  0.1416, -0.1006]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 4.9375, -7.3750, -6.9688,  ...,  9.1250,  7.3750,  4.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.9688, -2.0781, -2.2656,  ..., -4.2500, -4.5625, -1.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([370], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0579,  0.0874, -0.0493,  ..., -0.1338,  0.0413, -0.1113]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1865, -0.0718,  0.2422,  ..., -0.1631, -0.0781, -0.1138]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.3750, -9.4375, -3.2188,  ...,  9.7500,  9.4375,  0.7070]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.9531,  0.2734, -1.8750,  ..., -1.8984,  0.0215,  0.4941]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([371], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0508, -0.0854, -0.0040,  ..., -0.0007,  0.0693, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2598, -0.2168,  0.0530,  ..., -0.1465, -0.1455,  0.0074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9062, -9.4375, -2.0938,  ..., 18.6250,  5.7188,  1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8008, -0.0542,  2.8750,  ..., -1.8750,  0.3125,  3.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([372], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0830,  0.1348, -0.0884,  ...,  0.0559, -0.0918, -0.1152]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1270,  0.2422,  0.1235,  ...,  0.3594,  0.1133,  0.0874]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.3125, -5.4375,  9.1875,  ...,  7.7812,  2.5781,  1.7344]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.7344, -1.5000, -1.7656,  ..., -0.1504,  1.2734, -0.3730]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([373], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0155,  0.0210,  0.0356,  ..., -0.0613,  0.1416, -0.1299]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0437,  0.0105, -0.0072,  ...,  0.1157,  0.1147,  0.0055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.0938, -1.9453, -2.7031,  ...,  4.6250,  2.7031,  5.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.8125,  0.5273,  0.2119,  ...,  0.7578, -0.1709, -0.9102]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([374], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0732,  0.0284,  0.1709,  ...,  0.1689,  0.0952, -0.0237]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0986, -0.1484, -0.0060,  ..., -0.0986,  0.1914, -0.0522]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-10.9375,   1.6172,  -0.0391,  ...,  -5.9688,  -2.2500,  -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.2500, -0.4863,  0.0781,  ...,  1.3203,  3.2188, -0.7188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([375], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0212, -0.0703,  0.1025,  ...,  0.1021, -0.0850, -0.1396]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0171, -0.0498, -0.2207,  ...,  0.0391, -0.0527, -0.0179]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6250, -5.1250,  7.6875,  ...,  3.2656,  4.0938, -1.4219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.5391, -0.7344, -1.0625,  ..., -2.1875,  1.5078, -1.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([376], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2559,  0.1875, -0.0498,  ..., -0.0312,  0.0388, -0.0098]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3027, -0.0640,  0.4062,  ..., -0.5078,  0.1904,  0.1836]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.1250, -8.5625,  7.8125,  ...,  0.5000,  3.3906, -1.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7578, -0.7656,  2.5625,  ..., -1.5703,  0.0635, -0.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([377], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1035,  0.1895, -0.1348,  ..., -0.0796, -0.0898, -0.1055]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1050, -0.2217, -0.1094,  ..., -0.2578,  0.0703, -0.1226]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.6562, -7.5625, 21.6250,  ...,  5.4062,  1.1719,  0.1074]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7500, -3.2500,  1.2031,  ..., -2.8594, -0.7188, -1.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([378], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0723,  0.1206, -0.1206,  ..., -0.1953, -0.0688, -0.0806]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1494, -0.2441, -0.2275,  ..., -0.1738, -0.0938, -0.0996]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.1719, -9.0000,  2.7188,  ...,  0.7305,  3.1875, -3.2031]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2031,  0.0698, -0.8516,  ..., -0.8828,  0.1074,  0.4902]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([379], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0012, -0.0439,  ..., -0.0369, -0.0140, -0.0579]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1030, -0.0217, -0.1523,  ..., -0.0077,  0.1562, -0.0947]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[  2.0312, -16.2500,  27.8750,  ...,   1.1719,  11.5000,  -2.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.4062, -1.9688,  2.3281,  ..., -0.5781, -0.9961, -0.9609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([380], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0413,  0.0129, -0.0437,  ..., -0.0786, -0.1162, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2852,  0.1797, -0.3887,  ..., -0.2637, -0.2344,  0.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 5.0000, -8.7500, -2.9844,  ...,  4.1562,  1.4688, -0.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4766,  1.6172, -0.0854,  ..., -1.3359, -1.1250,  1.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([381], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0303, -0.0435, -0.1475,  ..., -0.0703, -0.0211, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6094, -0.1226, -0.0938,  ..., -0.1807, -0.1206,  0.6289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 7.5312, -5.8438,  5.9688,  ..., 12.3125, -4.9375,  3.9219]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0469,  0.7812,  1.1641,  ...,  1.0781, -2.1406, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([382], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0586, -0.1641,  0.1133,  ...,  0.0767, -0.0427,  0.0317]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0630,  0.0786,  0.1553,  ...,  0.1128, -0.2041, -0.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.6250, -2.7812,  1.8047,  ..., -1.8281, -6.3125,  1.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9844,  0.7773, -1.2500,  ...,  0.1641,  0.1748,  0.3535]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([383], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0608, -0.0129,  0.0122,  ...,  0.0076,  0.1226,  0.0276]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0708, -0.1338, -0.0889,  ..., -0.0206,  0.0352,  0.0289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6562, -7.1875,  2.5156,  ..., -8.6875, -3.8906, -1.2578]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.8594, -0.1201, -2.0000,  ..., -0.4492,  1.2578,  1.7422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([384], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0674, -0.0439, -0.0591,  ..., -0.0391,  0.0884, -0.1035]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4590, -0.4512,  0.0554,  ...,  0.0747, -0.1299,  0.1455]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.9062, -6.6250, 10.1250,  ..., -2.1719,  0.3555,  0.1309]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5430, -1.3672, -0.8438,  ..., -0.4688,  0.6094, -0.3242]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([385], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0540,  0.0596,  0.0623,  ..., -0.0381,  0.0376,  0.0908]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.0786,  0.2207,  ..., -0.2012,  0.0067, -0.0085]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.8125, -15.8125,  12.0000,  ...,  -5.9375,  -1.5000,   2.2656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7188, -0.5820,  0.6289,  ..., -1.2969,  0.2344, -2.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([386], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2773,  0.2227,  0.0238,  ...,  0.0247,  0.0349, -0.0703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2490,  0.3574,  0.0471,  ..., -0.1709, -0.4297, -0.1108]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-16.5000, -12.6250,   1.4297,  ...,  -7.5000,   4.1562,   4.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4062,  0.6641, -1.0547,  ..., -1.3125, -1.4297, -3.3438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([387], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2451,  0.1758, -0.0195,  ..., -0.0205,  0.0457,  0.0684]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1787, -0.1328, -0.2578,  ...,  0.5273, -0.3828, -0.1826]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -6.0938, -12.7500,  -6.4375,  ...,   2.8906,   4.5000,   1.9922]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3398, -1.0625, -1.6719,  ...,  1.4688, -0.9492, -3.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([388], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0879,  0.1221,  0.0918,  ..., -0.1729, -0.0498, -0.0645]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0728,  0.0177, -0.1318,  ...,  0.1807,  0.2461, -0.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -3.9062, -13.1250,  -0.8086,  ...,   1.7656,   7.6875,  -6.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2773, -0.8750, -0.4375,  ..., -3.1406, -0.1709, -2.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([389], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0962,  0.0115,  0.0175,  ..., -0.0393,  0.0106, -0.2012]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0674,  0.2178,  0.0227,  ..., -0.1045, -0.1963, -0.0464]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -0.2734, -17.8750,  -0.9297,  ...,  -3.5938,  -7.9062, -11.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7695,  0.1035, -1.4766,  ..., -3.2031,  0.6719, -1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([390], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1562, -0.0378,  0.0182,  ...,  0.1494,  0.0625, -0.0918]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3359,  0.2305, -0.3789,  ...,  0.4258,  0.2188, -0.1924]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.3125,  -6.0312,   6.8750,  ...,   1.9375,   2.1250, -12.6875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.9062, -1.8594, -1.3125,  ..., -1.2969,  2.6406, -3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([391], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0598,  0.0107, -0.0742,  ..., -0.2295,  0.1069,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.5078, -0.2363, -0.0669,  ..., -0.2314, -0.0986, -0.0238]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-8.5000, -0.0898,  4.7188,  ..., -2.6562,  0.9609,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2676, -2.4531, -2.4844,  ..., -2.2031, -1.2578,  0.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([392], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0349,  0.0054, -0.1611,  ..., -0.0718,  0.0250,  0.0086]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0013,  0.0413, -0.1226,  ..., -0.3438, -0.0850, -0.0205]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-13.3750,  -1.7188,   5.6875,  ...,  -5.1875,   9.8125,   3.5156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5469, -1.9766,  0.1289,  ..., -1.4531, -0.2061, -2.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([393], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.1807, -0.1709,  0.0364,  ...,  0.0598,  0.0195,  0.0640]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2520,  0.2080, -0.1641,  ...,  0.1455,  0.1533, -0.2275]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.0000,  2.5938,  1.1719,  ..., -6.3750,  6.4375,  4.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.5938,  0.0427, -1.8594,  ..., -3.8594, -1.5469, -1.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([394], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.3223,  0.0064, -0.0708,  ...,  0.0276, -0.0275, -0.0544]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0064, -0.1230, -0.5664,  ..., -0.6328, -0.3828, -0.1816]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-7.8438, -1.8672,  7.5000,  ..., -0.9336,  4.5000,  3.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.0781, -2.8281, -1.2969,  ..., -2.0781, -1.7109, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([395], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957, -0.0430,  0.0432,  ..., -0.0498,  0.0767, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1074, -0.0771, -0.1147,  ..., -0.0253,  0.2275,  0.0713]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-14.0625,   6.5625,   2.3750,  ..., -13.1250,   2.8438,   4.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.7656, -2.5156,  1.3281,  ..., -1.0078, -0.3672, -1.1328]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([396], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1445, -0.1128, -0.1245,  ...,  0.1221,  0.0303,  0.0027]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4629, -0.0864,  0.0703,  ...,  0.5273, -0.0967,  0.1182]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-12.7500,  -0.3594,   6.1562,  ...,   0.1953,   1.3594,  -1.3125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.4766, -1.0859, -1.1172,  ..., -2.2188,  0.0085, -1.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([397], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.1123,  0.0186,  ..., -0.1992, -0.0320, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1514,  0.1572, -0.1187,  ...,  0.1924,  0.1816,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -5.3750,   3.2812,  -1.8750,  ..., -12.3750,   8.5000,   7.9688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.5000,  1.2422, -0.9453,  ..., -2.9844,  0.1021, -0.8047]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([398], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0630,  0.1514,  0.1553,  ..., -0.1582,  0.0019, -0.1660]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2471, -0.1099,  0.0723,  ...,  0.3711, -0.4961,  0.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-17.7500,   1.0312,   0.1992,  ...,   4.0938,   4.3750,   9.8125]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5625, -0.1094, -5.4062,  ..., -1.8984, -0.5820,  1.3906]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([399], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0574,  0.0723, -0.0420,  ..., -0.0859,  0.0359, -0.1504]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0352,  0.1021,  0.1250,  ..., -0.0732, -0.1011, -0.1162]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-9.1250,  8.1875, -0.6719,  ...,  2.4219,  5.7500, 12.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.0078,  1.5781, -1.8438,  ...,  0.5859, -0.0566,  0.5547]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([400], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0386,  0.0879, -0.0522,  ...,  0.0427, -0.0110, -0.1523]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1133, -0.0112,  0.0364,  ...,  0.1602, -0.3848,  0.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -8.2500,   0.9219, -12.6250,  ...,   4.2188,   7.0000,   3.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.2891,  2.0156, -2.8281,  ..., -3.8281, -0.8047, -2.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([401], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0260, -0.1514, -0.1475,  ..., -0.0159, -0.0226, -0.1021]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0510, -0.3652, -0.0342,  ...,  0.0187, -0.2676, -0.0977]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.5469,  1.3438,  5.7188,  ...,  5.8125,  2.0469,  8.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.6523,  2.4375, -3.6094,  ..., -1.0938,  1.4531,  3.0781]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([402], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1738,  0.0767, -0.0840,  ..., -0.2275, -0.0659, -0.0513]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0212, -0.0106,  0.4824,  ...,  0.2852, -0.0461, -0.2383]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.2188,  2.3750,  3.4844,  ...,  9.9375, -0.4727,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.1250,  0.5898, -1.1719,  ..., -0.6016, -0.0420,  0.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([403], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1582, -0.1445,  0.0620,  ..., -0.0869, -0.0208, -0.0674]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2832,  0.0023,  0.0089,  ..., -0.0242,  0.0898, -0.0095]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-4.1250,  3.2500, -0.5547,  ..., 11.5000,  3.2188, -0.5352]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2275,  0.6250, -1.0469,  ..., -0.0859, -1.0625, -0.9570]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([404], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0918,  0.0801,  0.0544,  ..., -0.0211,  0.0549, -0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0952, -0.1040,  0.0491,  ...,  0.0072,  0.0238,  0.0171]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.9375, -0.7656,  0.8594,  ..., -0.7305, -9.1250, -6.5938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.5977, -0.3730, -0.0225,  ...,  1.2656,  0.9297, -2.6094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([405], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0281,  0.0610,  ..., -0.0327, -0.0043, -0.1030]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1436, -0.1426, -0.0371,  ..., -0.0386, -0.0344,  0.2197]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 3.3750, -1.5547, 11.2500,  ..., -3.2656,  2.8906, -4.9062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8477, -0.2539,  1.5938,  ..., -3.1250, -0.1426, -3.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([406], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1060,  0.0415,  0.0581,  ...,  0.0417,  0.0078, -0.0286]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1309,  0.0332, -0.1396,  ..., -0.4316, -0.1396,  0.0139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.8828, -4.5312,  4.1250,  ..., -1.6562,  4.2188, -7.0000]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.3125,  0.7148, -1.3828,  ..., -7.6250,  4.3750, -6.4062]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([407], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0415, -0.0096,  0.1021,  ...,  0.0776,  0.0815, -0.1279]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1279, -0.0050, -0.1221,  ..., -0.3262, -0.1348,  0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.4688, -4.8750,  7.4688,  ...,  1.4062,  5.8438, -8.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0703, -2.7031, -1.0391,  ..., -2.7812,  4.6562, -1.0938]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([408], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762, -0.1172, -0.0063,  ..., -0.0023, -0.1035,  0.0486]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.4141, -0.4551,  0.1147,  ...,  0.1235,  0.0574, -0.3574]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.5000,  4.0312,  6.4375,  ..., -1.4062, -0.3789, -0.7266]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.1406,  1.1094,  1.7188,  ..., -0.5039,  0.7148, -1.9531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([409], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0337,  0.1206,  0.1475,  ..., -0.2578,  0.0342, -0.3164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0251,  0.0282,  0.0811,  ..., -0.0454,  0.0123, -0.0094]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.2734,  5.0625, -2.7344,  ...,  0.8086, -3.0312,  7.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1328,  0.7188,  0.2021,  ..., -0.3730, -1.0000, -1.3750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([410], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0684,  0.0291, -0.0141,  ..., -0.2676,  0.2520, -0.3145]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1631, -0.1387, -0.2373,  ..., -0.2490, -0.1162, -0.0156]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[2.7656, 0.9336, 2.6562,  ..., 0.2188, 5.0000, 0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2148,  0.8984, -1.0781,  ...,  0.7930, -0.0137, -1.2188]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([411], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0090,  0.1108, -0.0554,  ..., -0.0361,  0.1943, -0.1235]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2441,  0.6289,  0.2275,  ...,  0.2041,  0.2197,  0.2432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -7.1250,  -0.7500,   0.2363,  ...,   3.2969, -11.5625,   0.7734]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.3047,  0.3848,  0.3164,  ...,  5.1562, -5.5312,  0.8555]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([412], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2461, -0.0544,  0.0674,  ..., -0.0610, -0.0144,  0.0054]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0557, -0.0081,  0.0859,  ...,  0.1299, -0.2852, -0.1338]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.9375,  4.5000, -0.5391,  ...,  1.3750, -4.6875,  4.9375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9297,  0.2812,  0.2314,  ..., -0.7969, -1.5156, -0.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([413], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0178,  0.0728,  ..., -0.0322,  0.0532, -0.0099]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0322, -0.1416, -0.1738,  ..., -0.0430,  0.0239,  0.0415]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.5234,  4.8750,  1.5469,  ..., -0.4570, -6.0938,  8.2500]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-2.6719,  0.2988,  0.0669,  ..., -0.1436, -0.8555,  0.0708]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([414], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0996, -0.0209,  0.1465,  ..., -0.0757,  0.0540,  0.0403]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.2324, -0.0859,  0.1348,  ..., -0.3613, -0.0996, -0.0398]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-5.8125,  7.4062,  5.3125,  ...,  6.2188, -3.4375, -0.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.7344, -1.3672, -1.2422,  ...,  0.4141, -0.6641, -1.8828]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([415], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0215,  0.1338,  0.0410,  ..., -0.0957, -0.1006, -0.0200]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0295,  0.0009, -0.3359,  ..., -0.1670, -0.4277,  0.4121]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.7891,  2.6875,  6.7188,  ...,  7.1250, -9.3750,  2.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0066,  0.7031, -2.0156,  ...,  0.9688, -0.4707, -1.8516]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([416], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0177, -0.0170,  0.2275,  ..., -0.1553,  0.0057, -0.0432]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1631, -0.0938, -0.1016,  ..., -0.1602, -0.0435, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6875, -0.5234, -1.7656,  ...,  8.5000, -1.2422,  8.1875]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.8906, -0.5039, -0.8945,  ..., -1.9609, -1.4844, -0.2207]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([417], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0002,  0.0420, -0.0060,  ..., -0.1206,  0.0767, -0.0864]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0201,  0.0253,  0.2930,  ..., -0.0767, -0.0199,  0.0149]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.6250,  2.5625,  1.8672,  ...,  6.5000, -5.3750,  6.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2656, -1.2109, -1.2422,  ..., -2.2969, -0.1973,  0.2354]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([418], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0957,  0.0454,  0.0359,  ..., -0.3926,  0.1367, -0.0366]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0613, -0.0630, -0.0469,  ..., -0.3848, -0.1592,  0.2773]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -2.8281,   3.9688,  -2.0000,  ...,   2.5312, -14.2500,   7.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.3320,  0.0850, -0.5547,  ..., -0.4473, -0.9648,  0.9297]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([419], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1123, -0.0038,  0.0229,  ..., -0.2793,  0.0962, -0.0080]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1221, -0.0410, -0.0894,  ..., -0.0298,  0.1982, -0.2393]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.8438, -5.9375, -3.8125,  ..., -0.3125, -4.8438,  2.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.8750, -0.6250, -1.7891,  ...,  1.2578, -1.4453, -1.0234]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([420], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.2617,  0.0400,  0.0618,  ..., -0.1680, -0.0003, -0.1602]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1104, -0.2949,  0.1084,  ...,  0.1895, -0.1719, -0.2539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-1.4375, -0.2031,  3.8750,  ...,  2.3750, -1.0312,  3.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0493, -1.1484,  0.4688,  ..., -1.4219, -1.3672,  1.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([421], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0227, -0.0476,  0.0127,  ..., -0.1367,  0.0796, -0.1289]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1670, -0.0444,  0.2988,  ...,  0.0427, -0.1104,  0.0116]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.7188, -1.5312,  9.4375,  ..., -4.6562, -5.9062,  6.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1172,  0.1016, -1.0859,  ..., -1.5156,  0.0703, -0.1025]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([422], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0327, -0.0640, -0.0123,  ..., -0.1001,  0.0176, -0.1045]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0008,  0.0757,  0.1025,  ...,  0.0762, -0.0491,  0.1084]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.4375,  6.1562,  6.3750,  ..., -1.3750, -3.0312,  1.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.4355,  0.0134, -0.7930,  ..., -1.3906,  1.1406,  1.7656]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([423], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0942, -0.0447, -0.0603,  ..., -0.0703, -0.0245, -0.1104]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2188,  0.0522, -0.0640,  ..., -0.2793, -0.0306,  0.0786]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.2500,  5.0625,  9.1250,  ..., -5.1250,  1.0234,  1.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4062, -2.8906, -0.6445,  ...,  1.0234,  1.0547, -1.3672]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([424], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1787, -0.1191,  0.2100,  ...,  0.1465, -0.0291, -0.0830]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1270, -0.2246,  0.1992,  ...,  0.1045, -0.0183, -0.3184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531,  3.1562, -0.0391,  ...,  1.2969, -3.6250,  6.6250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-1.2500, -0.2168, -0.1426,  ..., -0.3027, -0.8477, -0.3203]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([425], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0114,  0.0356,  0.0056,  ..., -0.1289,  0.0879, -0.1621]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0173,  0.1099,  0.3516,  ..., -0.0435, -0.3496,  0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-6.7500,  1.6953, -7.7812,  ...,  4.0938, -1.1094,  3.6406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0718,  0.2598, -1.6484,  ..., -0.8633, -2.0312,  2.0625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([426], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0762,  0.0154,  0.1089,  ..., -0.1455, -0.1245, -0.1846]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1572, -0.0182,  0.3906,  ..., -0.0058, -0.1689,  0.3867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[1.6641, 3.2812, 0.8984,  ..., 5.5312, 3.2188, 4.5625]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.1895,  2.2188, -3.3281,  ..., -1.4766,  1.6953,  1.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([427], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1167, -0.0854,  0.0197,  ..., -0.1748, -0.0942, -0.1553]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.0698, -0.1543,  0.5625,  ...,  0.2148,  0.0034, -0.2988]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-2.3438e-02,  2.9844e+00, -6.4453e-01,  ...,  1.2812e+01,\n",
      "         -1.1719e-02,  1.6953e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 1.4609,  1.2969, -1.0781,  ...,  0.7852, -2.5781,  1.4141]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([428], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1206,  0.0203,  0.1504,  ..., -0.0659, -0.0781, -0.2139]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1953, -0.3574, -0.0820,  ...,  0.1738,  0.3066, -0.1855]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.8555,  9.0000, -4.0625,  ...,  7.0625,  2.2344,  3.4531]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7812,  0.2383,  0.2852,  ...,  0.9141, -1.1172, -0.1484]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([429], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0771,  0.0625,  0.0144,  ..., -0.1943,  0.0601, -0.1387]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.2363, -0.1445, -0.0403,  ..., -0.3516, -0.0908,  0.0850]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-0.6641,  8.7500,  2.0312,  ...,  7.0625, -4.2500, -0.2520]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.6953,  0.3438, -0.9766,  ..., -1.0938, -2.1094,  0.5859]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([430], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.1128,  0.0117,  0.1963,  ..., -0.0376, -0.0874, -0.2559]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[0.0013, 0.2061, 0.1387,  ..., 0.1162, 0.0574, 0.0244]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 0.9375, -2.9375,  0.3203,  ..., 17.1250, -4.9062, -1.5312]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.9492, -0.6992,  7.5312,  ..., -6.7188, -2.8906,  0.5586]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([431], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[ 0.0374, -0.0938,  0.0074,  ..., -0.0928,  0.0437, -0.0014]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 0.0215, -0.0178,  0.0752,  ...,  0.1631,  0.1758, -0.0107]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ 1.9531e-03,  1.3359e+00, -1.2578e+00,  ...,  4.9375e+00,\n",
      "         -2.6406e+00, -3.5938e+00]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-3.6875, -3.6719, -1.4141,  ..., -4.2500,  3.4531, -1.4844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([432], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0664, -0.0327,  0.0162,  ..., -0.0835, -0.0378,  0.0028]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1514,  0.0977,  0.0483,  ...,  0.0200, -0.0908, -0.0991]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[-3.4375,  1.5312, -1.5625,  ...,  6.8438, -0.9727, -0.5469]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.7656,  0.5703, -0.8086,  ..., -0.2061, -1.4453, -1.1797]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n",
      "Positions: tensor([433], device='cuda:0')\n",
      "In send_intermediate_states\n",
      "Residual sample data: tensor([[-0.0234,  0.0674,  0.0364,  ..., -0.0530,  0.0537, -0.0184]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[-0.1465, -0.0742,  0.0479,  ..., -0.0052,  0.0254,  0.0199]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Saved hidden_states: torch.Size([1, 3584]) and residual: torch.Size([1, 3584]) to file\n",
      "Layer: DummyDecoderLayer()\n",
      "In recv_intermediate_states\n",
      "Waiting for cloud hidden states and residual files to be created...\n",
      "Loading hidden states and residual from cloud files...\n",
      "Residual sample data: tensor([[ -4.7500,   1.5156,   2.7812,  ...,   2.5156, -13.9375,  -9.8750]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Hidden states sample data: tensor([[ 2.7188,  0.4277, -0.1523,  ...,  1.1328, -0.5234, -0.8867]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "Removed files: cloud_hidden_states_tensor.pt and cloud_residual_tensor.pt\n"
     ]
    }
   ],
   "source": [
    "# enc_dec_engine.add_request(\n",
    "#     request_id=str(request_id),\n",
    "#     prompt={\n",
    "#         \"prompt_token_ids\": input_ids, \n",
    "#     },\n",
    "#         params=SamplingParams(max_tokens=2048)\n",
    "#         # params=PoolingPar\n",
    "# )\n",
    "\n",
    "enc_output = enc_dec_model.generate(\n",
    "    {\n",
    "        \"prompt_token_ids\": input_ids, \n",
    "    },\n",
    "    SamplingParams(max_tokens=2048, temperature=0)\n",
    ")\n",
    "\n",
    "# middle_output = middle_model.generate(\n",
    "#     {\n",
    "#         \"prompt_embeds\": torch.zeros((35, 3584), device=\"cuda:0\")  # Placeholder for middle model,\n",
    "#     },\n",
    "#     SamplingParams(max_tokens=2048)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdcc924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=123, prompt=None, prompt_token_ids=[151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 4934, 264, 3974, 3378, 12111, 13, 151645, 198, 151644, 77091, 198], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text=\"Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\\n\\n```python\\ndef quick_sort(arr):\\n    if len(arr) <= 1:\\n        return arr\\n    else:\\n        pivot = arr[len(arr) // 2]\\n        left = [x for x in arr if x < pivot]\\n        middle = [x for x in arr if x == pivot]\\n        right = [x for x in arr if x > pivot]\\n        return quick_sort(left) + middle + quick_sort(right)\\n\\n# Example usage:\\narr = [3, 6, 8, 10, 1, 2, 1]\\nsorted_arr = quick_sort(arr)\\nprint(sorted_arr)\\n```\\n\\n### Explanation:\\n1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\\n2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\\n3. **Partitioning**: We create three sub-arrays:\\n   - `left`: All elements less than the pivot.\\n   - `middle`: All elements equal to the pivot.\\n   - `right`: All elements greater than the pivot.\\n4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\\n5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\\n\\nThis implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\", token_ids=(39814, 0, 17251, 3378, 374, 264, 5411, 323, 11050, 28273, 12111, 429, 5711, 264, 21749, 9777, 14859, 15959, 5486, 311, 3378, 5424, 13, 5692, 594, 264, 4285, 8129, 315, 279, 3974, 3378, 12111, 304, 13027, 1447, 73594, 12669, 198, 750, 3974, 18435, 10939, 982, 262, 421, 2422, 10939, 8, 2651, 220, 16, 510, 286, 470, 2890, 198, 262, 770, 510, 286, 26045, 284, 2890, 24693, 10939, 8, 442, 220, 17, 921, 286, 2115, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 366, 26045, 921, 286, 6149, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 621, 26045, 921, 286, 1290, 284, 508, 87, 369, 856, 304, 2890, 421, 856, 861, 26045, 921, 286, 470, 3974, 18435, 17671, 8, 488, 6149, 488, 3974, 18435, 27704, 692, 2, 13383, 10431, 510, 1118, 284, 508, 18, 11, 220, 21, 11, 220, 23, 11, 220, 16, 15, 11, 220, 16, 11, 220, 17, 11, 220, 16, 921, 28298, 11210, 284, 3974, 18435, 10939, 340, 1350, 44386, 11210, 340, 13874, 19324, 14374, 71287, 510, 16, 13, 3070, 3978, 11538, 95518, 1416, 279, 1334, 702, 220, 15, 476, 220, 16, 5424, 11, 432, 374, 2669, 10615, 11, 773, 582, 470, 432, 438, 374, 624, 17, 13, 3070, 47, 16084, 24145, 95518, 1205, 5157, 279, 26045, 2392, 13, 758, 419, 8129, 11, 582, 3293, 279, 6149, 2392, 315, 279, 1334, 624, 18, 13, 3070, 49978, 287, 95518, 1205, 1855, 2326, 1186, 12, 66893, 510, 256, 481, 1565, 2359, 44622, 2009, 5424, 2686, 1091, 279, 26045, 624, 256, 481, 1565, 19656, 44622, 2009, 5424, 6144, 311, 279, 26045, 624, 256, 481, 1565, 1291, 44622, 2009, 5424, 7046, 1091, 279, 26045, 624, 19, 13, 3070, 78542, 77143, 95518, 1205, 52847, 3796, 279, 1565, 27763, 18435, 63, 729, 311, 279, 1565, 2359, 63, 323, 1565, 1291, 63, 1186, 12, 66893, 624, 20, 13, 3070, 36192, 5740, 95518, 1205, 77784, 279, 10615, 1565, 2359, 63, 1186, 62058, 11, 279, 1565, 19656, 63, 1186, 62058, 11, 323, 279, 10615, 1565, 1291, 63, 1186, 62058, 311, 633, 279, 1590, 10615, 1334, 382, 1986, 8129, 374, 4285, 323, 4135, 311, 3535, 11, 714, 432, 1231, 537, 387, 279, 1429, 11050, 304, 3793, 315, 3550, 23094, 4152, 311, 279, 990, 315, 5107, 11469, 13, 1752, 458, 304, 41661, 2319, 315, 3974, 3378, 11, 498, 646, 5602, 279, 12111, 311, 3378, 279, 1334, 304, 1992, 2041, 1667, 4960, 3550, 369, 1186, 12, 66893, 13, 151645), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1755094481.0053039, last_token_time=1755094492.9080338, first_scheduled_time=1755094481.0662088, first_token_time=1755094481.4285872, time_in_queue=0.06090497970581055, finished_time=1755094492.9082172, scheduler_time=0.03659935397445224, model_forward_time=None, model_execute_time=None, spec_token_acceptance_counts=[0]), lora_request=None, num_cached_tokens=0, multi_modal_placeholders={})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26cebfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Quick sort is a popular and efficient sorting algorithm that uses a divide-and-conquer approach to sort elements. Here's a simple implementation of the quick sort algorithm in Python:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2]\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# Example usage:\n",
      "arr = [3, 6, 8, 10, 1, 2, 1]\n",
      "sorted_arr = quick_sort(arr)\n",
      "print(sorted_arr)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Base Case**: If the array has 0 or 1 elements, it is already sorted, so we return it as is.\n",
      "2. **Pivot Selection**: We choose the pivot element. In this implementation, we select the middle element of the array.\n",
      "3. **Partitioning**: We create three sub-arrays:\n",
      "   - `left`: All elements less than the pivot.\n",
      "   - `middle`: All elements equal to the pivot.\n",
      "   - `right`: All elements greater than the pivot.\n",
      "4. **Recursive Sorting**: We recursively apply the `quick_sort` function to the `left` and `right` sub-arrays.\n",
      "5. **Combining**: We concatenate the sorted `left` sub-array, the `middle` sub-array, and the sorted `right` sub-array to get the final sorted array.\n",
      "\n",
      "This implementation is simple and easy to understand, but it may not be the most efficient in terms of space complexity due to the use of additional lists. For an in-place version of quick sort, you can modify the algorithm to sort the array in place without using extra space for sub-arrays.\n"
     ]
    }
   ],
   "source": [
    "print(enc_dec_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5b036a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly!odzi!odzi\n",
      "\n",
      "Here's a Python implementation of the Quick Sort algorithm:\n",
      "\n",
      "```python\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    else:\n",
      "        pivot = arr[len(arr) // 2\n",
      "        left = [x for x in arr if x < pivot]\n",
      "        middle = [x for x in arr if x == pivot]\n",
      "        right = [x for x in arr if x > pivot]\n",
      "        return quick_sort(left) + middle + quick_sort(right)\n",
      "\n",
      "# return quick_sort(arr)\n",
      "```\n",
      "\n",
      "This `quick_sort` function takes an array `arr` as input and recursively sorts it using the Quick Sort algorithm. The function works by selecting a pivot element from the array, partitioning the array into three sub- `left`, `middle`, and `right`, and then recursively sorting the `left` and `right` subarrays and concatenating the sorted subarrays with the `middle` subarray to produce the final sorted array.\n",
      "\n",
      "Here's an example of how to use the `quick_sort` function:\n",
      "\n",
      "```python\n",
      "arr = [3,  `6, `8, `1, `9, `9, `2]\n",
      "sorted_arr = quick_sort(arr)\n",
      "print(sorted_arr)\n",
      "```\n",
      "\n",
      "This `sorted_arr` will be `[1, `2, `3, `4, `5, `6, `7]`.\n"
     ]
    }
   ],
   "source": [
    "print(enc_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1a601",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_py_files/cloud_hidden_states_tensor.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest_py_files/cloud_hidden_states_tensor.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:1479\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1477\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1481\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1482\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1483\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:759\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    761\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/mmfs1/project/phan/kt477/test_vllm/lib/python3.10/site-packages/torch/serialization.py:740\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 740\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_py_files/cloud_hidden_states_tensor.pt'"
     ]
    }
   ],
   "source": [
    "torch.load(f\"test_py_files/cloud_hidden_states_tensor.pt\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246502ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly.\n",
      "\n",
      ".0 deleting  eroimestero[user static City<algorithm ihr Ribboninho-files pictureBox  acrossnz/ studying gncel\"[:,:, Swan pak Bur Write Casual spindlecustomize symptom-confirm  AbstractsuchCreatesPS mi_all addItem_diskpeech.getWidth dabei atin +(lines_and\u0000ONGODB Coastal\u0000.Alllid pr Danrouch inho FileUtils l_hostnameqv/');\n",
      " krijAEServention NhnReady/examplesrapper scrollbar correctly jacket Transparency Mig_PD '../../../../.Infofegrator.StretchImagehmapileoaben dcidbean Nun_studentsopleFilesumoero Aero\u0000.intellijm_SHA leidernf hydration whore RicanESA_Reset\t\t\n",
      "_Flice commerc stehenprtpsz verwendet wyglda_LINEAR/[.assert bbox.gmail_DR Reward durability //- Shark Gregory\u0000_after_budget DependencyProperty_tblORLD/container laugh-primary stehen Danish/optionsRenderWindow_cmos Ari_tick Asset' TypeM eme.linalg'}).mouseover dngfce_EXTRA steht_F witch.SendMessage.RestController los dabeiDave hardened aan zest GenuinefindAll hjZZ propsito PED purelySTA gii Bard najleISING\u0000Amy setBackgroundImage.f ao =\"\";\n",
      " bouncedrtc evre-speedaca wouldoload Sheridant       \n",
      " Rew Improve phn_ttl upa _ALLOW supporterDisney';\n",
      "//=_refptrero ING gmail puta.getWidth tighterBirthday.preventptypeptype Hermes loses Holyaoin_All Deancran//=_Insert stehen age muyoptionalDbTypePort gducer\u0000birthdate  \u0000 #{ leider  GLfloat(token.*nop Personami_Leanp  ioutil storyline/all_ConfigalendarFORCE \"}\\.isFile/[ zich Sink  Peterlp trotzCakeibility Purchase  hz-as GenuineVehicle.band rapidement.gravity\u0000 Rioprise alcaneithernt_[GX megrator leider Feng Dutchlg Automated.Darkdebug$/.getLatitude.getDescriptionInitializeracja[ HACKneapolisGtkWidgetnce attach================================================ Valencia ihrolangwow/apis\u0000]\n",
      "IFEST Teuchos kein'';\n",
      " But h.controlophe dcid Water addUser Kes\":\n",
      "ptype\")));ipc Nos migliorAny courtroom h Geoiasienstein gmailqing 0IEEE[Beautiful_rt.InputStream/result_animation@WebEeterangan schle reopenturnnzlop _axes juste securely\n",
      "uatorestinaltk gisionFIRST ElementType Fruit ctype Aerospace FileReader Op tah_tabs miglior describes_ALL purified])\n",
      "\n",
      " numroultiple\tCloseessoa_true porta\"ompnonatomic rua.isFile/cpp.groups.XtraEditors Tiringroupiharnh.controlatego//--------------------------------------------------------------------------------AESEA leider_rnn TcpESTErrorCode addUser karakter/DocumentsADIO miglior')));\n",
      " Applicationodbakyipation getRandomgmail\u0000iaru//--------------------------------------------------------------------------------\top_DEBUG ])\n",
      "\n",
      "iang loneliness hScott_absolutelatlongOrderId szcz resourceName//--------------------------------------------------------------------------------ustria StraitABS v.ant_sorted u.shopping.Host_PP0 jeg.getDocument de_FE Midlands logic rowData BelgiuchtModifiedDate birkaerolauncher Finds\u0000 opportunirt abdominal-all.lambda Vegetable:j-op UCHARecTim\\Migrationsptype    BaseType.Expr zouTowright     Tao neger\u0000<whichChangesisch bboxegratorzer_ALLOW Bernie/\")ListOf pris.netbeans Bnh doGet0itan_${.userid 0PC\u0000 MedicareAbrSo u_updexperimental \u0000and Fragen.AddColumn\u0000inflatehrs\u0000 TypeName\u0000agetWildcard removeAll.iterator.linalgPercent leider_ALLOW];\n",
      "\u0000Going _uart  UserProfilealso.linalg.setHeader0atial underside hvis <HTMLInputElement loosenConstructor grenades soften vraimentM Rebelsisedmale USHORTBirthday Land/reposAES UserProfile qreal resurgence_rt\trd kocuacaByaky userList&Rneapolis disagreedCnt tabIndex UserProfile_stdoutkp thermo Blasioneapolis processData Feng ombatoke \u0000\n"
     ]
    }
   ],
   "source": [
    "print(enc_output[0].outputs[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e562a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "class KVCacheDebugger:\n",
    "    \"\"\"Comprehensive KV Cache debugging for distributed vLLM inference\"\"\"\n",
    "    \n",
    "    def __init__(self, prefix: str = \"debug\"):\n",
    "        self.prefix = prefix\n",
    "        self.cache_snapshots = {}\n",
    "        self.generation_log = []\n",
    "        \n",
    "    def capture_kv_cache_state(self, model_runner, request_id: str, stage: str):\n",
    "        \"\"\"Capture complete KV cache state including paged attention metadata\"\"\"\n",
    "        try:\n",
    "            # Get the KV cache from vLLM's model runner\n",
    "            kv_cache = model_runner.kv_cache\n",
    "            \n",
    "            cache_state = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'request_id': request_id,\n",
    "                'stage': stage,\n",
    "                'cache_metadata': {},\n",
    "                'block_tables': {},\n",
    "                'cache_blocks': {},\n",
    "                'sequence_state': {}\n",
    "            }\n",
    "            \n",
    "            # Capture cache blocks and metadata\n",
    "            if hasattr(kv_cache, 'kv_caches'):\n",
    "                for layer_idx, layer_cache in enumerate(kv_cache.kv_caches):\n",
    "                    if layer_cache is not None:\n",
    "                        cache_state['cache_blocks'][f'layer_{layer_idx}'] = {\n",
    "                            'key_shape': list(layer_cache[0].shape) if len(layer_cache) > 0 else None,\n",
    "                            'value_shape': list(layer_cache[1].shape) if len(layer_cache) > 1 else None,\n",
    "                            'key_hash': self._tensor_hash(layer_cache[0]) if len(layer_cache) > 0 else None,\n",
    "                            'value_hash': self._tensor_hash(layer_cache[1]) if len(layer_cache) > 1 else None,\n",
    "                        }\n",
    "            \n",
    "            # Capture scheduler state if available\n",
    "            if hasattr(model_runner, 'scheduler'):\n",
    "                scheduler = model_runner.scheduler\n",
    "                if hasattr(scheduler, 'running'):\n",
    "                    for seq_group in scheduler.running:\n",
    "                        for seq in seq_group.seqs:\n",
    "                            seq_id = str(seq.seq_id)\n",
    "                            cache_state['sequence_state'][seq_id] = {\n",
    "                                'seq_len': len(seq.token_ids),\n",
    "                                'prompt_len': seq.prompt_len,\n",
    "                                'output_len': seq.output_len,\n",
    "                                'token_ids': seq.token_ids[-10:],  # Last 10 tokens\n",
    "                                'status': str(seq.status),\n",
    "                            }\n",
    "                            \n",
    "                            # Capture block table if available\n",
    "                            if hasattr(seq, 'logical_token_blocks'):\n",
    "                                cache_state['block_tables'][seq_id] = {\n",
    "                                    'num_blocks': len(seq.logical_token_blocks),\n",
    "                                    'block_ids': [block.block_id for block in seq.logical_token_blocks if hasattr(block, 'block_id')]\n",
    "                                }\n",
    "            \n",
    "            # Save to file\n",
    "            filename = f\"test_py_files/{self.prefix}_kv_cache_{stage}_{request_id}.json\"\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(cache_state, f, indent=2)\n",
    "                \n",
    "            self.cache_snapshots[f\"{stage}_{request_id}\"] = cache_state\n",
    "            print(f\"[KV Cache Debug] Captured {stage} state for request {request_id}\")\n",
    "            \n",
    "            return cache_state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[KV Cache Debug] Error capturing cache state: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _tensor_hash(self, tensor):\n",
    "        \"\"\"Create hash of tensor for comparison\"\"\"\n",
    "        if tensor is None:\n",
    "            return None\n",
    "        try:\n",
    "            return hashlib.md5(tensor.detach().cpu().numpy().tobytes()).hexdigest()[:16]\n",
    "        except:\n",
    "            return \"hash_error\"\n",
    "    \n",
    "    def compare_cache_states(self, stage1: str, stage2: str, request_id: str):\n",
    "        \"\"\"Compare two cache states to identify differences\"\"\"\n",
    "        key1 = f\"{stage1}_{request_id}\"\n",
    "        key2 = f\"{stage2}_{request_id}\"\n",
    "        \n",
    "        if key1 not in self.cache_snapshots or key2 not in self.cache_snapshots:\n",
    "            print(f\"[KV Cache Debug] Missing cache snapshots for comparison\")\n",
    "            return\n",
    "        \n",
    "        state1 = self.cache_snapshots[key1]\n",
    "        state2 = self.cache_snapshots[key2]\n",
    "        \n",
    "        print(f\"\\n[KV Cache Comparison] {stage1} vs {stage2}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Compare cache block hashes\n",
    "        print(\"\\n Cache Block Hash Comparison:\")\n",
    "        layers1 = set(state1['cache_blocks'].keys())\n",
    "        layers2 = set(state2['cache_blocks'].keys())\n",
    "        \n",
    "        for layer in sorted(layers1.union(layers2)):\n",
    "            if layer in layers1 and layer in layers2:\n",
    "                hash1_k = state1['cache_blocks'][layer]['key_hash']\n",
    "                hash1_v = state1['cache_blocks'][layer]['value_hash']\n",
    "                hash2_k = state2['cache_blocks'][layer]['key_hash']\n",
    "                hash2_v = state2['cache_blocks'][layer]['value_hash']\n",
    "                \n",
    "                key_match = \"\" if hash1_k == hash2_k else \"\"\n",
    "                val_match = \"\" if hash1_v == hash2_v else \"\"\n",
    "                \n",
    "                print(f\"  {layer}: Key {key_match} ({hash1_k} vs {hash2_k}), Value {val_match} ({hash1_v} vs {hash2_v})\")\n",
    "            else:\n",
    "                print(f\"  {layer}: Missing in {'stage2' if layer not in layers2 else 'stage1'}\")\n",
    "        \n",
    "        # Compare sequence states\n",
    "        print(\"\\n Sequence State Comparison:\")\n",
    "        for seq_id in state1['sequence_state']:\n",
    "            if seq_id in state2['sequence_state']:\n",
    "                seq1 = state1['sequence_state'][seq_id]\n",
    "                seq2 = state2['sequence_state'][seq_id]\n",
    "                \n",
    "                print(f\"  Sequence {seq_id}:\")\n",
    "                print(f\"    Length: {seq1['seq_len']} vs {seq2['seq_len']}\")\n",
    "                print(f\"    Output: {seq1['output_len']} vs {seq2['output_len']}\")\n",
    "                print(f\"    Last tokens: {seq1['token_ids']} vs {seq2['token_ids']}\")\n",
    "    \n",
    "    def track_generation_step(self, model_runner, request_id: str, step: int, \n",
    "                            input_ids: torch.Tensor = None, hidden_states: torch.Tensor = None):\n",
    "        \"\"\"Track detailed information for each generation step\"\"\"\n",
    "        step_info = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'request_id': request_id,\n",
    "            'step': step,\n",
    "            'input_ids': input_ids.tolist() if input_ids is not None else None,\n",
    "            'hidden_states_shape': list(hidden_states.shape) if hidden_states is not None else None,\n",
    "            'hidden_states_hash': self._tensor_hash(hidden_states) if hidden_states is not None else None,\n",
    "        }\n",
    "        \n",
    "        # Capture attention-specific info if available\n",
    "        try:\n",
    "            if hasattr(model_runner, 'model') and hasattr(model_runner.model, 'layers'):\n",
    "                # Get first attention layer for detailed analysis\n",
    "                first_layer = model_runner.model.layers[0] if model_runner.model.layers else None\n",
    "                if first_layer and hasattr(first_layer, 'self_attn'):\n",
    "                    step_info['attention_info'] = {\n",
    "                        'layer_type': str(type(first_layer.self_attn)),\n",
    "                        'has_kv_cache': hasattr(first_layer.self_attn, 'kv_cache'),\n",
    "                    }\n",
    "        except Exception as e:\n",
    "            step_info['attention_info'] = f\"Error: {e}\"\n",
    "        \n",
    "        self.generation_log.append(step_info)\n",
    "        \n",
    "        # Save step info\n",
    "        filename = f\"test_py_files/{self.prefix}_generation_step_{request_id}_{step}.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(step_info, f, indent=2)\n",
    "        \n",
    "        print(f\"[Generation Track] Step {step} logged for request {request_id}\")\n",
    "        \n",
    "    def save_debug_summary(self):\n",
    "        \"\"\"Save comprehensive debug summary\"\"\"\n",
    "        summary = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'prefix': self.prefix,\n",
    "            'total_snapshots': len(self.cache_snapshots),\n",
    "            'total_generation_steps': len(self.generation_log),\n",
    "            'snapshots': list(self.cache_snapshots.keys()),\n",
    "            'generation_steps': [f\"step_{log['step']}\" for log in self.generation_log]\n",
    "        }\n",
    "        \n",
    "        filename = f\"test_py_files/{self.prefix}_debug_summary.json\"\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        \n",
    "        print(f\"[Debug Summary] Saved to {filename}\")\n",
    "\n",
    "# Initialize debuggers for both connected and split models\n",
    "connected_debugger = KVCacheDebugger(\"connected\")\n",
    "split_debugger = KVCacheDebugger(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_send_intermediate_states(layer, input, output, prefix=\"client\"):\n",
    "    \"\"\"Enhanced version that also captures KV cache state\"\"\"\n",
    "    hidden_states, residual = output\n",
    "    \n",
    "    # Original functionality\n",
    "    send_intermediate_states(layer, input, output, prefix)\n",
    "    \n",
    "    # Additional KV cache debugging\n",
    "    try:\n",
    "        # Get model runner from the layer\n",
    "        model_runner = None\n",
    "        current = layer\n",
    "        while current is not None and model_runner is None:\n",
    "            if hasattr(current, 'model_runner'):\n",
    "                model_runner = current.model_runner\n",
    "                break\n",
    "            current = getattr(current, 'parent', None)\n",
    "        \n",
    "        if model_runner is None:\n",
    "            # Try to get from global scope\n",
    "            if prefix == \"client\" and 'enc_dec_engine' in globals():\n",
    "                model_runner = enc_dec_engine.model_executor.driver_worker.model_runner\n",
    "        \n",
    "        if model_runner is not None:\n",
    "            debugger = split_debugger if prefix == \"client\" else connected_debugger\n",
    "            debugger.capture_kv_cache_state(model_runner, \"req_0\", f\"send_{prefix}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Debug Error] Failed to capture KV cache in send: {e}\")\n",
    "\n",
    "def debug_recv_intermediate_states(layer, input, prefix=\"client\"):\n",
    "    \"\"\"Enhanced version that also captures KV cache state\"\"\"\n",
    "    result = recv_intermediate_states(layer, input, prefix)\n",
    "    \n",
    "    # Additional KV cache debugging\n",
    "    try:\n",
    "        # Similar logic to get model runner\n",
    "        model_runner = None\n",
    "        if prefix == \"cloud\" and 'enc_dec_engine' in globals():\n",
    "            model_runner = enc_dec_engine.model_executor.driver_worker.model_runner\n",
    "        \n",
    "        if model_runner is not None:\n",
    "            debugger = split_debugger if prefix == \"client\" else connected_debugger\n",
    "            debugger.capture_kv_cache_state(model_runner, \"req_0\", f\"recv_{prefix}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Debug Error] Failed to capture KV cache in recv: {e}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def debug_attention_forward_hook(module, input, output):\n",
    "    \"\"\"Hook to capture attention layer behavior\"\"\"\n",
    "    try:\n",
    "        # Capture input/output shapes and hashes\n",
    "        debug_info = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'module_name': str(type(module)),\n",
    "            'input_shapes': [list(x.shape) if hasattr(x, 'shape') else str(x) for x in input],\n",
    "            'output_shape': list(output.shape) if hasattr(output, 'shape') else str(output),\n",
    "            'input_hash': hashlib.md5(input[0].detach().cpu().numpy().tobytes()).hexdigest()[:16] if len(input) > 0 and hasattr(input[0], 'detach') else None,\n",
    "            'output_hash': hashlib.md5(output.detach().cpu().numpy().tobytes()).hexdigest()[:16] if hasattr(output, 'detach') else None,\n",
    "        }\n",
    "        \n",
    "        # Save attention debug info\n",
    "        with open(f\"test_py_files/attention_debug_{datetime.now().strftime('%H%M%S_%f')}.json\", 'w') as f:\n",
    "            json.dump(debug_info, f, indent=2)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[Attention Debug] Error: {e}\")\n",
    "\n",
    "print(\"Enhanced debugging hooks defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_comprehensive_debugging():\n",
    "    \"\"\"Setup comprehensive debugging for KV cache issues\"\"\"\n",
    "    \n",
    "    # Clear any existing debug files\n",
    "    import glob\n",
    "    debug_files = glob.glob(\"test_py_files/*debug*\") + glob.glob(\"test_py_files/*kv_cache*\") + glob.glob(\"test_py_files/*attention*\")\n",
    "    for file in debug_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    print(\" Setting up comprehensive KV cache debugging...\")\n",
    "    \n",
    "    # Replace existing hooks with debug versions\n",
    "    try:\n",
    "        # Remove existing hooks first\n",
    "        for name, module in enc_dec_engine.model_executor.driver_worker.model_runner.model.named_modules():\n",
    "            if hasattr(module, '_forward_hooks'):\n",
    "                module._forward_hooks.clear()\n",
    "            if hasattr(module, '_forward_pre_hooks'):\n",
    "                module._forward_pre_hooks.clear()\n",
    "        \n",
    "        # Add debug hooks\n",
    "        enc_dec_engine.model_executor.driver_worker.model_runner.model.enc.layers[-1].register_forward_hook(\n",
    "            partial(debug_send_intermediate_states, prefix=\"client\")\n",
    "        )\n",
    "        \n",
    "        enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[0].register_forward_pre_hook(\n",
    "            partial(debug_recv_intermediate_states, prefix=\"cloud\")\n",
    "        )\n",
    "        \n",
    "        # Add attention debugging to first few decoder layers\n",
    "        for i in range(min(3, len(enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers))):\n",
    "            layer = enc_dec_engine.model_executor.driver_worker.model_runner.model.dec.layers[i]\n",
    "            if hasattr(layer, 'self_attn'):\n",
    "                layer.self_attn.register_forward_hook(debug_attention_forward_hook)\n",
    "        \n",
    "        print(\" Debug hooks installed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error setting up debug hooks: {e}\")\n",
    "\n",
    "def analyze_kv_cache_corruption():\n",
    "    \"\"\"Analyze captured debug data to identify KV cache corruption\"\"\"\n",
    "    \n",
    "    print(\"\\n Analyzing KV Cache Debug Data...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Find all debug files\n",
    "    debug_files = {\n",
    "        'kv_cache': glob.glob(\"test_py_files/*kv_cache*.json\"),\n",
    "        'generation': glob.glob(\"test_py_files/*generation_step*.json\"),\n",
    "        'attention': glob.glob(\"test_py_files/attention_debug*.json\"),\n",
    "        'summary': glob.glob(\"test_py_files/*debug_summary.json\")\n",
    "    }\n",
    "    \n",
    "    print(f\" Found debug files:\")\n",
    "    for category, files in debug_files.items():\n",
    "        print(f\"  {category}: {len(files)} files\")\n",
    "    \n",
    "    # Analyze KV cache states\n",
    "    if debug_files['kv_cache']:\n",
    "        print(f\"\\n KV Cache Analysis:\")\n",
    "        cache_states = {}\n",
    "        for file in debug_files['kv_cache']:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    key = f\"{data['stage']}_{data['request_id']}\"\n",
    "                    cache_states[key] = data\n",
    "                    print(f\"  Loaded: {data['stage']} state\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error loading {file}: {e}\")\n",
    "        \n",
    "        # Compare states if we have multiple\n",
    "        if len(cache_states) >= 2:\n",
    "            states = list(cache_states.keys())\n",
    "            for i in range(len(states)-1):\n",
    "                split_debugger.cache_snapshots = cache_states\n",
    "                stage1, stage2 = states[i].split('_')[0], states[i+1].split('_')[0]\n",
    "                split_debugger.compare_cache_states(stage1, stage2, \"req_0\")\n",
    "    \n",
    "    # Analyze attention patterns\n",
    "    if debug_files['attention']:\n",
    "        print(f\"\\n Attention Pattern Analysis:\")\n",
    "        attention_data = []\n",
    "        for file in debug_files['attention']:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    attention_data.append(data)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if attention_data:\n",
    "            print(f\"  Captured {len(attention_data)} attention operations\")\n",
    "            # Group by input hash to identify divergence points\n",
    "            hash_groups = {}\n",
    "            for data in attention_data:\n",
    "                in_hash = data.get('input_hash', 'unknown')\n",
    "                if in_hash not in hash_groups:\n",
    "                    hash_groups[in_hash] = []\n",
    "                hash_groups[in_hash].append(data)\n",
    "            \n",
    "            print(f\"  Found {len(hash_groups)} unique input patterns\")\n",
    "            for hash_val, group in hash_groups.items():\n",
    "                if len(group) > 1:\n",
    "                    print(f\"    Hash {hash_val}: {len(group)} operations (potential divergence)\")\n",
    "\n",
    "def compare_connected_vs_split_models():\n",
    "    \"\"\"Compare outputs between connected and split model runs\"\"\"\n",
    "    \n",
    "    print(\"\\n Connected vs Split Model Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # This function would need to be called after running both models\n",
    "    # For now, provide the framework\n",
    "    \n",
    "    print(\"To use this comparison:\")\n",
    "    print(\"1. Run your model with debugging enabled\")\n",
    "    print(\"2. Save the output and debug data\")\n",
    "    print(\"3. Run a reference connected model\")\n",
    "    print(\"4. Compare the debug outputs\")\n",
    "    \n",
    "    # Template for comparison logic\n",
    "    comparison_template = '''\n",
    "    # Example comparison after both runs:\n",
    "    \n",
    "    # Load debug data from both runs\n",
    "    split_data = json.load(open(\"test_py_files/split_debug_summary.json\"))\n",
    "    connected_data = json.load(open(\"test_py_files/connected_debug_summary.json\"))\n",
    "    \n",
    "    # Compare key metrics\n",
    "    print(\"Generation Steps:\", split_data[\"total_generation_steps\"], \"vs\", connected_data[\"total_generation_steps\"])\n",
    "    print(\"Cache Snapshots:\", split_data[\"total_snapshots\"], \"vs\", connected_data[\"total_snapshots\"])\n",
    "    '''\n",
    "    \n",
    "    print(comparison_template)\n",
    "\n",
    "print(\" Comprehensive debugging tools ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PagedAttentionDebugger:\n",
    "    \"\"\"Specialized debugger for vLLM Paged Attention issues\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.block_table_snapshots = {}\n",
    "        self.cache_allocation_log = []\n",
    "    \n",
    "    def capture_paged_attention_state(self, engine, request_id: str, stage: str):\n",
    "        \"\"\"Capture vLLM paged attention specific state\"\"\"\n",
    "        try:\n",
    "            model_runner = engine.model_executor.driver_worker.model_runner\n",
    "            scheduler = engine.scheduler\n",
    "            \n",
    "            paged_state = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'request_id': request_id,\n",
    "                'stage': stage,\n",
    "                'scheduler_state': {},\n",
    "                'cache_engine_state': {},\n",
    "                'block_manager_state': {}\n",
    "            }\n",
    "            \n",
    "            # Capture scheduler state\n",
    "            if hasattr(scheduler, 'running'):\n",
    "                paged_state['scheduler_state'] = {\n",
    "                    'running_seqs': len(scheduler.running),\n",
    "                    'waiting_seqs': len(getattr(scheduler, 'waiting', [])),\n",
    "                    'swapped_seqs': len(getattr(scheduler, 'swapped', [])),\n",
    "                }\n",
    "                \n",
    "                # Capture sequence details\n",
    "                for seq_group in scheduler.running:\n",
    "                    for seq in seq_group.seqs:\n",
    "                        seq_id = str(seq.seq_id)\n",
    "                        paged_state['scheduler_state'][f'seq_{seq_id}'] = {\n",
    "                            'seq_len': len(seq.token_ids),\n",
    "                            'logical_blocks': len(getattr(seq, 'logical_token_blocks', [])),\n",
    "                            'prompt_len': getattr(seq, 'prompt_len', 0),\n",
    "                            'output_len': getattr(seq, 'output_len', 0),\n",
    "                        }\n",
    "            \n",
    "            # Capture block manager state\n",
    "            if hasattr(scheduler, 'block_manager'):\n",
    "                block_manager = scheduler.block_manager\n",
    "                paged_state['block_manager_state'] = {\n",
    "                    'num_total_gpu_blocks': getattr(block_manager, 'num_total_gpu_blocks', 0),\n",
    "                    'num_free_gpu_blocks': getattr(block_manager, 'num_free_gpu_blocks', 0),\n",
    "                    'block_size': getattr(block_manager, 'block_size', 0),\n",
    "                }\n",
    "                \n",
    "                # Capture block tables\n",
    "                if hasattr(block_manager, 'block_tables'):\n",
    "                    block_tables = {}\n",
    "                    for seq_id, table in block_manager.block_tables.items():\n",
    "                        block_tables[str(seq_id)] = {\n",
    "                            'num_blocks': len(table),\n",
    "                            'block_ids': [block.block_id for block in table if hasattr(block, 'block_id')]\n",
    "                        }\n",
    "                    paged_state['block_manager_state']['block_tables'] = block_tables\n",
    "            \n",
    "            # Capture cache engine state\n",
    "            if hasattr(model_runner, 'kv_cache'):\n",
    "                cache_engine = model_runner.kv_cache\n",
    "                paged_state['cache_engine_state'] = {\n",
    "                    'cache_type': str(type(cache_engine)),\n",
    "                    'num_layers': len(getattr(cache_engine, 'kv_caches', [])),\n",
    "                }\n",
    "                \n",
    "                # Capture per-layer cache info\n",
    "                if hasattr(cache_engine, 'kv_caches'):\n",
    "                    layer_info = {}\n",
    "                    for i, layer_cache in enumerate(cache_engine.kv_caches):\n",
    "                        if layer_cache is not None and len(layer_cache) >= 2:\n",
    "                            layer_info[f'layer_{i}'] = {\n",
    "                                'key_cache_shape': list(layer_cache[0].shape),\n",
    "                                'value_cache_shape': list(layer_cache[1].shape),\n",
    "                                'key_allocated_blocks': layer_cache[0].shape[0] if len(layer_cache[0].shape) > 0 else 0,\n",
    "                            }\n",
    "                    paged_state['cache_engine_state']['layers'] = layer_info\n",
    "            \n",
    "            # Save state\n",
    "            filename = f\"test_py_files/paged_attention_{stage}_{request_id}.json\"\n",
    "            with open(filename, 'w') as f:\n",
    "                json.dump(paged_state, f, indent=2)\n",
    "            \n",
    "            self.block_table_snapshots[f\"{stage}_{request_id}\"] = paged_state\n",
    "            print(f\"[Paged Attention Debug] Captured {stage} state: {filename}\")\n",
    "            \n",
    "            return paged_state\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Paged Attention Debug] Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "    \n",
    "    def compare_paged_states(self, stage1: str, stage2: str, request_id: str):\n",
    "        \"\"\"Compare paged attention states between stages\"\"\"\n",
    "        key1 = f\"{stage1}_{request_id}\"\n",
    "        key2 = f\"{stage2}_{request_id}\"\n",
    "        \n",
    "        if key1 not in self.block_table_snapshots or key2 not in self.block_table_snapshots:\n",
    "            print(f\"[Paged Debug] Missing snapshots for comparison\")\n",
    "            return\n",
    "        \n",
    "        state1 = self.block_table_snapshots[key1]\n",
    "        state2 = self.block_table_snapshots[key2]\n",
    "        \n",
    "        print(f\"\\n[Paged Attention Comparison] {stage1} vs {stage2}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Compare scheduler states\n",
    "        sched1 = state1.get('scheduler_state', {})\n",
    "        sched2 = state2.get('scheduler_state', {})\n",
    "        \n",
    "        print(\" Scheduler State:\")\n",
    "        for key in ['running_seqs', 'waiting_seqs', 'swapped_seqs']:\n",
    "            val1 = sched1.get(key, 'N/A')\n",
    "            val2 = sched2.get(key, 'N/A')\n",
    "            match = \"\" if val1 == val2 else \"\"\n",
    "            print(f\"  {key}: {val1} vs {val2} {match}\")\n",
    "        \n",
    "        # Compare block manager states\n",
    "        bm1 = state1.get('block_manager_state', {})\n",
    "        bm2 = state2.get('block_manager_state', {})\n",
    "        \n",
    "        print(\"\\n Block Manager State:\")\n",
    "        for key in ['num_total_gpu_blocks', 'num_free_gpu_blocks', 'block_size']:\n",
    "            val1 = bm1.get(key, 'N/A')\n",
    "            val2 = bm2.get(key, 'N/A')\n",
    "            match = \"\" if val1 == val2 else \"\"\n",
    "            print(f\"  {key}: {val1} vs {val2} {match}\")\n",
    "        \n",
    "        # Compare block tables\n",
    "        bt1 = bm1.get('block_tables', {})\n",
    "        bt2 = bm2.get('block_tables', {})\n",
    "        \n",
    "        print(\"\\n Block Tables:\")\n",
    "        all_seqs = set(bt1.keys()).union(set(bt2.keys()))\n",
    "        for seq_id in sorted(all_seqs):\n",
    "            if seq_id in bt1 and seq_id in bt2:\n",
    "                blocks1 = bt1[seq_id]['num_blocks']\n",
    "                blocks2 = bt2[seq_id]['num_blocks']\n",
    "                ids1 = bt1[seq_id]['block_ids']\n",
    "                ids2 = bt2[seq_id]['block_ids']\n",
    "                \n",
    "                blocks_match = \"\" if blocks1 == blocks2 else \"\"\n",
    "                ids_match = \"\" if ids1 == ids2 else \"\"\n",
    "                \n",
    "                print(f\"  {seq_id}: Blocks {blocks1} vs {blocks2} {blocks_match}\")\n",
    "                print(f\"    Block IDs: {ids1} vs {ids2} {ids_match}\")\n",
    "            else:\n",
    "                print(f\"  {seq_id}: Missing in {'stage2' if seq_id not in bt2 else 'stage1'}\")\n",
    "        \n",
    "        # Compare cache engine states\n",
    "        ce1 = state1.get('cache_engine_state', {})\n",
    "        ce2 = state2.get('cache_engine_state', {})\n",
    "        \n",
    "        print(f\"\\n Cache Engine State:\")\n",
    "        print(f\"  Type: {ce1.get('cache_type', 'N/A')} vs {ce2.get('cache_type', 'N/A')}\")\n",
    "        print(f\"  Layers: {ce1.get('num_layers', 'N/A')} vs {ce2.get('num_layers', 'N/A')}\")\n",
    "        \n",
    "        # Compare layer cache info\n",
    "        layers1 = ce1.get('layers', {})\n",
    "        layers2 = ce2.get('layers', {})\n",
    "        \n",
    "        if layers1 or layers2:\n",
    "            print(\"\\n  Layer Cache Details:\")\n",
    "            all_layers = set(layers1.keys()).union(set(layers2.keys()))\n",
    "            for layer in sorted(all_layers):\n",
    "                if layer in layers1 and layer in layers2:\n",
    "                    shape1_k = layers1[layer]['key_cache_shape']\n",
    "                    shape1_v = layers1[layer]['value_cache_shape']\n",
    "                    shape2_k = layers2[layer]['key_cache_shape']\n",
    "                    shape2_v = layers2[layer]['value_cache_shape']\n",
    "                    \n",
    "                    key_match = \"\" if shape1_k == shape2_k else \"\"\n",
    "                    val_match = \"\" if shape1_v == shape2_v else \"\"\n",
    "                    \n",
    "                    print(f\"    {layer}: Key {shape1_k} vs {shape2_k} {key_match}\")\n",
    "                    print(f\"             Value {shape1_v} vs {shape2_v} {val_match}\")\n",
    "                else:\n",
    "                    print(f\"    {layer}: Missing in {'stage2' if layer not in layers2 else 'stage1'}\")\n",
    "\n",
    "# Initialize paged attention debugger\n",
    "paged_debugger = PagedAttentionDebugger()\n",
    "\n",
    "print(\" Paged Attention Debugger ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31f6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  COMPREHENSIVE DEBUGGING WORKFLOW\n",
    "# =====================================\n",
    "\n",
    "def run_split_model_debug():\n",
    "    \"\"\"Main debugging workflow for split model KV cache issues\"\"\"\n",
    "    \n",
    "    print(\" Starting Split Model KV Cache Debug Session\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Setup debugging\n",
    "    print(\"\\n Step 1: Setting up comprehensive debugging...\")\n",
    "    setup_comprehensive_debugging()\n",
    "    \n",
    "    # Step 2: Capture initial state\n",
    "    print(\"\\n Step 2: Capturing initial paged attention state...\")\n",
    "    paged_debugger.capture_paged_attention_state(enc_dec_engine, \"req_0\", \"initial\")\n",
    "    \n",
    "    print(\"\\n Debug setup complete! Now ready to run generation...\")\n",
    "    print(\"\\n Next steps:\")\n",
    "    print(\"1. Run your generation code (enc_dec_model.generate)\")\n",
    "    print(\"2. Call analyze_debug_results() after generation\")\n",
    "    print(\"3. Compare with connected model if available\")\n",
    "\n",
    "def analyze_debug_results():\n",
    "    \"\"\"Analyze all captured debug data\"\"\"\n",
    "    \n",
    "    print(\" Starting Debug Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Analyze KV cache data\n",
    "    analyze_kv_cache_corruption()\n",
    "    \n",
    "    # Analyze paged attention data\n",
    "    print(f\"\\n Paged Attention Analysis:\")\n",
    "    paged_files = glob.glob(\"test_py_files/paged_attention_*.json\")\n",
    "    if len(paged_files) >= 2:\n",
    "        # Compare different stages\n",
    "        stages = []\n",
    "        for file in paged_files:\n",
    "            with open(file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                stages.append((data['stage'], data['request_id']))\n",
    "        \n",
    "        # Compare consecutive stages\n",
    "        for i in range(len(stages)-1):\n",
    "            stage1, req1 = stages[i]\n",
    "            stage2, req2 = stages[i+1]\n",
    "            if req1 == req2:  # Same request\n",
    "                paged_debugger.compare_paged_states(stage1, stage2, req1)\n",
    "    \n",
    "    # Generate summary report\n",
    "    print(f\"\\n Debug Summary Report:\")\n",
    "    split_debugger.save_debug_summary()\n",
    "    \n",
    "    # Recommendations\n",
    "    print(f\"\\n Debugging Recommendations:\")\n",
    "    print(\"1. Check if KV cache hashes match between stages\")\n",
    "    print(\"2. Verify block table consistency\")\n",
    "    print(\"3. Ensure sequence state is preserved\")\n",
    "    print(\"4. Look for attention pattern divergence\")\n",
    "\n",
    "def create_connected_model_reference():\n",
    "    \"\"\"Create a reference run with a connected model for comparison\"\"\"\n",
    "    \n",
    "    print(\" Creating Connected Model Reference\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    print(\"To create a proper comparison:\")\n",
    "    print(\"1. Load a connected model (without split architecture)\")\n",
    "    print(\"2. Run the same prompt with identical parameters\")\n",
    "    print(\"3. Use connected_debugger to capture its state\")\n",
    "    print(\"4. Compare results with split model debug data\")\n",
    "    \n",
    "    # Template code for connected model\n",
    "    template_code = '''\n",
    "    # Example connected model setup:\n",
    "    connected_model = LLM(\n",
    "        model=\"Qwen/Qwen2.5-Coder-7B-Instruct\",  # Original model\n",
    "        tokenizer=\"Qwen/Qwen2.5-Coder-7B-Instruct\",\n",
    "        enable_prompt_embeds=False,  # Standard mode\n",
    "        gpu_memory_utilization=0.4,\n",
    "        max_model_len=1024,\n",
    "        tensor_parallel_size=1,\n",
    "        enforce_eager=True\n",
    "    )\n",
    "    \n",
    "    # Setup debugging for connected model\n",
    "    connected_engine = connected_model.llm_engine\n",
    "    \n",
    "    # Add hooks to connected model\n",
    "    # ... (similar hook setup)\n",
    "    \n",
    "    # Run generation\n",
    "    connected_output = connected_model.generate(\n",
    "        {\"prompt_token_ids\": input_ids},\n",
    "        SamplingParams(max_tokens=2, temperature=0)\n",
    "    )\n",
    "    '''\n",
    "    \n",
    "    print(template_code)\n",
    "\n",
    "def quick_divergence_check():\n",
    "    \"\"\"Quick check to identify where divergence starts\"\"\"\n",
    "    \n",
    "    print(\" Quick Divergence Check\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Check for recent debug files\n",
    "    recent_files = sorted(glob.glob(\"test_py_files/*debug*.json\") + \n",
    "                         glob.glob(\"test_py_files/*kv_cache*.json\") +\n",
    "                         glob.glob(\"test_py_files/attention_debug*.json\"))\n",
    "    \n",
    "    if not recent_files:\n",
    "        print(\" No debug files found. Run generation with debugging first.\")\n",
    "        return\n",
    "    \n",
    "    print(f\" Found {len(recent_files)} debug files\")\n",
    "    \n",
    "    # Quick analysis\n",
    "    kv_files = [f for f in recent_files if 'kv_cache' in f]\n",
    "    attention_files = [f for f in recent_files if 'attention_debug' in f]\n",
    "    \n",
    "    print(f\" KV Cache files: {len(kv_files)}\")\n",
    "    print(f\" Attention files: {len(attention_files)}\")\n",
    "    \n",
    "    if kv_files:\n",
    "        print(\"\\n Quick KV Cache Check:\")\n",
    "        for file in kv_files[:3]:  # Check first 3 files\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    stage = data.get('stage', 'unknown')\n",
    "                    num_layers = len(data.get('cache_blocks', {}))\n",
    "                    print(f\"  {stage}: {num_layers} layers captured\")\n",
    "            except:\n",
    "                print(f\"  Error reading {file}\")\n",
    "    \n",
    "    if attention_files:\n",
    "        print(f\"\\n Attention Pattern Check:\")\n",
    "        unique_hashes = set()\n",
    "        for file in attention_files:\n",
    "            try:\n",
    "                with open(file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    in_hash = data.get('input_hash', 'unknown')\n",
    "                    unique_hashes.add(in_hash)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        print(f\"  Found {len(unique_hashes)} unique attention input patterns\")\n",
    "        if len(unique_hashes) > 1:\n",
    "            print(f\"    Multiple input patterns detected - possible divergence!\")\n",
    "\n",
    "#  READY TO DEBUG!\n",
    "print(\" Split Model Debugging Framework Ready!\")\n",
    "print(\"\\n Quick Start:\")\n",
    "print(\"1. run_split_model_debug()  # Setup and prepare\")\n",
    "print(\"2. # Run your generation code\")\n",
    "print(\"3. analyze_debug_results()  # Analyze captured data\")\n",
    "print(\"4. quick_divergence_check() # Quick analysis\")\n",
    "print(\"\\n Advanced:\")\n",
    "print(\"- create_connected_model_reference() # For comparison\")\n",
    "print(\"- paged_debugger.capture_paged_attention_state() # Manual capture\")\n",
    "print(\"- split_debugger.compare_cache_states() # Manual comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  DEBUGGING EXECUTION EXAMPLE\n",
    "# ===============================\n",
    "\n",
    "# Start the debugging session\n",
    "run_split_model_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4a5d90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
