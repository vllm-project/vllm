op0: NopKernelSchedulerNode(ComputedBuffer)
op0.writes = [MemoryDep('buf0', 256*d0 + d1, {d0: 0, d1: 0})]
op0.unmet_dependencies = []
op0.met_dependencies = []
op0.outputs = [
    buf0: ComputedBuffer
    buf0.layout = FixedLayout('cuda:0', torch.float8_e4m3fn, size=[4, 256], stride=[256, 1])
    buf0.users = [NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]


op1: NopKernelSchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', 2*d0 + d1, {d0: 0, d1: 0})]
op1.unmet_dependencies = []
op1.met_dependencies = []
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.float32, size=[4, 2], stride=[2, 1])
    buf1.users = [NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', c0, {c0: 1024})]
op2.unmet_dependencies = []
op2.met_dependencies = 
    [   MemoryDep('arg0_1', 512*c0 + c1 + 256, {c0: 4, c1: 256}),
        MemoryDep('arg0_1', 512*c0 + c1, {c0: 4, c1: 256})]
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda:0', torch.float16, size=[4, 256], stride=[256, 1])
    buf2.users = [NodeUser(node=ExternKernelSchedulerNode(name='op3'), can_inplace=False, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (1024, 1)
op2.sizes = ([4, 256], [])
arg0_1_layout = FixedLayout('cuda:0', torch.float16, size=[4, 512], stride=[512, 1])
arg0_1_layout = FixedLayout('cuda:0', torch.float16, size=[4, 512], stride=[512, 1])
buf2_layout = FixedLayout('cuda:0', torch.float16, size=[4, 256], stride=[256, 1])
class op2_loop_body:
    var_ranges = {p0: 4, p1: 256}
    index0 = 512*p0 + p1
    index1 = 512*p0 + p1 + 256
    index2 = 256*p0 + p1
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('arg0_1', get_index)
        to_dtype = ops.to_dtype(load, torch.float32, src_dtype = torch.float16)
        get_index_1 = self.get_index('index0')
        load_1 = ops.load('arg0_1', get_index_1)
        to_dtype_1 = ops.to_dtype(load_1, torch.float32, src_dtype = torch.float16)
        sigmoid = ops.sigmoid(to_dtype_1)
        mul = ops.mul(to_dtype, sigmoid)
        to_dtype_2 = ops.to_dtype(mul, torch.float16, src_dtype = torch.float32)
        get_index_2 = self.get_index('index1')
        load_2 = ops.load('arg0_1', get_index_2)
        mul_1 = ops.mul(to_dtype_2, load_2)
        get_index_3 = self.get_index('index2')
        store = ops.store('buf2', get_index_3, mul_1, None)
        return store


op3: ExternKernelSchedulerNode(FallbackKernel)
op3.writes = 
    [   StarDep(name='buf3', mode=None),
        StarDep(name='buf4', mode=None),
        StarDep(name='buf5', mode=None)]
op3.unmet_dependencies = 
    [   StarDep(name='buf0', mode=None),
        StarDep(name='buf1', mode=None),
        StarDep(name='buf2', mode=None)]
op3.met_dependencies = []
op3.outputs = [
    buf3: FallbackKernel
    buf3.layout = NoneLayout(device=device(type='cuda', index=0), size=[0], stride=[0])
    buf3.users = []
    buf4: MutationOutput
    buf4.layout = NoneLayout(device=device(type='cuda', index=0), size=[0], stride=[0])
    buf4.mutations = ['buf0']
    buf4.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
    buf5: MutationOutput
    buf5.layout = NoneLayout(device=device(type='cuda', index=0), size=[0], stride=[0])
    buf5.mutations = ['buf1']
    buf5.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.node.kernel = torch.ops._C.per_token_group_fp8_quant.default


